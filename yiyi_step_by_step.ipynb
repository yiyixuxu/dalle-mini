{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec4bc13d-2cb3-4db1-91e6-0406e2a424e7",
   "metadata": {},
   "source": [
    "__Boris meeting notes__\n",
    "\n",
    "scan layers - \n",
    "* usually used on loops \n",
    "* more memorial \n",
    "* scanned - \n",
    "  * 1 more dimension \n",
    "  * vmap across \n",
    "  \n",
    "where to add n-grammer: FlaxBartEncoder\n",
    "\n",
    "need to edit partition: edit `_get_partition_rules` ('embedding')\n",
    "\n",
    "examples to understand how to use pjit \n",
    "* google reserach /t5x\n",
    "* huggingface transformers /examples/research porjects;https://github.com/huggingface/transformers/tree/main/examples/research_projects/jax-projects/model_parallel\n",
    "\n",
    "the new base config\n",
    "https://wandb.ai/dalle-mini/dalle-mini/runs/v0bq34cl/overview?workspace=user-borisd13\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb412422-c658-41a0-b8a9-5f3812e369e7",
   "metadata": {},
   "source": [
    "__command__\n",
    "* baseline\n",
    "\n",
    "python3 /home/yixu/dalle-yiyi/tools/train/train.py --assert_TPU_available  --do_train --do_eval --config_name config/mini_glu --dtype bfloat16 --tokenizer_name boris/dalle-mini-tokenizer --dataset_repo_or_path boris/gis_filtered --use_auth_token --blank_caption_prob 0.2 --output_dir output --overwrite_output_dir --per_device_train_batch_size 34 --gradient_accumulation_steps 3 --optim distributed_shampoo --block_size 1024 --beta1 0.9 --beta2 0.99 --learning_rate 0.0001 --warmup_steps 2000 --mp_devices 1 --logging_steps 100 --eval_steps 400 --save_steps 4000\n",
    "\n",
    "\n",
    "* testing mp_devices=2\n",
    "\n",
    "python3 /home/yixu/dalle-yiyi/tools/train/train.py --assert_TPU_available  --do_train --do_eval --config_name config/mini_glu --dtype bfloat16 --tokenizer_name boris/dalle-mini-tokenizer --dataset_repo_or_path boris/gis_filtered --use_auth_token --blank_caption_prob 0.2 --output_dir output --overwrite_output_dir --per_device_train_batch_size 34 --gradient_accumulation_steps 3 --optim distributed_shampoo --block_size 1024 --beta1 0.9 --beta2 0.99 --learning_rate 0.0001 --warmup_steps 2000 --mp_devices 2 --logging_steps 100 --eval_steps 400 --save_steps 4000\n",
    "\n",
    "__hugggingface token__: https://huggingface.co/settings/tokens\n",
    "* method1: \n",
    "```python\n",
    "pip install huggingface_hub\n",
    "huggingface-cli login\n",
    "```\n",
    "* method2:\n",
    "```python\n",
    "pip install huggingface_hub\n",
    "python -c \"from huggingface_hub.hf_api import HfFolder; HfFolder.save_token('MY_HUGGINGFACE_TOKEN_HERE')\"\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0591d84d-b6d9-4449-897b-7d5312f4d425",
   "metadata": {},
   "source": [
    "# training loop\n",
    "\n",
    "train.py -main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd21f72f-2b6d-49ea-85ce-a77be1b9ddfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052b8bd9-834c-4635-927e-d73f65865120",
   "metadata": {
    "tags": []
   },
   "source": [
    "### import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29f93b1d-cfaa-4efd-a0ec-4ef028063980",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "root = Path('tools/train/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0efa4e65-0ee1-45ca-aed2-0062ccb63646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't forget to do this next time (create 8 devices on cpu)\n",
    "import os\n",
    "os.environ['XLA_FLAGS'] = '--xla_force_host_platform_device_count=8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f18baaf-8261-49e9-9419-bb3f065b83b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import tempfile\n",
    "import time\n",
    "from dataclasses import asdict, dataclass, field\n",
    "from functools import partial\n",
    "from typing import Any, Callable, NamedTuple, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6dd9e8b-2c95-45c2-8b84-1121ed0342ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flax.core.frozen_dict import FrozenDict, unfreeze\n",
    "from flax.traverse_util import flatten_dict, unflatten_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "354fdeda-a4a4-46a6-806e-bc0374da97bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import flax.linen as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "27935f46-62a5-4295-9525-071d6d589c2e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'FlaxBartEncoder' from 'dalle_mini.model' (/Volumes/GoogleDrive/My Drive/Github/dalle-mini/src/dalle_mini/model/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [410], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdalle_mini\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdalle_mini\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdalle_mini\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     25\u001b[0m     DalleBart,\n\u001b[1;32m     26\u001b[0m     DalleBartConfig,\n\u001b[1;32m     27\u001b[0m     DalleBartTokenizer,\n\u001b[1;32m     28\u001b[0m     set_partitions,\n\u001b[1;32m     29\u001b[0m     FlaxBartEncoder,\n\u001b[1;32m     30\u001b[0m     FlaxBartDecoder\n\u001b[1;32m     31\u001b[0m )\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcloud\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m storage\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'FlaxBartEncoder' from 'dalle_mini.model' (/Volumes/GoogleDrive/My Drive/Github/dalle-mini/src/dalle_mini/model/__init__.py)"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "import flax\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jaxlib\n",
    "import numpy as np\n",
    "import optax\n",
    "import transformers\n",
    "import wandb\n",
    "from datasets import Dataset\n",
    "from flax import core, struct, traverse_util\n",
    "from flax.core.frozen_dict import FrozenDict, freeze, unfreeze\n",
    "from flax.serialization import from_bytes, to_bytes\n",
    "from flax.training.common_utils import onehot\n",
    "from jax.experimental import PartitionSpec, maps\n",
    "from jax.experimental.compilation_cache import compilation_cache as cc\n",
    "from jax.experimental.pjit import pjit, with_sharding_constraint\n",
    "from tools.train.scalable_shampoo.distributed_shampoo import GraftingType, distributed_shampoo\n",
    "from tqdm import tqdm\n",
    "from transformers import HfArgumentParser\n",
    "\n",
    "import dalle_mini\n",
    "from dalle_mini.data import Dataset\n",
    "from dalle_mini.model import (\n",
    "    DalleBart,\n",
    "    DalleBartConfig,\n",
    "    DalleBartTokenizer,\n",
    "    set_partitions,\n",
    ")\n",
    "\n",
    "try:\n",
    "    from google.cloud import storage\n",
    "except:\n",
    "    storage = None\n",
    "\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a326326c-d11e-4a14-a1a9-b2c0ce9fb0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc.initialize_cache(\"jax_cache\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eede60e-2dbd-43a3-b55c-70ee5090656f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### ModelArguments,DataTrainingArguments, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e746c857-371a-44ce-9962-2edfb4b938a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ModelArguments:\n",
    "    \"\"\"\n",
    "    Arguments pertaining to which model/config/tokenizer we are going to fine-tune, or train from scratch.\n",
    "    \"\"\"\n",
    "\n",
    "    model_name_or_path: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"The model checkpoint for weights initialization. \"\n",
    "            \"Don't set if you want to train a model from scratch. \"\n",
    "            \"W&B artifact references are supported in addition to the sources supported by `PreTrainedModel`.\"\n",
    "        },\n",
    "    )\n",
    "    config_name: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"Pretrained config name or path if not the same as model_name_or_path\"\n",
    "        },\n",
    "    )\n",
    "    tokenizer_name: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"Pretrained tokenizer name or path if not the same as model_name_or_path\"\n",
    "        },\n",
    "    )\n",
    "    dtype: Optional[str] = field(\n",
    "        default=\"float32\",\n",
    "        metadata={\n",
    "            \"help\": \"Floating-point format in which the computations will be performed (not the model weights). Choose one of `[float32, float16, bfloat16]`.\"\n",
    "        },\n",
    "    )\n",
    "    restore_state: Optional[bool] = field(\n",
    "        default=False,\n",
    "        metadata={\n",
    "            \"help\": \"Restore optimizer and training state. Can be True (will retrieve associated wandb artifact), a local directory or a Google bucket path.\"\n",
    "        },\n",
    "    )\n",
    "    dropout: Optional[float] = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"Dropout rate. Overwrites config.\"},\n",
    "    )\n",
    "    activation_dropout: Optional[float] = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"Activation dropout rate. Overwrites config.\"},\n",
    "    )\n",
    "    attention_dropout: Optional[float] = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"Attention dropout rate. Overwrites config.\"},\n",
    "    )\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if self.tokenizer_name is None:\n",
    "            self.tokenizer_name = self.model_name_or_path\n",
    "            assert (\n",
    "                self.tokenizer_name is not None\n",
    "            ), \"Tokenizer name or model name/path needs to be specified\"\n",
    "        if self.restore_state:\n",
    "            assert self.model_name_or_path is not None and (\n",
    "                \"/model-\" in self.model_name_or_path\n",
    "            ), \"Restoring state only available with W&B artifact reference\"\n",
    "\n",
    "    def get_metadata(self):\n",
    "        if self.model_name_or_path is not None and \":\" in self.model_name_or_path:\n",
    "            if jax.process_index() == 0:\n",
    "                artifact = wandb.run.use_artifact(self.model_name_or_path)\n",
    "            else:\n",
    "                artifact = wandb.Api().artifact(self.model_name_or_path)\n",
    "            return artifact.metadata\n",
    "        else:\n",
    "            return dict()\n",
    "\n",
    "    def get_opt_state(self):\n",
    "        with tempfile.TemporaryDirectory() as tmp_dir:  # avoid multiple artifact copies\n",
    "            if self.restore_state is True:\n",
    "                # wandb artifact\n",
    "                state_artifact = self.model_name_or_path.replace(\n",
    "                    \"/model-\", \"/state-\", 1\n",
    "                )\n",
    "                if jax.process_index() == 0:\n",
    "                    artifact = wandb.run.use_artifact(state_artifact)\n",
    "                else:\n",
    "                    artifact = wandb.Api().artifact(state_artifact)\n",
    "                if artifact.metadata.get(\"bucket_path\"):\n",
    "                    # we will read directly file contents\n",
    "                    self.restore_state = artifact.metadata[\"bucket_path\"]\n",
    "                else:\n",
    "                    artifact_dir = artifact.download(tmp_dir)\n",
    "                    self.restore_state = str(Path(artifact_dir) / \"opt_state.msgpack\")\n",
    "\n",
    "            if self.restore_state.startswith(\"gs://\"):\n",
    "                bucket_path = Path(self.restore_state[5:]) / \"opt_state.msgpack\"\n",
    "                bucket, blob_name = str(bucket_path).split(\"/\", 1)\n",
    "                assert (\n",
    "                    storage is not None\n",
    "                ), 'Could not find google.storage. Install with \"pip install google-cloud-storage\"'\n",
    "                client = storage.Client()\n",
    "                bucket = client.bucket(bucket)\n",
    "                blob = bucket.blob(blob_name)\n",
    "                return blob.download_as_bytes()\n",
    "\n",
    "            with Path(self.restore_state).open(\"rb\") as f:\n",
    "                return f.read()\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataTrainingArguments:\n",
    "    \"\"\"\n",
    "    Arguments pertaining to what data we are going to input our model for training and eval.\n",
    "    \"\"\"\n",
    "\n",
    "    text_column: Optional[str] = field(\n",
    "        default=\"caption\",\n",
    "        metadata={\n",
    "            \"help\": \"The name of the column in the datasets containing the full texts (for summarization).\"\n",
    "        },\n",
    "    )\n",
    "    encoding_column: Optional[str] = field(\n",
    "        default=\"encoding\",\n",
    "        metadata={\n",
    "            \"help\": \"The name of the column in the datasets containing the image encodings.\"\n",
    "        },\n",
    "    )\n",
    "    dataset_repo_or_path: str = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"The dataset repository containing encoded files.\"},\n",
    "    )\n",
    "    train_file: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"The input training data file (glob & braceexpand acceptable).\"\n",
    "        },\n",
    "    )\n",
    "    validation_file: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"An optional input evaluation data file (glob & braceexpand acceptable).\"\n",
    "        },\n",
    "    )\n",
    "    # data loading should not be a bottleneck so we use \"streaming\" mode by default\n",
    "    streaming: Optional[bool] = field(\n",
    "        default=True,\n",
    "        metadata={\"help\": \"Whether to stream the dataset.\"},\n",
    "    )\n",
    "    use_auth_token: Optional[bool] = field(\n",
    "        default=False,\n",
    "        metadata={\n",
    "            \"help\": \"Whether to use the authentication token for private datasets.\"\n",
    "        },\n",
    "    )\n",
    "    shard_by_host: Optional[bool] = field(\n",
    "        default=False,\n",
    "        metadata={\n",
    "            \"help\": \"Whether to shard data files by host in multi-host environments.\"\n",
    "        },\n",
    "    )\n",
    "    blank_caption_prob: Optional[float] = field(\n",
    "        default=0.0,\n",
    "        metadata={\n",
    "            \"help\": \"Probability of removing some captions for classifier-free guidance.\"\n",
    "        },\n",
    "    )\n",
    "    clip_score_column: Optional[str] = field(\n",
    "        default=\"clip_score\",\n",
    "        metadata={\"help\": \"Column that containts clip score for filtering.\"},\n",
    "    )\n",
    "    min_clip_score: Optional[float] = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"Minimum clip score required.\"},\n",
    "    )\n",
    "    max_clip_score: Optional[float] = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"Maximum clip score required.\"},\n",
    "    )\n",
    "    filter_column: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"Column that containts classes to be filtered.\"},\n",
    "    )\n",
    "    filter_value: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"Class value to be kept during filtering.\"},\n",
    "    )\n",
    "    multi_eval_ds: Optional[bool] = field(\n",
    "        default=False,\n",
    "        metadata={\n",
    "            \"help\": \"Whether to look for multiple validation datasets (local support only).\"\n",
    "        },\n",
    "    )\n",
    "    max_train_samples: Optional[int] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"For debugging purposes or quicker training, truncate the number of training examples.\"\n",
    "        },\n",
    "    )\n",
    "    max_eval_samples: Optional[int] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"For debugging purposes or quicker training, truncate the number of evaluation examples.\"\n",
    "        },\n",
    "    )\n",
    "    preprocessing_num_workers: Optional[int] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"The number of processes to use for the preprocessing. Not used in streaming mode.\"\n",
    "        },\n",
    "    )\n",
    "    overwrite_cache: bool = field(\n",
    "        default=False,\n",
    "        metadata={\n",
    "            \"help\": \"Overwrite the cached training and evaluation sets. Not used in streaming mode.\"\n",
    "        },\n",
    "    )\n",
    "    # default seed of None ensures we don't repeat the same items if script was interrupted during an epoch\n",
    "    seed_dataset: int = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"Random seed for the dataset that will be set at the beginning of training.\"\n",
    "        },\n",
    "    )\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if self.dataset_repo_or_path is None:\n",
    "            raise ValueError(\"Need a dataset repository or path.\")\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TrainingArguments:\n",
    "    \"\"\"\n",
    "    Arguments pertaining to training parameters.\n",
    "    \"\"\"\n",
    "\n",
    "    output_dir: str = field(\n",
    "        metadata={\n",
    "            \"help\": \"The output directory where the model predictions and checkpoints will be written.\"\n",
    "        },\n",
    "    )\n",
    "    overwrite_output_dir: bool = field(\n",
    "        default=False,\n",
    "        metadata={\n",
    "            \"help\": (\n",
    "                \"Overwrite the content of the output directory. \"\n",
    "                \"Use this to continue training if output_dir points to a checkpoint directory.\"\n",
    "            )\n",
    "        },\n",
    "    )\n",
    "\n",
    "    do_train: bool = field(default=False, metadata={\"help\": \"Whether to run training.\"})\n",
    "    do_eval: bool = field(\n",
    "        default=False, metadata={\"help\": \"Whether to run eval on the validation set.\"}\n",
    "    )\n",
    "\n",
    "    per_device_train_batch_size: int = field(\n",
    "        default=8,\n",
    "        metadata={\"help\": \"Batch size per data parallel device for training.\"},\n",
    "    )\n",
    "    per_device_eval_batch_size: Optional[int] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"Batch size per data parallel device for evaluation. Same as training batch size if not set.\"\n",
    "        },\n",
    "    )\n",
    "\n",
    "    gradient_accumulation_steps: int = field(\n",
    "        default=1,\n",
    "        metadata={\n",
    "            \"help\": \"Number of updates steps to accumulate before performing an update pass.\"\n",
    "        },\n",
    "    )\n",
    "    gradient_checkpointing: bool = field(\n",
    "        default=False, metadata={\"help\": \"Use gradient checkpointing.\"}\n",
    "    )\n",
    "\n",
    "    learning_rate: float = field(\n",
    "        default=5e-5, metadata={\"help\": \"The initial learning rate.\"}\n",
    "    )\n",
    "    optim: str = field(\n",
    "        default=\"distributed_shampoo\",\n",
    "        metadata={\n",
    "            \"help\": 'The optimizer to use. Can be \"distributed_shampoo\" (default), \"adam\" or \"adafactor\"'\n",
    "        },\n",
    "    )\n",
    "    weight_decay: float = field(\n",
    "        default=0.0, metadata={\"help\": \"Weight decay applied to parameters.\"}\n",
    "    )\n",
    "    beta1: float = field(\n",
    "        default=0.9,\n",
    "        metadata={\"help\": \"Beta1 for Adam & Distributed Shampoo.\"},\n",
    "    )\n",
    "    beta2: float = field(\n",
    "        default=0.999,\n",
    "        metadata={\"help\": \"Beta2 for for Adam & Distributed Shampoo.\"},\n",
    "    )\n",
    "    adam_epsilon: float = field(\n",
    "        default=1e-8, metadata={\"help\": \"Epsilon for AdamW optimizer.\"}\n",
    "    )\n",
    "    max_grad_norm: float = field(\n",
    "        default=1.0, metadata={\"help\": \"Max gradient norm for Adafactor.\"}\n",
    "    )\n",
    "    block_size: int = field(\n",
    "        default=1024,\n",
    "        metadata={\"help\": \"Chunked size for large layers with Distributed Shampoo.\"},\n",
    "    )\n",
    "    preconditioning_compute_steps: int = field(\n",
    "        default=10, metadata={\"help\": \"Number of steps to update preconditioner.\"}\n",
    "    )\n",
    "    skip_preconditioning_dim_size_gt: int = field(\n",
    "        default=4096,\n",
    "        metadata={\"help\": \"Max size for preconditioning with Distributed Shampoo.\"},\n",
    "    )\n",
    "    graft_type: str = field(\n",
    "        default=\"rmsprop_normalized\",\n",
    "        metadata={\n",
    "            \"help\": \"The type of grafting to use. Can be 'rmsprop_normalized' (default), 'rmsprop', 'adagrad', 'adagrad_normalized', 'sgd' or 'sqrt_n'\"\n",
    "        },\n",
    "    )\n",
    "    nesterov: bool = field(\n",
    "        default=False,\n",
    "        metadata={\"help\": \"Use Nesterov momentum for Distributed Shampoo.\"},\n",
    "    )\n",
    "    optim_quantized: bool = field(\n",
    "        default=False,\n",
    "        metadata={\n",
    "            \"help\": \"Whether to quantize optimizer (only supported with Distributed Shampoo).\"\n",
    "        },\n",
    "    )\n",
    "    shard_shampoo_across: str = field(\n",
    "        default=\"dp\",\n",
    "        metadata={\n",
    "            \"help\": \"Whether to shard the optimizer across data devices (dp), model devices (mp) or both (2d).\"\n",
    "        },\n",
    "    )\n",
    "\n",
    "    num_train_epochs: int = field(\n",
    "        default=3, metadata={\"help\": \"Total number of training epochs to perform.\"}\n",
    "    )\n",
    "\n",
    "    warmup_steps: int = field(\n",
    "        default=0, metadata={\"help\": \"Linear warmup over warmup_steps.\"}\n",
    "    )\n",
    "    lr_decay: str = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"Decay to be used in the learning rate scheduler. Can be None (default), linear or exponential.\"\n",
    "        },\n",
    "    )\n",
    "    lr_transition_steps: int = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"Number of transition steps associated with learning rate decay when using exponential decay.\"\n",
    "        },\n",
    "    )\n",
    "    lr_decay_rate: float = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"Decay rate associated with learning rate when using exponential decay.\"\n",
    "        },\n",
    "    )\n",
    "    lr_staircase: bool = field(\n",
    "        default=False,\n",
    "        metadata={\n",
    "            \"help\": \"Whether to use staircase or continuous learning rate when using exponential decay.\"\n",
    "        },\n",
    "    )\n",
    "    lr_offset: int = field(\n",
    "        default=0,\n",
    "        metadata={\"help\": \"Number of steps to offset learning rate and keep it at 0.\"},\n",
    "    )\n",
    "    logging_steps: int = field(\n",
    "        default=40, metadata={\"help\": \"Log every X updates steps.\"}\n",
    "    )\n",
    "    eval_steps: int = field(\n",
    "        default=400, metadata={\"help\": \"Run an evaluation every X steps.\"}\n",
    "    )\n",
    "    save_steps: int = field(\n",
    "        default=4000, metadata={\"help\": \"Save checkpoint every X updates steps.\"}\n",
    "    )\n",
    "    log_model: bool = field(\n",
    "        default=False,\n",
    "        metadata={\"help\": \"Log model to wandb at `save_steps` frequency.\"},\n",
    "    )\n",
    "    log_norm_steps: int = field(\n",
    "        default=True,\n",
    "        metadata={\"help\": \"Log parameters and gradients norm at this frequency.\"},\n",
    "    )\n",
    "    log_histogram_steps: int = field(\n",
    "        default=False,\n",
    "        metadata={\n",
    "            \"help\": \"Log parameters and gradients histograms at this frequency. Slows down training.\"\n",
    "        },\n",
    "    )\n",
    "\n",
    "    seed_model: int = field(\n",
    "        default=42,\n",
    "        metadata={\n",
    "            \"help\": \"Random seed for the model that will be set at the beginning of training.\"\n",
    "        },\n",
    "    )\n",
    "\n",
    "    embeddings_only: bool = field(\n",
    "        default=False, metadata={\"help\": \"Train only embedding layers.\"}\n",
    "    )\n",
    "    init_embeddings: bool = field(\n",
    "        default=False,\n",
    "        metadata={\"help\": \"When training embedding layers, initialize them.\"},\n",
    "    )\n",
    "\n",
    "    wandb_entity: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"The wandb entity to use (for teams).\"},\n",
    "    )\n",
    "    wandb_project: str = field(\n",
    "        default=\"dalle-mini\",\n",
    "        metadata={\"help\": \"The name of the wandb project.\"},\n",
    "    )\n",
    "    wandb_job_type: str = field(\n",
    "        default=\"Seq2Seq\",\n",
    "        metadata={\"help\": \"The name of the wandb job type.\"},\n",
    "    )\n",
    "\n",
    "    assert_TPU_available: bool = field(\n",
    "        default=False,\n",
    "        metadata={\"help\": \"Verify that TPU is not in use.\"},\n",
    "    )\n",
    "\n",
    "    use_vmap_trick: bool = field(\n",
    "        default=True,\n",
    "        metadata={\"help\": \"Verify that TPU is not in use.\"},\n",
    "    )\n",
    "\n",
    "    mp_devices: Optional[int] = field(\n",
    "        default=1,\n",
    "        metadata={\n",
    "            \"help\": \"Number of devices required for model parallelism. The other dimension of available devices is used for data parallelism.\"\n",
    "        },\n",
    "    )\n",
    "\n",
    "    dp_devices: int = field(init=False)\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if self.assert_TPU_available:\n",
    "            assert (\n",
    "                jax.local_device_count() == 8\n",
    "            ), \"TPUs in use, please check running processes\"\n",
    "        if self.output_dir.startswith(\"gs://\"):\n",
    "            assert (\n",
    "                storage is not None\n",
    "            ), 'Could not find google.storage. Install with \"pip install google-cloud-storage\"'\n",
    "        assert self.optim in [\n",
    "            \"distributed_shampoo\",\n",
    "            \"adam\",\n",
    "            \"adafactor\",\n",
    "        ], f\"Selected optimizer not supported: {self.optim}\"\n",
    "        if self.optim == \"adafactor\" and self.weight_decay == 0:\n",
    "            self.weight_decay = None\n",
    "        assert self.graft_type in [\n",
    "            \"rmsprop_normalized\",\n",
    "            \"rmsprop\",\n",
    "            \"adagrad\",\n",
    "            \"adagrad_normalized\",\n",
    "            \"sgd\",\n",
    "            \"sqrt_n\",\n",
    "        ], f\"Selected graft type not supported: {self.graft_type}\"\n",
    "        assert self.lr_decay in [\n",
    "            None,\n",
    "            \"linear\",\n",
    "            \"exponential\",\n",
    "        ], f\"Selected learning rate decay not supported: {self.lr_decay}\"\n",
    "        if self.per_device_eval_batch_size is None:\n",
    "            self.per_device_eval_batch_size = self.per_device_train_batch_size\n",
    "        if self.log_norm_steps is True:\n",
    "            self.log_norm_steps = self.logging_steps\n",
    "        if not self.do_train:\n",
    "            self.num_train_epochs = 1\n",
    "        if (\n",
    "            os.path.exists(self.output_dir)\n",
    "            and os.listdir(self.output_dir)\n",
    "            and self.do_train\n",
    "            and not self.overwrite_output_dir\n",
    "        ):\n",
    "            raise ValueError(\n",
    "                f\"Output directory ({self.output_dir}) already exists and is not empty.\"\n",
    "                \"Use --overwrite_output_dir to overcome.\"\n",
    "            )\n",
    "        assert self.shard_shampoo_across in [\n",
    "            \"dp\",\n",
    "            \"mp\",\n",
    "            \"2d\",\n",
    "        ], f\"Shard shampoo across {self.shard_shampoo_across} not supported.\"\n",
    "        assert (\n",
    "            self.mp_devices > 0\n",
    "        ), f\"Number of devices for model parallelism must be > 0\"\n",
    "        assert (\n",
    "            jax.device_count() % self.mp_devices == 0\n",
    "        ), f\"Number of available devices ({jax.device_count()} must be divisible by number of devices used for model parallelism ({self.mp_devices}).\"\n",
    "        self.dp_devices = jax.device_count() // self.mp_devices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6aae11-77db-457e-a404-d672976b7241",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### create parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ae61ec0-d1de-4d30-9fcd-b078c9c37b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = HfArgumentParser(\n",
    "        (ModelArguments, DataTrainingArguments, TrainingArguments)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65561459-a99c-4284-9c48-3784cd357f03",
   "metadata": {},
   "source": [
    "based on __base config__:\n",
    "\n",
    "\n",
    "https://wandb.ai/dalle-mini/dalle-mini/runs/mheh9e55/overview?workspace=user-borisd13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf04e0e2-6aa2-41ee-bc4f-2442705ec5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on https://wandb.ai/dalle-mini/dalle-mini/runs/mheh9e55/overview?workspace=user-borisd13\n",
    "# I removed --assert_TPU_available --wandb_entity dalle-mini\n",
    "# make mp_device = 1 \n",
    "  # tried to make mp_device=1 but it doesn't work (not dividable)\n",
    "commandline = [\"--do_train\", \"--do_eval\",\n",
    "               \"--config_name\", \"config/mini_glu\",\n",
    "                          \"--dtype\", \"bfloat16\",\n",
    "                          \"--tokenizer_name\", \"boris/dalle-mini-tokenizer\",\n",
    "                          \"--dataset_repo_or_path\", \"boris/gis_filtered\",\n",
    "                          \"--use_auth_token\",\n",
    "                          \"--blank_caption_prob\", \"0.2\",\n",
    "                          \"--output_dir\", \"output\",\n",
    "                          \"--overwrite_output_dir\",\n",
    "                          \"--per_device_train_batch_size\", \"34\",\n",
    "                          \"--gradient_accumulation_steps\", \"3\",\n",
    "                          \"--optim\", \"distributed_shampoo\",\n",
    "                          \"--block_size\", \"1024\",\n",
    "                          \"--beta1\", \"0.9\",\n",
    "                          \"--beta2\", \"0.99\",\n",
    "                          \"--learning_rate\", \"0.0001\",\n",
    "                          \"--warmup_steps\", \"2000\",\n",
    "                          \"--mp_devices\", \"1\",\n",
    "                          \"--logging_steps\", \"100\",\n",
    "                          \"--eval_steps\", \"400\",\n",
    "                          \"--save_steps\", \"4000\",\n",
    "                          \"--log_model\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c70ae9-6505-4b1c-8e89-6e8ba05f7096",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### parse the arguments into 3 dicts: model_args, data_args and training_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61d09166-2f2e-4275-93f5-e37a16ddef82",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args, data_args, training_args = parser.parse_args_into_dataclasses(commandline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9261886-91b2-408d-90e9-ad73a8d51e86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelArguments(model_name_or_path=None, config_name='config/mini_glu', tokenizer_name='boris/dalle-mini-tokenizer', dtype='bfloat16', restore_state=False, dropout=None, activation_dropout=None, attention_dropout=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4fa41b2-3553-45a8-b830-96b0a95cc9ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainingArguments(output_dir='output', overwrite_output_dir=True, do_train=True, do_eval=True, per_device_train_batch_size=34, per_device_eval_batch_size=34, gradient_accumulation_steps=3, gradient_checkpointing=False, learning_rate=0.0001, optim='distributed_shampoo', weight_decay=0.0, beta1=0.9, beta2=0.99, adam_epsilon=1e-08, max_grad_norm=1.0, block_size=1024, preconditioning_compute_steps=10, skip_preconditioning_dim_size_gt=4096, graft_type='rmsprop_normalized', nesterov=False, optim_quantized=False, shard_shampoo_across='dp', num_train_epochs=3, warmup_steps=2000, lr_decay=None, lr_transition_steps=None, lr_decay_rate=None, lr_staircase=False, lr_offset=0, logging_steps=100, eval_steps=400, save_steps=4000, log_model=True, log_norm_steps=100, log_histogram_steps=False, seed_model=42, embeddings_only=False, init_embeddings=False, wandb_entity=None, wandb_project='dalle-mini', wandb_job_type='Seq2Seq', assert_TPU_available=False, use_vmap_trick=True, mp_devices=1, dp_devices=8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea5a824-2faa-40c0-a077-725da4a95176",
   "metadata": {
    "tags": []
   },
   "source": [
    "### create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "971ad466-5db9-4dd7-88b5-8b96b9e2d57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset as hf_load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c53516e1-52d5-42fa-8014-54c08bd0d241",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Using custom data configuration boris--gis_filtered-25538b40fa6a4fdf\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset(\n",
    "        **asdict(data_args),\n",
    "        do_train=training_args.do_train,\n",
    "        do_eval=training_args.do_eval,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1fbc7abc-b24b-4430-8bc4-73852a8399ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local TPUs: 8\n"
     ]
    }
   ],
   "source": [
    "print(f\"Local TPUs: {jax.local_device_count()}\")\n",
    "logger.info(f\"Global TPUs: {jax.device_count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ff98903-63af-41ca-ad7c-5e95772c099e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Logger __main__ (WARNING)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba77c313-5f16-4a8d-bff8-c9efa250459f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### get model config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0ef8b523-ff45-4422-bc9e-0b24b03b4b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  look for dropout and gradient_checkpointing\n",
    "# add to the default config if any\n",
    "config_args = {\n",
    "        k: getattr(model_args, k)\n",
    "        for k in [\"dropout\", \"activation_dropout\", \"attention_dropout\"]\n",
    "        if getattr(model_args, k) is not None\n",
    "    }\n",
    "config_args[\"gradient_checkpointing\"] = training_args.gradient_checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cbbe856b-d83e-4057-8424-2431ef858430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gradient_checkpointing': False}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "94127576-fb77-4a1e-8e78-82f50b57c118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create config as DalleBartConfig\n",
    "config = DalleBartConfig.from_pretrained(str(root /model_args.config_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c800df48-6ed5-4bb0-8112-f49028349c58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DalleBartConfig {\n",
       "  \"activation_dropout\": 0.0,\n",
       "  \"activation_function\": \"gelu\",\n",
       "  \"attention_dropout\": 0.0,\n",
       "  \"bos_token_id\": 16385,\n",
       "  \"d_model\": 1024,\n",
       "  \"decoder_attention_heads\": 16,\n",
       "  \"decoder_ffn_dim\": 2730,\n",
       "  \"decoder_layers\": 12,\n",
       "  \"decoder_start_token_id\": 16384,\n",
       "  \"do_sample\": true,\n",
       "  \"dropout\": 0.0,\n",
       "  \"encoder_attention_heads\": 16,\n",
       "  \"encoder_ffn_dim\": 2730,\n",
       "  \"encoder_layers\": 12,\n",
       "  \"encoder_vocab_size\": 50300,\n",
       "  \"eos_token_id\": 16385,\n",
       "  \"force_ln_scale\": false,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"image_length\": 256,\n",
       "  \"image_vocab_size\": 16400,\n",
       "  \"init_std\": 0.02,\n",
       "  \"is_encoder_decoder\": true,\n",
       "  \"ln_positions\": \"normformer\",\n",
       "  \"ln_type\": \"layernorm\",\n",
       "  \"max_length\": 257,\n",
       "  \"max_text_length\": 64,\n",
       "  \"min_length\": 257,\n",
       "  \"model_type\": \"dallebart\",\n",
       "  \"normalize_text\": true,\n",
       "  \"pad_token_id\": 16385,\n",
       "  \"scale_embedding\": false,\n",
       "  \"sinkhorn_iters\": 1,\n",
       "  \"tau_init\": 0.05,\n",
       "  \"tie_word_embeddings\": false,\n",
       "  \"transformers_version\": \"4.24.0.dev0\",\n",
       "  \"use_absolute_position_embeddings\": true,\n",
       "  \"use_alibi\": false,\n",
       "  \"use_bias\": false,\n",
       "  \"use_cache\": true,\n",
       "  \"use_cosine_attention\": false,\n",
       "  \"use_deepnet_scaling\": false,\n",
       "  \"use_final_ln_decoder\": true,\n",
       "  \"use_final_ln_encoder\": true,\n",
       "  \"use_glu\": true,\n",
       "  \"use_head_scale\": false,\n",
       "  \"use_scan\": false,\n",
       "  \"use_subln_init\": false,\n",
       "  \"use_swin_position_embeddings\": false\n",
       "}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffe3269-c4d8-48da-aacf-74598b91efe0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ef530704-f43c-4f11-868d-6f0659be565e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# did not provide a model path so create a new model \n",
    "model_args.model_name_or_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8a8d82c3-c29d-4c2e-9ee0-b33563cc4b38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args.seed_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "969745af-ca4b-4d5f-a13a-50e1121a328a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bfloat16'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dtype in tpu is bfloat16\n",
    "model_args.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "47367881-5541-4017-8ca5-9e90c2f2cfa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "jax.numpy.bfloat16"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getattr(jnp, model_args.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "98951f0a-8856-4e82-9066-3bb66f400b37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "jax.numpy.bfloat16"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.bfloat16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "17d7d02e-1b30-46d7-a3dc-bfb8f443ce3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = DalleBart(\n",
    "            config,\n",
    "            seed=training_args.seed_model,\n",
    "            dtype=getattr(jnp, model_args.dtype),\n",
    "            _do_init=False,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cad5fd8e-f1d4-4322-a23d-7aaf2fe874f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "844c076c-c7c2-4549-8bbe-6d64ed312b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the config_args (dropout and gradient_checkpointing) to model config\n",
    "for k, v in config_args.items():\n",
    "    setattr(model.config, k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1bd5893e-e03c-4975-bde2-b4e0938b4279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5180626384, 5180626384)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(model.config), id(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "62114813-d011-45cd-9c2a-8bb3ddf58ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get model metadata\n",
    "model_metadata = model_args.get_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "306f5509-7b0f-485d-a5bc-db039a89937c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52c181d-0c72-494b-a5bd-885a1e3f9dfc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### !! get partitionspec -> param_spec\n",
    "\n",
    "use __set_partitions__ function to get __ParitionSpec__ for params \n",
    "\n",
    "```python\n",
    "param_spec = set_partitions(params_shape, model.config.use_scan)\n",
    "```\n",
    "* input __params_shape__ is a tree contains shapes info(i.e. __ShapeDtypeStruct__) for each parameters\n",
    "* returns __param_spec__ is a tree with same structure but with __PartitionSpec__\n",
    "\n",
    "what is __PartitionSpec__?\n",
    "* __resource assignment specification__, used to define __pjit__'s argument __in_axis_resources__ and __out_axis_resources__ : \n",
    "```python\n",
    "pjit(fn, in_axis_resources= .., out_axis_resources=..)(data)\n",
    "```\n",
    "* it is a __tuple__ of __length__ at most equal to the __rank of the partitioned value__ \n",
    "  * partitioned value?\n",
    "    * in the example above, __data__ and __in_axis_resource__ should both be pytree with __same structure__, one contain __partitioned value__, one contains the __PartitionSpec__, each PartitionedSpec has a corresponding paritioned value in __data__\n",
    "* <u>each element in PartitionSpec</u> can be a __None__, a __mesh axis__ or a __tuple of mesh axes__, and specifies the set of resources assigned to partition the <u>valueâ€™s dimension</u> matching its position in the spec\n",
    "* we will look at our example soon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "595ca0b6-70ea-49cb-a8bf-120d3009d606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# arguments\n",
    "model.config.use_scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "82ebba04-93b1-42a1-a754-0367601cf481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params_shape_tree is a property of FlaxPreTrainedModel - it's created when the model object is created\n",
    "params_shape = model.params_shape_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "be08f243-ec4f-4dc3-9948-e3edc25c860d",
   "metadata": {},
   "outputs": [],
   "source": [
    " # get PartitionSpec for model params (required to be a dict)\n",
    "param_spec = set_partitions(params_shape, model.config.use_scan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ecbb5e19-bc87-4645-a812-5e62f374d375",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_shape = freeze(params_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309f5a60-d17f-4468-a19e-447a74e7c98e",
   "metadata": {},
   "source": [
    "How is __param_spec__ used in dalle-mini?\n",
    "\n",
    "* assume we load the model from a checkpoint(which we are not now) , we will need to use param_spec to create __initial train state__\n",
    "* our __params__ is None right now, but assume we are loading model from a checkpoint, the params variable will be a pytree with same structure as __param_spec__, and you can checkout the shape for each individual parameter in __params_shape__ below\n",
    "\n",
    "```python\n",
    "state = pjit(\n",
    "                init_state,\n",
    "                in_axis_resources=(param_spec,)\n",
    "                if model_args.model_name_or_path\n",
    "                else None,\n",
    "                out_axis_resources=state_spec,\n",
    "                donate_argnums=(0,),\n",
    "            )(params)\n",
    "```\n",
    "\n",
    "below, we will taking one __parameter__ (i.e. partitioned value) as example, trying to understand its __PartitionSpec__ \n",
    "\n",
    "* the parameter __P__ has 2 dimensions: __<font color=red>p[0]</font>__, __P[1]__ (1024 x 16385)\n",
    "    ```python\n",
    "    p(0,0),    p(0,1), ..., p(0,16384)\n",
    "    p(1,0),    p(1,1), ..., p(1,16384)\n",
    "    \n",
    "    ...\n",
    "    p(1023,0), p(1023,1),...,p(1023,16384)\n",
    "    ```\n",
    "* the __mesh__ has 2 dimensions: __'dp'__, __'mp'__ (4 x 2) \n",
    "    ```python\n",
    "    d0, d1, \n",
    "    d2, d3\n",
    "    d4, d5, \n",
    "    d6, d7\n",
    "    ```\n",
    "* the PartitionSpec __PartitionSpec(<font color=red>None</font>, 'mp')__ has 2 elements, corresponding to the __<font color=red>p[0]</font>__ and __p[1]__. and it says we want to <font color=blue>shard</font> __p[1]__ across the mesh axis __'mp'__ and <font color=blue>duplicated</font> __<font color=red>p[0]</font>__ across mesh axis <font color=red>__'dp'__</font>\n",
    " \n",
    " \n",
    "so the 4 devices on the first column __(i.e. d0,d2,d4,d6)__ will have same slice of data \n",
    "  ```python\n",
    "   p(0,0),    p(0,1),  ..., p(0,8192)\n",
    "   p(1,0),    p(1,1),  ..., p(1,8192)\n",
    "                 ...\n",
    "   p(1023,0), p(1023,1),...,p(1023,8192)\n",
    "   ```\n",
    "    \n",
    "the 4 devices on the second column __(d1,d3,d5,d7)__ will also have same slice of data\n",
    "\n",
    "   ```python\n",
    "   p(0,8192),    p(0,8193),  ...,    p(0,16384)\n",
    "   p(1,8192),    p(1,8193),  ...,    p(1,16384)\n",
    "                 ...\n",
    "   p(1023,8192), p(1023,8193),  ..., p(1023,16384)\n",
    "   ```\n",
    "  \n",
    " we will validate this later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "250f94f3-0848-41de-a05e-62181f3e056f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ShapeDtypeStruct(shape=(1024, 16401), dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take one parameter as example, i.e. lm_head /kernel, denote as P\n",
    "# P has 2 dimensions, size 1024 x 16385 \n",
    "params_shape['lm_head']['kernel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ae085eab-fcd9-4a1e-b58a-d1ed13b2a3a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PartitionSpec(None, 'mp')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#P's partitionspec in param_spec\n",
    "# None <-> p[0] <-> mesh axis 'dp' : the first dimension (size 1024 will be replicated across dp =4)\n",
    "# 'mp' -> p[1] <-> mesh axis 'mp': the second dimension (size 16385 will be sharded across mp = 2)\n",
    "param_spec['lm_head']['kernel']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462220d3-259f-4809-a590-7a74b5406817",
   "metadata": {},
   "source": [
    "PartitionSpec for parameters\n",
    "* it seems like embedding dimension (1024) is always None\n",
    "* we want to make sure all device has access to all embedding dimensions(?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "a8650c01-35ed-4f04-9da3-9e79a6ac1937",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenDict({\n",
       "    lm_head: {\n",
       "        kernel: PartitionSpec(None, 'mp'),\n",
       "    },\n",
       "    model: {\n",
       "        decoder: {\n",
       "            embed_positions: {\n",
       "                embedding: PartitionSpec('mp', None),\n",
       "            },\n",
       "            embed_tokens: {\n",
       "                embedding: PartitionSpec('mp', None),\n",
       "            },\n",
       "            final_ln: {\n",
       "                bias: None,\n",
       "            },\n",
       "            layernorm_embedding: {\n",
       "                bias: None,\n",
       "                scale: None,\n",
       "            },\n",
       "            layers: {\n",
       "                FlaxBartDecoderLayer_0: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_1: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_10: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_11: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_2: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_3: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_4: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_5: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_6: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_7: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_8: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_9: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "            },\n",
       "        },\n",
       "        encoder: {\n",
       "            embed_positions: {\n",
       "                embedding: PartitionSpec('mp', None),\n",
       "            },\n",
       "            embed_tokens: {\n",
       "                embedding: PartitionSpec('mp', None),\n",
       "            },\n",
       "            final_ln: {\n",
       "                bias: None,\n",
       "            },\n",
       "            layernorm_embedding: {\n",
       "                bias: None,\n",
       "                scale: None,\n",
       "            },\n",
       "            layers: {\n",
       "                FlaxBartEncoderLayer_0: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_1: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_10: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_11: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_2: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_3: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_4: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_5: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_6: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_7: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_8: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_9: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "            },\n",
       "        },\n",
       "    },\n",
       "})"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "a9101986-6e28-454d-945d-772adaa9a430",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenDict({\n",
       "    lm_head: {\n",
       "        kernel: ShapeDtypeStruct(shape=(1024, 16401), dtype=float32),\n",
       "    },\n",
       "    model: {\n",
       "        decoder: {\n",
       "            embed_positions: {\n",
       "                embedding: ShapeDtypeStruct(shape=(256, 1024), dtype=float32),\n",
       "            },\n",
       "            embed_tokens: {\n",
       "                embedding: ShapeDtypeStruct(shape=(16401, 1024), dtype=float32),\n",
       "            },\n",
       "            final_ln: {\n",
       "                bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "            },\n",
       "            layernorm_embedding: {\n",
       "                bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "            },\n",
       "            layers: {\n",
       "                FlaxBartDecoderLayer_0: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_1: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_10: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_11: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_2: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_3: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_4: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_5: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_6: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_7: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_8: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_9: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                },\n",
       "            },\n",
       "        },\n",
       "        encoder: {\n",
       "            embed_positions: {\n",
       "                embedding: ShapeDtypeStruct(shape=(64, 1024), dtype=float32),\n",
       "            },\n",
       "            embed_tokens: {\n",
       "                embedding: ShapeDtypeStruct(shape=(50300, 1024), dtype=float32),\n",
       "            },\n",
       "            final_ln: {\n",
       "                bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "            },\n",
       "            layernorm_embedding: {\n",
       "                bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "            },\n",
       "            layers: {\n",
       "                FlaxBartEncoderLayer_0: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_1: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_10: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_11: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_2: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_3: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_4: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_5: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_6: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_7: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_8: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_9: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                },\n",
       "            },\n",
       "        },\n",
       "    },\n",
       "})"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab418c9c-356d-498d-a110-faf7e89016ab",
   "metadata": {
    "tags": []
   },
   "source": [
    "### load tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "40930437-d19d-4622-a764-680920acfd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DalleBartTokenizer.from_pretrained(\n",
    "        model_args.tokenizer_name, use_fast=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "33194450-4157-4b8f-8ceb-6a99bd1d0971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizerFast(name_or_path='boris/dalle-mini-tokenizer', vocab_size=50265, model_max_len=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=False)})"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "fa7670cf-8045-4b15-b4ff-f986976376a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab['<s>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "c00045b8-8b12-4251-b955-d72f50ea0413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab['</s>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "58fb9c65-1609-4c02-97e3-ab2aeff8f6b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab['<unk>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "52b1c1e9-d415-4419-92a9-d5e11ecf6477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab['<pad>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "aa0b5f25-dfbd-4af4-824c-ecd1de858101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50265"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9db36f-d214-473f-bada-64e143e69378",
   "metadata": {
    "tags": []
   },
   "source": [
    "### preprocessing dataset\n",
    "* filter dataset - doesn't do anything with our base config\n",
    "* apply a normalize function on captions -> not sure what it does \n",
    "* randomly replace 20% of captions as blank texts\n",
    "* create output\n",
    "  * input_ids: tokenized caption\n",
    "  * attention_mask: output of tokenizer as well \n",
    "  * \"labels\" (i.e. example[\"encoding\"])\n",
    "    *  __what is example['encoding']?__ output from vqgan encoder \n",
    "  * \"decoder_input_ids\" (same as labels but shift right 1 position, adding bos token)\n",
    "    * e.g. tok1, tok2, tok3 -> bos, tok1, tok2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "eb30c18d-7a1f-4705-a16b-4a15cbb9f4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing the datasets.\n",
    "# We need to normalize and tokenize inputs and targets.\n",
    "dataset.preprocess(tokenizer=tokenizer, config=model.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ec850d4d-cc04-4217-aa07-d2194d01094c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'generator' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [45], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# vqgan encode images to 16 x 16 = 256 discrete tokens from a vocabulary of size 16384,\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m))\n",
      "\u001b[0;31mTypeError\u001b[0m: 'generator' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# vqgan encode images to 16 x 16 = 256 discrete tokens from a vocabulary of size 16384,\n",
    "len(next(iter(dataset.train_dataset)['encoding']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "628e1237-e4d4-4b15-86f6-9aba428bc69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_preprocessed = next(iter(dataset.train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1439bde9-6438-472e-81c7-c5a1af2262af",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': array([    0,    75,  1455,    31,    11,  7315, 16612, 25641,  5072,\n",
       "         7406,    11,   176, 49895,   107,   820,   125, 10795,     2,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1]),\n",
       " 'attention_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'labels': array([ 1304, 15525, 14164,  7191,  8173,  1495, 16147,  8173,  2428,\n",
       "         8173, 14447,  8173, 14164, 14164,  1755, 11605,  4815,  2528,\n",
       "         2528,  6965,  3212, 11674,  9157,  3547,  4236,  5900,  8493,\n",
       "        14447,  8447,  2528, 11605, 10549,  2810,  1989,  9899,  4945,\n",
       "        13107,  1024,  6204, 15387,  8408, 11228,  8668,   134,  1742,\n",
       "         7504,  2428, 11605, 14447,  7504,  8493,  6078, 15881,  1464,\n",
       "         8663,  9296, 15945,  2813,  5791, 15703, 15695, 12062,  2528,\n",
       "        14447,  6965,  2428, 10549,  6242, 14247, 10278,  8412,  1402,\n",
       "         9470,  8668,  1270,   632, 10956,   572,  6965,  2129,  6965,\n",
       "        10549,  9502, 11024, 13293,  1952,  8717,  2813,  3812, 10805,\n",
       "          948,  1270,  8225,  3386,  5657,  8447, 11196,  6078,  9514,\n",
       "         9819,  8663, 11196, 12625,  7106, 11591,  1227,  9470,  4869,\n",
       "         4635,  3135,  4950, 13769, 11196,  1989, 11725,  9753,  8888,\n",
       "         6965,  8202,  6628,  6690,  3804, 13513,  1586,  8431,  7467,\n",
       "         5071,  9630, 11196,  1755, 10561, 12272,  8888, 12016,  5509,\n",
       "        11004,  8075,  8888, 11456,  7191,  2439,   699,  5657, 15558,\n",
       "        14447,  7781, 11196,  6060, 11456, 14703,  4483, 15431,  4945,\n",
       "         7696,  5418, 14703, 15963,  8888, 13579,  5305,  7491,  5401,\n",
       "         8202,  1193, 11587,  2383,  2105,  1402,  1586, 12623,    66,\n",
       "         5509,  7504,  1635,  7751,  1052,  4147, 10508, 12659,  6808,\n",
       "         9131, 14547,  4483,  2428,  2428,  8612,  3424,  5772, 10362,\n",
       "         4147,  1755, 10019,  4815, 10549,  2528,  4465, 10037,  1464,\n",
       "        11326,  8867,  8111,  7696,  6348, 12625,  1702, 11591,  8493,\n",
       "        10549,  6965, 14447,  2528,  6078,  2334,  8566, 16031,  7749,\n",
       "        13579,  7491,  8408,  7781,  9150,  8075,  7504,  2528,  6965,\n",
       "         6172,  6172,  6889, 14494,  6348,  8447, 10549,   601, 10549,\n",
       "        11993, 10912, 11725, 12892,  7504, 11605, 14853,  4903,  6930,\n",
       "        14247, 13769,  5657, 14247,  4903,  4903,  4099,  4903, 14247,\n",
       "         4903, 13769,  6930, 12016]),\n",
       " 'decoder_input_ids': array([16384.,  1304., 15525., 14164.,  7191.,  8173.,  1495., 16147.,\n",
       "         8173.,  2428.,  8173., 14447.,  8173., 14164., 14164.,  1755.,\n",
       "        11605.,  4815.,  2528.,  2528.,  6965.,  3212., 11674.,  9157.,\n",
       "         3547.,  4236.,  5900.,  8493., 14447.,  8447.,  2528., 11605.,\n",
       "        10549.,  2810.,  1989.,  9899.,  4945., 13107.,  1024.,  6204.,\n",
       "        15387.,  8408., 11228.,  8668.,   134.,  1742.,  7504.,  2428.,\n",
       "        11605., 14447.,  7504.,  8493.,  6078., 15881.,  1464.,  8663.,\n",
       "         9296., 15945.,  2813.,  5791., 15703., 15695., 12062.,  2528.,\n",
       "        14447.,  6965.,  2428., 10549.,  6242., 14247., 10278.,  8412.,\n",
       "         1402.,  9470.,  8668.,  1270.,   632., 10956.,   572.,  6965.,\n",
       "         2129.,  6965., 10549.,  9502., 11024., 13293.,  1952.,  8717.,\n",
       "         2813.,  3812., 10805.,   948.,  1270.,  8225.,  3386.,  5657.,\n",
       "         8447., 11196.,  6078.,  9514.,  9819.,  8663., 11196., 12625.,\n",
       "         7106., 11591.,  1227.,  9470.,  4869.,  4635.,  3135.,  4950.,\n",
       "        13769., 11196.,  1989., 11725.,  9753.,  8888.,  6965.,  8202.,\n",
       "         6628.,  6690.,  3804., 13513.,  1586.,  8431.,  7467.,  5071.,\n",
       "         9630., 11196.,  1755., 10561., 12272.,  8888., 12016.,  5509.,\n",
       "        11004.,  8075.,  8888., 11456.,  7191.,  2439.,   699.,  5657.,\n",
       "        15558., 14447.,  7781., 11196.,  6060., 11456., 14703.,  4483.,\n",
       "        15431.,  4945.,  7696.,  5418., 14703., 15963.,  8888., 13579.,\n",
       "         5305.,  7491.,  5401.,  8202.,  1193., 11587.,  2383.,  2105.,\n",
       "         1402.,  1586., 12623.,    66.,  5509.,  7504.,  1635.,  7751.,\n",
       "         1052.,  4147., 10508., 12659.,  6808.,  9131., 14547.,  4483.,\n",
       "         2428.,  2428.,  8612.,  3424.,  5772., 10362.,  4147.,  1755.,\n",
       "        10019.,  4815., 10549.,  2528.,  4465., 10037.,  1464., 11326.,\n",
       "         8867.,  8111.,  7696.,  6348., 12625.,  1702., 11591.,  8493.,\n",
       "        10549.,  6965., 14447.,  2528.,  6078.,  2334.,  8566., 16031.,\n",
       "         7749., 13579.,  7491.,  8408.,  7781.,  9150.,  8075.,  7504.,\n",
       "         2528.,  6965.,  6172.,  6172.,  6889., 14494.,  6348.,  8447.,\n",
       "        10549.,   601., 10549., 11993., 10912., 11725., 12892.,  7504.,\n",
       "        11605., 14853.,  4903.,  6930., 14247., 13769.,  5657., 14247.,\n",
       "         4903.,  4903.,  4099.,  4903., 14247.,  4903., 13769.,  6930.])}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ad91a836-3c99-4a7c-ba41-c73aee375d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(example_preprocessed['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fa800d96-d787-4e91-a5e9-84be343a5b5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16147"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_preprocessed['labels'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "id": "ab333880-f20e-45d3-987c-02c77949f9ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attention_mask': (64,),\n",
       " 'decoder_input_ids': (256,),\n",
       " 'input_ids': (64,),\n",
       " 'labels': (256,)}"
      ]
     },
     "execution_count": 521,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.tree_map(lambda x:x.shape, example_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "3d6d87c4-698d-46b9-a6cf-efea56f36559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask', 'labels', 'decoder_input_ids'])"
      ]
     },
     "execution_count": 516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_preprocessed.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5a0b5a-e33c-4e40-9a0d-ffb6b63cd7b8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### step by step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3b8857-8322-4c00-bdbb-3d2d850bbc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# required config variables, not sure what they are at this time\n",
    "decoder_start_token_id = config.decoder_start_token_id\n",
    "normalize_text = config.normalize_text\n",
    "max_length = config.max_text_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cd3f4b-07c5-480a-a144-a52ef745b5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_start_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf98c88-66cb-4f93-9c28-af795eade90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_text, max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea719a38-6520-47f4-a916-393f6e6b69ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# our data looks like this, caption and its encoding\n",
    "example = next(iter(dataset.train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a347dccd-edb7-461d-b98b-35d6e160998a",
   "metadata": {},
   "outputs": [],
   "source": [
    "example['caption']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23eed47f-6bd8-4f39-b6fc-540b72c5250a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(example['encoding'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0c77e5-5d64-4289-a33a-8fda8ca0d48e",
   "metadata": {},
   "source": [
    "filter datasets - \n",
    "* filter for both `train_dataset` and `eval_dataset`, i will take train_dataset as example\n",
    "* in our case, this step doesn't actually do anything "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f6cf7b-22b7-4764-88ae-0997e3c0ce95",
   "metadata": {},
   "outputs": [],
   "source": [
    "for example in dataset.train_dataset:\n",
    "    if example['clip_score'] is not None:\n",
    "        print(example['clip_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39aa1bc8-044d-41fd-838a-947cfdc4d082",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(dataset.train_dataset), type(dataset.eval_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c649fd2b-d819-4d87-a1a4-b7ed1e0bbac5",
   "metadata": {},
   "source": [
    "for our configuration, this `partial_filter_function` evaluate as \n",
    "\n",
    "```python\n",
    "def filter_function(example):\n",
    "  return True\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1a60c1-de81-46f6-b26a-6587850c4c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.clip_score_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39534aaa-4aeb-4132-8bc9-96bf1923f17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_function(\n",
    "    example,\n",
    "    min_clip_score,\n",
    "    max_clip_score,\n",
    "    clip_score_column,\n",
    "    filter_column,\n",
    "    filter_value,\n",
    "):\n",
    "    if min_clip_score is not None and example[clip_score_column] < min_clip_score:\n",
    "        return False\n",
    "    if max_clip_score is not None and example[clip_score_column] > max_clip_score:\n",
    "        return False\n",
    "    if filter_column is not None and example[filter_column] != filter_value:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "partial_filter_function = partial(\n",
    "            filter_function,\n",
    "            filter_column=None,\n",
    "            filter_value=None,\n",
    "            clip_score_column='clip_score',\n",
    "            min_clip_score=None,\n",
    "            max_clip_score=None,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09315606-e9a3-44de-a70f-488137831f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.train_dataset.filter??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f6cea3-dad4-4bb6-b7b2-5590a303ee33",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.train_dataset.filter(partial_filter_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7a51fe-b9af-477f-b273-8670980e5c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157cbef9-f0c0-4ee0-9916-567f8fe7193f",
   "metadata": {},
   "source": [
    "apply a normalize function to each caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b345399c-ea3c-4d16-9206-79d5dc5e25da",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.text_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9b06d1-4b01-403b-8129-cf6756b5f1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dalle_mini.model.text import TextNormalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb24e016-6246-4d7e-b15a-28102589c057",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_normalizer=TextNormalizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a254c9-e4de-4ea5-8a18-44e0f36cd93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_function(example, text_column, text_normalizer):\n",
    "    example[text_column] = text_normalizer(example[text_column])\n",
    "    return example"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f1a93b0e-10ec-4e34-a386-f8c0382ca856",
   "metadata": {},
   "source": [
    "partial_normalize_function = partial(\n",
    "                normalize_function,\n",
    "                text_column=self.text_column,\n",
    "                text_normalizer=text_normalizer,\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e620c30b-72d8-4164-badd-4eade9055b92",
   "metadata": {},
   "source": [
    "`partial_normalize_function` evaluate as \n",
    "```python\n",
    "def partial_normalize_function(example):\n",
    "    return text_normalizer(example['caption'])\n",
    "```\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693582b4-b4a7-418d-8c91-acdce5010ffe",
   "metadata": {},
   "source": [
    "blank captions??\n",
    "\n",
    "20% of the time, will set the caption to be blank - not sure why"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57c76e0-095d-4c18-87cf-ab144e904b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.blank_caption_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62181c7-764c-485a-b4b1-3aaac2458315",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.np_rng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01c3932-17a3-40d8-b556-df45b23b641f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def blank_caption_function(example, text_column, blank_caption_prob, rng=None):\n",
    "    if (\n",
    "        blank_caption_prob\n",
    "        and (rng.random() if rng is not None else np.random.random())\n",
    "        < blank_caption_prob\n",
    "    ):\n",
    "        example[text_column] = \"\"\n",
    "    return example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96611087-94b9-4774-874e-b185c1d34c03",
   "metadata": {},
   "source": [
    "preprocess_function? \n",
    "\n",
    "partial_preprocess_function takes a batch of exampls as input and return a batch of outputs each contains: \n",
    "* label:  example['encoding']: tok1, tok2, tok3\n",
    "* decoder_input_ids: bos, tok1, tok2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fc07a8-319b-4ef1-94c2-70c8ab40de62",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.text_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64862f3-0939-4a6c-aaed-5c45e0b0cbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.encoding_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c419202a-b2e7-4ddc-9b01-9db34107ce06",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf87f65-e866-4ae6-9e2d-03bdc1152ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_start_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716aec49-3329-4cb6-a290-d4bc056ca0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(\n",
    "    examples,\n",
    "    tokenizer, # passed from train.py\n",
    "    text_column, # 'caption'\n",
    "    encoding_column, #'encoding'\n",
    "    max_length,#64\n",
    "    decoder_start_token_id, # 16384\n",
    "):\n",
    "    inputs = examples[text_column] # caption\n",
    "    # Setting padding=\"max_length\" as we need fixed length inputs for jitted functions\n",
    "    model_inputs = tokenizer(\n",
    "        inputs,\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        return_tensors=\"np\",\n",
    "    )\n",
    "\n",
    "    # set up targets\n",
    "    # Note: labels correspond to our target indices\n",
    "    # decoder input ids are the same but shifted to the right with bos at the beginning (and without last token)\n",
    "    labels = examples[encoding_column]\n",
    "    labels = np.asarray(labels)\n",
    "\n",
    "    # We need the labels, in addition to the decoder_input_ids, for the compute_loss function\n",
    "    model_inputs[\"labels\"] = labels\n",
    "\n",
    "    # In our case, this prepends the bos token and removes the last one\n",
    "    decoder_input_ids = shift_tokens_right(labels, decoder_start_token_id)\n",
    "    model_inputs[\"decoder_input_ids\"] = decoder_input_ids\n",
    "\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6eacaa-ed0e-41fc-b0a1-a1c92ee3ef3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.train_dataset.map??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebbaf9f-ec5a-4244-ac5b-0129dba52941",
   "metadata": {
    "tags": []
   },
   "source": [
    "### calculate training related variables (different batch sizes)\n",
    "\n",
    "num_epochs, different batch sizes, steps_per_epoch, num_train_steps, num_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c880c874-2e8e-4be3-83c3-2a47be0d6278",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_rng = jax.random.PRNGKey(training_args.seed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "58d5f253-5c76-4972-8a57-f6e6b252a1f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = training_args.num_train_epochs\n",
    "num_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1c2df7ff-5079-42e2-971e-5620333f4763",
   "metadata": {},
   "outputs": [],
   "source": [
    " # batch size : batch size (per device) * number of devices // node? \n",
    " # jax.local_device_count() = number of TPU devices\n",
    "batch_size_per_node_per_grad_step = (\n",
    "        training_args.per_device_train_batch_size\n",
    "        * jax.local_device_count()\n",
    "        // training_args.mp_devices\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "54212475-f38c-432e-bf3b-30f057d870d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args.per_device_train_batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f981c5e0-d33c-44c8-a50c-9041ec18e90b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args.mp_devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "efd1f2bf-570f-46fd-83f2-b95fb45bdba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "272"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size_per_node_per_grad_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "822ec37b-a39b-4300-8e7f-39ba134cad3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args.gradient_accumulation_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c2edc433-c6a9-4991-897d-800a4a6ad857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I guess we updated gradient every 3 steps, so the gradient update is calculated based on 3 batches\n",
    "batch_size_per_node = (\n",
    "        batch_size_per_node_per_grad_step * training_args.gradient_accumulation_steps\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4d22a42c-4244-42d4-8f31-0c343e5961dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "816"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size_per_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0397df37-808d-4853-ad58-b0f3e45170d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# jax.process_count = number of nodes? MP?\n",
    "batch_size_per_step = batch_size_per_node * jax.process_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "703bbfac-a5e6-4347-8a74-4eb3e5903c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_batch_size_per_node = (\n",
    "        training_args.per_device_eval_batch_size\n",
    "        * jax.local_device_count()\n",
    "        // training_args.mp_devices\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2e200224-bc8a-401b-8e2f-6eb446e734da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "272"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_batch_size_per_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "350e9ded-36b7-49fa-a36a-d129deacff31",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_batch_size_per_step = eval_batch_size_per_node * jax.process_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b3128f52-b737-433b-b3c2-915de6720941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "09bf1bc2-df19-4dcb-856b-a83281d3bf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_train_dataset, len_eval_dataset = dataset.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "15c94eb6-f634-4ba9-8016-db5fc3c42e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    " steps_per_epoch = (\n",
    "        len_train_dataset // batch_size_per_node\n",
    "        if len_train_dataset is not None\n",
    "        else None\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5141ba65-c88e-49be-a844-885f10498a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# None is our case\n",
    "steps_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "36becb19-b691-4b91-ac7f-ba48acc4b7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# also None is our case\n",
    "num_train_steps = (\n",
    "        steps_per_epoch * num_epochs if steps_per_epoch is not None else None\n",
    "    )\n",
    "num_train_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "901a8945-ffc5-4b4c-9c18-fdcc937aea60",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_params = model.num_params(params_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "793901ed-ac94-4cd3-805d-d68847bf8a69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "437903344"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a3a7ac-39dc-4d08-8005-efb7379e7cd0",
   "metadata": {},
   "source": [
    "logging the ablove info info about model and data to both logging and wandb config with \n",
    "\n",
    "`wandb.config.update({...})`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fc9d87-c679-4ecb-814d-e4da3bbd318f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### create a learning_rate_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5ce414-8f85-49f2-873d-eddbfbe33560",
   "metadata": {},
   "source": [
    "* if lr_offset >0, say for example = 100, there will be 100 steps with 0 learnings before warmup - <font color=red>what is this for?</font>\n",
    "* first 2000 steps linearly warm up ( lr from 0 ~ 0.0001), then constant at 0.0001 - this is our __default setting__\n",
    "* optionally, you can set up exponential or linear decay function for the rest of your training steps \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "740131a0-99b0-41d3-b821-162c2467e3b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0001"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args.learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ea2d3f6a-5cf9-404b-a158-db06ed478210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args.warmup_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "19ee39bc-4184-4e24-8f46-65f7cbf78f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "warmup_fn = optax.linear_schedule(\n",
    "            init_value=0.0,\n",
    "            end_value=training_args.learning_rate,\n",
    "            transition_steps=training_args.warmup_steps + 1,  # ensure not 0\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f3e0351a-2f30-4ef4-912f-ed6ba31c6e54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args.lr_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7d20ede8-cbb8-4ff0-a99a-de5be1524bdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#our num_train_steps is None, so it will have a warmup phase (2000) and then train with 1e-3 forever\n",
    "num_train_steps is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "582f15d8-a7ca-44eb-b3a6-a89b1bf7ad74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args.lr_decay is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8abc9a9b-60d1-48e2-a889-f675055b32e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def create_learning_rate_fn() -> Callable[[int], jnp.array]:\n",
    "        \"\"\"Create the learning rate function.\"\"\"\n",
    "        warmup_fn = optax.linear_schedule(\n",
    "            init_value=0.0,\n",
    "            end_value=training_args.learning_rate,\n",
    "            transition_steps=training_args.warmup_steps + 1,  # ensure not 0\n",
    "        )\n",
    "        last_boundary = training_args.warmup_steps\n",
    "        # offset step when resuming\n",
    "        if training_args.lr_offset:\n",
    "            warmup_fn = optax.join_schedules(\n",
    "                schedules=[optax.constant_schedule(0.0), warmup_fn],\n",
    "                boundaries=[training_args.lr_offset],\n",
    "            )\n",
    "            last_boundary += training_args.lr_offset\n",
    "        if training_args.lr_decay is None:\n",
    "            return warmup_fn\n",
    "        elif training_args.lr_decay == \"linear\":\n",
    "            assert (\n",
    "                num_train_steps is not None\n",
    "            ), \"linear decay requires knowing the dataset length\"\n",
    "            decay_fn = optax.linear_schedule(\n",
    "                init_value=training_args.learning_rate,\n",
    "                end_value=0,\n",
    "                transition_steps=num_train_steps - training_args.warmup_steps,\n",
    "            )\n",
    "        elif training_args.lr_decay == \"exponential\":\n",
    "            decay_fn = optax.exponential_decay(\n",
    "                init_value=training_args.learning_rate,\n",
    "                transition_steps=training_args.lr_transition_steps,\n",
    "                decay_rate=training_args.lr_decay_rate,\n",
    "                staircase=training_args.lr_staircase,\n",
    "            )\n",
    "        schedule_fn = optax.join_schedules(\n",
    "            schedules=[warmup_fn, decay_fn],\n",
    "            boundaries=[last_boundary],\n",
    "        )\n",
    "        return schedule_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b3fe4d92-b4e1-43b6-acae-7881fc95c621",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_fn = create_learning_rate_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cedf39f8-5320-47c4-a65f-2ba46b7ebe50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(1.e-04, dtype=float32, weak_type=True)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try a really large number of steps\n",
    "learning_rate_fn(1000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a52a5d-abdf-4ad4-8ed2-b565f33cc666",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### trainable_params_shape\n",
    "* base config with embedding_only == False, all parameters are trainable : __trainable_params_shape__ is same as __params_shape__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c6d8e41b-a15a-436e-b795-170a708d084f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainable_params(data, embeddings_only):\n",
    "    \"\"\"Keep only trainable parameters\"\"\"\n",
    "\n",
    "    if not embeddings_only:\n",
    "        return data\n",
    "\n",
    "    data = unfreeze(data)\n",
    "    trainable = {\n",
    "        \"lm_head\": data[\"lm_head\"],\n",
    "        \"model\": {\n",
    "            \"decoder\": {\n",
    "                layer: data[\"model\"][\"decoder\"][layer]\n",
    "                for layer in [\n",
    "                    \"embed_positions\",\n",
    "                    \"embed_tokens\",\n",
    "                    \"final_ln\",\n",
    "                    \"layernorm_embedding\",\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "    }\n",
    "    return freeze(trainable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2463de53-a693-4b7f-b5a3-2bb39a58b3e3",
   "metadata": {},
   "source": [
    "if set embedding_only = True, this part of parameters won't be updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e899013a-2401-4189-a658-e749a79342c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainable_params_shape = trainable_params(\n",
    "        params_shape, training_args.embeddings_only\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e0c6bed3-3eed-427f-a878-8328d8d79f56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5177362800, 5177362800)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# actually exact same object\n",
    "id(trainable_params_shape), id(params_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4407e4aa-1308-45b9-8964-bdd6d986af35",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### read about pjit before create optimizer\n",
    "https://jax.readthedocs.io/en/latest/jax-101/08-pjit.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fadca4-1d61-43da-b43f-950adf217ff4",
   "metadata": {},
   "source": [
    "with pmap, we only partition data, i.e. same model are run on each device with a subset of data; but with pjit, we can use it to partition functions as well - we can partition models and have subsets of the model run in parallel across multiple devices \n",
    "\n",
    "parallel model training \n",
    "* model \n",
    "```python\n",
    "        layer1   âž¡ï¸   layer 2 \n",
    "     parameter1  âž¡ï¸   parameter2\n",
    "      [1,2,3]       [4,5,6,7,8,9]\n",
    "\n",
    " device0:[1]              [4,5]\n",
    " device1:[2]              [6,7]\n",
    " device2:[3]              [8,9]\n",
    "    \n",
    "```\n",
    "        \n",
    "* to be clear, we don't partition the layers: all the devices will get all layers in the same sequence\n",
    "* with pjit, we can partition the parameters, so each device will get a subset of model and these models can run in parallel \n",
    "* need to understand more about __how to partition the parameters__? for example, for attention layers, if we partition the sequence length dimension, some tokens will not be able to interact with others? partition the head dimension will probably be ok\n",
    "\n",
    "__pjit__ is the API for for core infrastructure __XLA SPMD partitioner__\n",
    "* SPMD: single program, multiple data?\n",
    "* input: \n",
    "  * function \n",
    "  * partitioning specifications for function inputs - (`in_axis_resources`)\n",
    "  * partitioning specification for outputs (`out_axis_resources`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc15916-7ab4-43f2-80e1-c4116304cff7",
   "metadata": {},
   "source": [
    "what is mesh?\n",
    "\n",
    "the resources specified in these 2 arguments must refer to mesh axis, as defined by the jax jax.experimental.maps.Mesh() context manager.\n",
    "\n",
    "in our case, our mesh axises are: 'dp', 'mp' - the first dimension is data parallelism, second dimension is model parallelism\n",
    "\n",
    "* when we partition the parameters, the \"dp\" axis should always be None (see our param_spec below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a6c1bba3-655b-4ec9-b9d7-5e93df34896b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "jax.tree_leaves(param_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d137fa2-c855-4f50-9bb9-0655b583f929",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.experimental import maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7824b2-b497-4e05-a6a4-3ccba70dec9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data parallelism, model parallelism\n",
    "# pjit is normally used on tpu pod slice, i.e. multiple tpu next to each other (32 devices or so)\n",
    "# but you can still use pjit with 1 tpu (8 devices), here we do 4x2\n",
    "mesh_shape = (training_args.dp_devices, training_args.mp_devices)\n",
    "devices = np.asarray(jax.devices()).reshape(*mesh_shape)\n",
    "devices, devices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee3ea31-6c49-4f7e-804f-cd5de70e6e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mp: model parallelism\n",
    "# it is specified in argument \n",
    "training_args.mp_devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "971b33e8-b207-4f25-b768-586e6b7d1aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dp: data parallelism: \n",
    "# it is calculated by number of total devices divided by mp\n",
    "training_args.dp_devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5513b677-3efa-4931-b769-6728bbda0d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "jax.device_count() // training_args.mp_devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e190b4cd-adef-44e0-963b-39a4871e7f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = maps.Mesh(devices, (\"dp\", \"mp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9335b237-3fec-4a83-8375-eba7940912c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31de0878-940b-4635-8bde-d76a6f3ae169",
   "metadata": {},
   "source": [
    "Inputs to a pjitted function will be __automatically partitioned__ across __devices__ if theyâ€™re not already correctly partitioned based on __in_axis_resources.__\n",
    "\n",
    "* in dalle-mini example, \n",
    "  * we pjitted the function to create the initial trainstate it is called inside train_step function\n",
    "  * train_step is also pjitted \n",
    "```python\n",
    "def init_state(params):\n",
    "    return TrainState.create(...)\n",
    "\n",
    "state = pjit(init_state,\n",
    "             in_axis_resources=(param_spec,)\n",
    "             None,\n",
    "             out_axis_resources=state_spec,\n",
    "             donate_argnums=(0,),)(params)\n",
    "  \n",
    "def train_step(state, batch, train_time):\n",
    "    ...\n",
    "    return state, metrics\n",
    "                    \n",
    "p_train_step = pjit(\n",
    "    train_step,\n",
    "    in_axis_resources=(state_spec,batch_spec,None,),\n",
    "    out_axis_resources=(state_spec, None),\n",
    "    donate_argnums=(0,),\n",
    "    )\n",
    "\n",
    "state, train_metrics = p_train_step(state, batch, train_time)\n",
    "```\n",
    "\n",
    "read more about buffer donation https://jax.readthedocs.io/en/latest/faq.html#buffer-donation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5a0de1-19a0-4a9e-bf7b-35a0930f0b6c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### create optimizer: distributed_shampoo -> opt, statistics_partition_spec\n",
    "\n",
    "* __opt__ is a GradientTransformation object, just like other optimizers we pass as tx to TrainState; however, it is used differentl for pjit mode (more on this in next section)\n",
    "* __statistics_partition_spec__ is the PartitionSpec for shampoo's statistics - not sure how it is used "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6bc62cb0-c0b9-4c7b-8633-82dd292b0482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'distributed_shampoo'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shampoo is a second-order optimizer \n",
    "training_args.optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7533ad56-17e9-470b-b34c-b6a68c10d7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.train.scalable_shampoo.distributed_shampoo import GraftingType, distributed_shampoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a728b56c-712b-4d9a-873f-517ef430ba4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<enum 'GraftingType'>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GraftingType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d32c8b23-1231-4e72-97b0-4b52cb774ff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rmsprop_normalized'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args.graft_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d57196c4-5429-479e-8a40-8c3d28a70a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# graft_type - not sure what this is \n",
    "graft_type = {\n",
    "            \"sgd\": GraftingType.SGD,\n",
    "            \"adagrad\": GraftingType.ADAGRAD,\n",
    "            \"rmsprop\": GraftingType.RMSPROP,\n",
    "            \"rmsprop_normalized\": GraftingType.RMSPROP_NORMALIZED,\n",
    "            \"sqrt_n\": GraftingType.SQRT_N,\n",
    "            \"adagrad_normalized\": GraftingType.ADAGRAD_NORMALIZED,\n",
    "        }[training_args.graft_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6128e918-04a8-4c21-9a4e-ccf9b29cb452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<GraftingType.RMSPROP_NORMALIZED: 4>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graft_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9bf33333-08c6-4592-a5c7-757eb2016faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.experimental import PartitionSpec, maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d96b5a05-b811-48ae-8754-eb9310bfcc22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dp'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shard across dp - what does this mean?\n",
    "training_args.shard_shampoo_across "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5578b4f3-974e-48f1-8bf3-79a3b7dbba5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create statistics_partition_spec\n",
    "# I'm not sure how it is used\n",
    "statistics_partition_spec = (\n",
    "            PartitionSpec(None, training_args.shard_shampoo_across, None)\n",
    "            if training_args.shard_shampoo_across != \"2d\"\n",
    "            else PartitionSpec(None, \"dp\", \"mp\")\n",
    "        )\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4526bf4e-d61a-4913-8c95-d36ed17b039c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PartitionSpec(None, 'dp', None)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statistics_partition_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "cc74f195-1b0e-4404-97e8-6d54ed13d1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arguments to create `distributed_shampoo`\n",
    "opt = distributed_shampoo(\n",
    "            learning_rate_fn,\n",
    "            block_size=training_args.block_size,\n",
    "            beta1=training_args.beta1,\n",
    "            beta2=training_args.beta2,\n",
    "            diagonal_epsilon=1e-10,\n",
    "            matrix_epsilon=1e-6,\n",
    "            weight_decay=training_args.weight_decay,\n",
    "            start_preconditioning_step=max(\n",
    "                training_args.preconditioning_compute_steps + 1, 101\n",
    "            ),\n",
    "            preconditioning_compute_steps=training_args.preconditioning_compute_steps,\n",
    "            statistics_compute_steps=1,\n",
    "            best_effort_shape_interpretation=True,\n",
    "            graft_type=graft_type,\n",
    "            nesterov=training_args.nesterov,\n",
    "            exponent_override=0,\n",
    "            statistics_partition_spec=statistics_partition_spec,\n",
    "            preconditioner_partition_spec=PartitionSpec(\n",
    "                training_args.shard_shampoo_across, None, None\n",
    "            )\n",
    "            if training_args.shard_shampoo_across != \"2d\"\n",
    "            else PartitionSpec(\n",
    "                \"mp\" if training_args.mp_devices > training_args.dp_devices else \"dp\",\n",
    "                None,\n",
    "                None,\n",
    "            ),\n",
    "            num_devices_for_pjit=training_args.dp_devices,\n",
    "            shard_optimizer_states=True,\n",
    "            inverse_failure_threshold=0.1,\n",
    "            moving_average_for_momentum=True,\n",
    "            skip_preconditioning_dim_size_gt=training_args.skip_preconditioning_dim_size_gt,\n",
    "            clip_by_scaled_gradient_norm=None,\n",
    "            precision=jax.lax.Precision.HIGHEST,\n",
    "            best_effort_memory_usage_reduction=training_args.optim_quantized,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b9034eba-0101-44f0-8640-10eef6090cb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what is this? chucked size for large layers with distributed shampoo\n",
    "training_args.block_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5a09e945-234c-4002-b33d-3959706d688a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args.preconditioning_compute_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "af17f7e1-5b6c-4d86-82a5-1925288b83e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientTransformation(init=<function distributed_shampoo.<locals>._init_fns at 0x145bf23b0>, update=<function distributed_shampoo.<locals>.sharded_update_fn at 0x145bf1510>)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1f8b9f-2bc4-4adb-a6e4-63f3262b5b6b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### optimizers for different parameter groups ->  `optimizer` {} and `opt_fn` {}\n",
    "\n",
    "* __optimizer {}__ contains optimizers, i.e. GradientTransformation, which you can use to create initial optimizer state (__init__ function) , or update optimizer state (__update__ function)\n",
    "* __opt_fn {}__ contains \n",
    "  * __pspec_fn__: function to create partitioan specs for optimizer state \n",
    "  * shape_and_dtype_fn: not sure what's this for yet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c4ebccd2-d08d-4e7f-9b63-66710cc06ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_fn = opt.update\n",
    "optimizer = {}\n",
    "opt_fn = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761bec2c-0f96-4780-949b-47349b88663e",
   "metadata": {},
   "source": [
    "__split_params?__\n",
    "\n",
    "what does this do? `split_params(trainable_params_shape)` \n",
    "\n",
    "it split the parameters into 3 groups: \"standard\", \"scanned_encoder\", \"scanned_decoder\"\n",
    "\n",
    " * FlaxBartEncoderLayers -> scanned_encoder\n",
    " * FlaxBartDecoderLayers -> scanned_decoder\n",
    " * everything else -> standard\n",
    " \n",
    "the result is a dict contain all 3 parameter groups, you can access with keys standard, scanned_encoder and scanned_decoder; we then create optimizers for each parameter group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "364ccdd7-452b-4342-9e62-6d752580aeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_params(data):\n",
    "    \"\"\"Split params between scanned and non-scanned\"\"\"\n",
    "    flat = traverse_util.flatten_dict(unfreeze(data))\n",
    "    split = {\"standard\": {}, \"scanned_encoder\": {}, \"scanned_decoder\": {}}\n",
    "    for k, v in flat.items():\n",
    "        if \"FlaxBartEncoderLayers\" in k:\n",
    "            split[\"scanned_encoder\"][k] = v\n",
    "        elif \"FlaxBartDecoderLayers\" in k:\n",
    "            split[\"scanned_decoder\"][k] = v\n",
    "        else:\n",
    "            split[\"standard\"][k] = v\n",
    "    # remove empty keys\n",
    "    split = {k: v for k, v in split.items() if v}\n",
    "    for k, v in split.items():\n",
    "        split[k] = freeze(traverse_util.unflatten_dict(v))\n",
    "    return split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f2b8aacb-836f-489b-8018-931e53759019",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'standard': FrozenDict({\n",
       "     lm_head: {\n",
       "         kernel: ShapeDtypeStruct(shape=(1024, 16401), dtype=float32),\n",
       "     },\n",
       "     model: {\n",
       "         decoder: {\n",
       "             embed_positions: {\n",
       "                 embedding: ShapeDtypeStruct(shape=(256, 1024), dtype=float32),\n",
       "             },\n",
       "             embed_tokens: {\n",
       "                 embedding: ShapeDtypeStruct(shape=(16401, 1024), dtype=float32),\n",
       "             },\n",
       "             final_ln: {\n",
       "                 bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "             },\n",
       "             layernorm_embedding: {\n",
       "                 bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                 scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "             },\n",
       "             layers: {\n",
       "                 FlaxBartDecoderLayer_0: {\n",
       "                     FlaxBartAttention_0: {\n",
       "                         k_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         out_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         q_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         v_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                     },\n",
       "                     FlaxBartAttention_1: {\n",
       "                         k_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         out_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         q_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         v_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                     },\n",
       "                     GLU_0: {\n",
       "                         Dense_0: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                         },\n",
       "                         Dense_1: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                         },\n",
       "                         Dense_2: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                         },\n",
       "                         LayerNorm_0: {\n",
       "                             bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                         },\n",
       "                         LayerNorm_1: {\n",
       "                             bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                         },\n",
       "                     },\n",
       "                     LayerNorm_0: {\n",
       "                         bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                     },\n",
       "                     LayerNorm_1: {\n",
       "                         bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                         scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                     },\n",
       "                     LayerNorm_2: {\n",
       "                         bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                     },\n",
       "                     LayerNorm_3: {\n",
       "                         bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                         scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                     },\n",
       "                 },\n",
       "                 FlaxBartDecoderLayer_1: {\n",
       "                     FlaxBartAttention_0: {\n",
       "                         k_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         out_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         q_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         v_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                     },\n",
       "                     FlaxBartAttention_1: {\n",
       "                         k_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         out_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         q_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         v_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                     },\n",
       "                     GLU_0: {\n",
       "                         Dense_0: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                         },\n",
       "                         Dense_1: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                         },\n",
       "                         Dense_2: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                         },\n",
       "                         LayerNorm_0: {\n",
       "                             bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                         },\n",
       "                         LayerNorm_1: {\n",
       "                             bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                         },\n",
       "                     },\n",
       "                     LayerNorm_0: {\n",
       "                         bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                     },\n",
       "                     LayerNorm_1: {\n",
       "                         bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                         scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                     },\n",
       "                     LayerNorm_2: {\n",
       "                         bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                     },\n",
       "                     LayerNorm_3: {\n",
       "                         bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                         scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                     },\n",
       "                 },\n",
       "                 FlaxBartDecoderLayer_10: {\n",
       "                     FlaxBartAttention_0: {\n",
       "                         k_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         out_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         q_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         v_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                     },\n",
       "                     FlaxBartAttention_1: {\n",
       "                         k_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         out_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         q_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         v_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                     },\n",
       "                     GLU_0: {\n",
       "                         Dense_0: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                         },\n",
       "                         Dense_1: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                         },\n",
       "                         Dense_2: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                         },\n",
       "                         LayerNorm_0: {\n",
       "                             bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                         },\n",
       "                         LayerNorm_1: {\n",
       "                             bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                         },\n",
       "                     },\n",
       "                     LayerNorm_0: {\n",
       "                         bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                     },\n",
       "                     LayerNorm_1: {\n",
       "                         bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                         scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                     },\n",
       "                     LayerNorm_2: {\n",
       "                         bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                     },\n",
       "                     LayerNorm_3: {\n",
       "                         bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                         scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                     },\n",
       "                 },\n",
       "                 FlaxBartDecoderLayer_11: {\n",
       "                     FlaxBartAttention_0: {\n",
       "                         k_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         out_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         q_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         v_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                     },\n",
       "                     FlaxBartAttention_1: {\n",
       "                         k_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         out_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         q_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         v_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                     },\n",
       "                     GLU_0: {\n",
       "                         Dense_0: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                         },\n",
       "                         Dense_1: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                         },\n",
       "                         Dense_2: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                         },\n",
       "                         LayerNorm_0: {\n",
       "                             bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                         },\n",
       "                         LayerNorm_1: {\n",
       "                             bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                         },\n",
       "                     },\n",
       "                     LayerNorm_0: {\n",
       "                         bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                     },\n",
       "                     LayerNorm_1: {\n",
       "                         bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                         scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                     },\n",
       "                     LayerNorm_2: {\n",
       "                         bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                     },\n",
       "                     LayerNorm_3: {\n",
       "                         bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                         scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                     },\n",
       "                 },\n",
       "                 FlaxBartDecoderLayer_2: {\n",
       "                     FlaxBartAttention_0: {\n",
       "                         k_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         out_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         q_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         v_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                     },\n",
       "                     FlaxBartAttention_1: {\n",
       "                         k_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         out_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         q_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         v_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                     },\n",
       "                     GLU_0: {\n",
       "                         Dense_0: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                         },\n",
       "                         Dense_1: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                         },\n",
       "                         Dense_2: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                         },\n",
       "                         LayerNorm_0: {\n",
       "                             bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                         },\n",
       "                         LayerNorm_1: {\n",
       "                             bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                         },\n",
       "                     },\n",
       "                     LayerNorm_0: {\n",
       "                         bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                     },\n",
       "                     LayerNorm_1: {\n",
       "                         bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                         scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                     },\n",
       "                     LayerNorm_2: {\n",
       "                         bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                     },\n",
       "                     LayerNorm_3: {\n",
       "                         bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                         scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                     },\n",
       "                 },\n",
       "                 FlaxBartDecoderLayer_3: {\n",
       "                     FlaxBartAttention_0: {\n",
       "                         k_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         out_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         q_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         v_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                     },\n",
       "                     FlaxBartAttention_1: {\n",
       "                         k_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         out_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         q_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         v_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                     },\n",
       "                     GLU_0: {\n",
       "                         Dense_0: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                         },\n",
       "                         Dense_1: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                         },\n",
       "                         Dense_2: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                         },\n",
       "                         LayerNorm_0: {\n",
       "                             bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                         },\n",
       "                         LayerNorm_1: {\n",
       "                             bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                         },\n",
       "                     },\n",
       "                     LayerNorm_0: {\n",
       "                         bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                     },\n",
       "                     LayerNorm_1: {\n",
       "                         bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                         scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                     },\n",
       "                     LayerNorm_2: {\n",
       "                         bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                     },\n",
       "                     LayerNorm_3: {\n",
       "                         bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                         scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                     },\n",
       "                 },\n",
       "                 FlaxBartDecoderLayer_4: {\n",
       "                     FlaxBartAttention_0: {\n",
       "                         k_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         out_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         q_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         v_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                     },\n",
       "                     FlaxBartAttention_1: {\n",
       "                         k_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         out_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         q_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         v_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                     },\n",
       "                     GLU_0: {\n",
       "                         Dense_0: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                         },\n",
       "                         Dense_1: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                         },\n",
       "                         Dense_2: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                         },\n",
       "                         LayerNorm_0: {\n",
       "                             bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                         },\n",
       "                         LayerNorm_1: {\n",
       "                             bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                         },\n",
       "                     },\n",
       "                     LayerNorm_0: {\n",
       "                         bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                     },\n",
       "                     LayerNorm_1: {\n",
       "                         bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                         scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                     },\n",
       "                     LayerNorm_2: {\n",
       "                         bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                     },\n",
       "                     LayerNorm_3: {\n",
       "                         bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                         scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                     },\n",
       "                 },\n",
       "                 FlaxBartDecoderLayer_5: {\n",
       "                     FlaxBartAttention_0: {\n",
       "                         k_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         out_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         q_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         v_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                     },\n",
       "                     FlaxBartAttention_1: {\n",
       "                         k_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         out_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         q_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         v_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                     },\n",
       "                     GLU_0: {\n",
       "                         Dense_0: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                         },\n",
       "                         Dense_1: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                         },\n",
       "                         Dense_2: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                         },\n",
       "                         LayerNorm_0: {\n",
       "                             bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                         },\n",
       "                         LayerNorm_1: {\n",
       "                             bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                         },\n",
       "                     },\n",
       "                     LayerNorm_0: {\n",
       "                         bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                     },\n",
       "                     LayerNorm_1: {\n",
       "                         bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                         scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                     },\n",
       "                     LayerNorm_2: {\n",
       "                         bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                     },\n",
       "                     LayerNorm_3: {\n",
       "                         bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                         scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                     },\n",
       "                 },\n",
       "                 FlaxBartDecoderLayer_6: {\n",
       "                     FlaxBartAttention_0: {\n",
       "                         k_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         out_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         q_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         v_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                     },\n",
       "                     FlaxBartAttention_1: {\n",
       "                         k_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         out_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         q_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         v_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                     },\n",
       "                     GLU_0: {\n",
       "                         Dense_0: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                         },\n",
       "                         Dense_1: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                         },\n",
       "                         Dense_2: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                         },\n",
       "                         LayerNorm_0: {\n",
       "                             bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                         },\n",
       "                         LayerNorm_1: {\n",
       "                             bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                         },\n",
       "                     },\n",
       "                     LayerNorm_0: {\n",
       "                         bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                     },\n",
       "                     LayerNorm_1: {\n",
       "                         bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                         scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                     },\n",
       "                     LayerNorm_2: {\n",
       "                         bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                     },\n",
       "                     LayerNorm_3: {\n",
       "                         bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                         scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                     },\n",
       "                 },\n",
       "                 FlaxBartDecoderLayer_7: {\n",
       "                     FlaxBartAttention_0: {\n",
       "                         k_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         out_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         q_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         v_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                     },\n",
       "                     FlaxBartAttention_1: {\n",
       "                         k_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         out_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         q_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         v_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                     },\n",
       "                     GLU_0: {\n",
       "                         Dense_0: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                         },\n",
       "                         Dense_1: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                         },\n",
       "                         Dense_2: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                         },\n",
       "                         LayerNorm_0: {\n",
       "                             bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                         },\n",
       "                         LayerNorm_1: {\n",
       "                             bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                         },\n",
       "                     },\n",
       "                     LayerNorm_0: {\n",
       "                         bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                     },\n",
       "                     LayerNorm_1: {\n",
       "                         bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                         scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                     },\n",
       "                     LayerNorm_2: {\n",
       "                         bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                     },\n",
       "                     LayerNorm_3: {\n",
       "                         bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                         scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                     },\n",
       "                 },\n",
       "                 FlaxBartDecoderLayer_8: {\n",
       "                     FlaxBartAttention_0: {\n",
       "                         k_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         out_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         q_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         v_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                     },\n",
       "                     FlaxBartAttention_1: {\n",
       "                         k_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         out_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         q_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         v_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                     },\n",
       "                     GLU_0: {\n",
       "                         Dense_0: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                         },\n",
       "                         Dense_1: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                         },\n",
       "                         Dense_2: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                         },\n",
       "                         LayerNorm_0: {\n",
       "                             bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                         },\n",
       "                         LayerNorm_1: {\n",
       "                             bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                         },\n",
       "                     },\n",
       "                     LayerNorm_0: {\n",
       "                         bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                     },\n",
       "                     LayerNorm_1: {\n",
       "                         bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                         scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                     },\n",
       "                     LayerNorm_2: {\n",
       "                         bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                     },\n",
       "                     LayerNorm_3: {\n",
       "                         bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                         scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                     },\n",
       "                 },\n",
       "                 FlaxBartDecoderLayer_9: {\n",
       "                     FlaxBartAttention_0: {\n",
       "                         k_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         out_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         q_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         v_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                     },\n",
       "                     FlaxBartAttention_1: {\n",
       "                         k_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         out_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         q_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         v_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                     },\n",
       "                     GLU_0: {\n",
       "                         Dense_0: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                         },\n",
       "                         Dense_1: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                         },\n",
       "                         Dense_2: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                         },\n",
       "                         LayerNorm_0: {\n",
       "                             bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                         },\n",
       "                         LayerNorm_1: {\n",
       "                             bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                         },\n",
       "                     },\n",
       "                     LayerNorm_0: {\n",
       "                         bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                     },\n",
       "                     LayerNorm_1: {\n",
       "                         bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                         scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                     },\n",
       "                     LayerNorm_2: {\n",
       "                         bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                     },\n",
       "                     LayerNorm_3: {\n",
       "                         bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                         scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                     },\n",
       "                 },\n",
       "             },\n",
       "         },\n",
       "         encoder: {\n",
       "             embed_positions: {\n",
       "                 embedding: ShapeDtypeStruct(shape=(64, 1024), dtype=float32),\n",
       "             },\n",
       "             embed_tokens: {\n",
       "                 embedding: ShapeDtypeStruct(shape=(50300, 1024), dtype=float32),\n",
       "             },\n",
       "             final_ln: {\n",
       "                 bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "             },\n",
       "             layernorm_embedding: {\n",
       "                 bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                 scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "             },\n",
       "             layers: {\n",
       "                 FlaxBartEncoderLayer_0: {\n",
       "                     FlaxBartAttention_0: {\n",
       "                         k_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         out_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         q_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         v_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                     },\n",
       "                     GLU_0: {\n",
       "                         Dense_0: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                         },\n",
       "                         Dense_1: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                         },\n",
       "                         Dense_2: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                         },\n",
       "                         LayerNorm_0: {\n",
       "                             bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                         },\n",
       "                         LayerNorm_1: {\n",
       "                             bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                         },\n",
       "                     },\n",
       "                     LayerNorm_0: {\n",
       "                         bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                     },\n",
       "                     LayerNorm_1: {\n",
       "                         bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                         scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                     },\n",
       "                 },\n",
       "                 FlaxBartEncoderLayer_1: {\n",
       "                     FlaxBartAttention_0: {\n",
       "                         k_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         out_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         q_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         v_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                     },\n",
       "                     GLU_0: {\n",
       "                         Dense_0: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                         },\n",
       "                         Dense_1: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                         },\n",
       "                         Dense_2: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                         },\n",
       "                         LayerNorm_0: {\n",
       "                             bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                         },\n",
       "                         LayerNorm_1: {\n",
       "                             bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                         },\n",
       "                     },\n",
       "                     LayerNorm_0: {\n",
       "                         bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                     },\n",
       "                     LayerNorm_1: {\n",
       "                         bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                         scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                     },\n",
       "                 },\n",
       "                 FlaxBartEncoderLayer_10: {\n",
       "                     FlaxBartAttention_0: {\n",
       "                         k_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         out_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         q_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         v_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                     },\n",
       "                     GLU_0: {\n",
       "                         Dense_0: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                         },\n",
       "                         Dense_1: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                         },\n",
       "                         Dense_2: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                         },\n",
       "                         LayerNorm_0: {\n",
       "                             bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                         },\n",
       "                         LayerNorm_1: {\n",
       "                             bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                         },\n",
       "                     },\n",
       "                     LayerNorm_0: {\n",
       "                         bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                     },\n",
       "                     LayerNorm_1: {\n",
       "                         bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                         scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                     },\n",
       "                 },\n",
       "                 FlaxBartEncoderLayer_11: {\n",
       "                     FlaxBartAttention_0: {\n",
       "                         k_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         out_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         q_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         v_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                     },\n",
       "                     GLU_0: {\n",
       "                         Dense_0: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                         },\n",
       "                         Dense_1: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                         },\n",
       "                         Dense_2: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                         },\n",
       "                         LayerNorm_0: {\n",
       "                             bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                         },\n",
       "                         LayerNorm_1: {\n",
       "                             bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                         },\n",
       "                     },\n",
       "                     LayerNorm_0: {\n",
       "                         bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                     },\n",
       "                     LayerNorm_1: {\n",
       "                         bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                         scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                     },\n",
       "                 },\n",
       "                 FlaxBartEncoderLayer_2: {\n",
       "                     FlaxBartAttention_0: {\n",
       "                         k_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         out_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         q_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         v_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                     },\n",
       "                     GLU_0: {\n",
       "                         Dense_0: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                         },\n",
       "                         Dense_1: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                         },\n",
       "                         Dense_2: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                         },\n",
       "                         LayerNorm_0: {\n",
       "                             bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                         },\n",
       "                         LayerNorm_1: {\n",
       "                             bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                         },\n",
       "                     },\n",
       "                     LayerNorm_0: {\n",
       "                         bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                     },\n",
       "                     LayerNorm_1: {\n",
       "                         bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                         scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                     },\n",
       "                 },\n",
       "                 FlaxBartEncoderLayer_3: {\n",
       "                     FlaxBartAttention_0: {\n",
       "                         k_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         out_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         q_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         v_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                     },\n",
       "                     GLU_0: {\n",
       "                         Dense_0: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                         },\n",
       "                         Dense_1: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                         },\n",
       "                         Dense_2: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                         },\n",
       "                         LayerNorm_0: {\n",
       "                             bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                         },\n",
       "                         LayerNorm_1: {\n",
       "                             bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                         },\n",
       "                     },\n",
       "                     LayerNorm_0: {\n",
       "                         bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                     },\n",
       "                     LayerNorm_1: {\n",
       "                         bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                         scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                     },\n",
       "                 },\n",
       "                 FlaxBartEncoderLayer_4: {\n",
       "                     FlaxBartAttention_0: {\n",
       "                         k_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         out_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         q_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         v_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                     },\n",
       "                     GLU_0: {\n",
       "                         Dense_0: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                         },\n",
       "                         Dense_1: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                         },\n",
       "                         Dense_2: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                         },\n",
       "                         LayerNorm_0: {\n",
       "                             bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                         },\n",
       "                         LayerNorm_1: {\n",
       "                             bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                         },\n",
       "                     },\n",
       "                     LayerNorm_0: {\n",
       "                         bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                     },\n",
       "                     LayerNorm_1: {\n",
       "                         bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                         scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                     },\n",
       "                 },\n",
       "                 FlaxBartEncoderLayer_5: {\n",
       "                     FlaxBartAttention_0: {\n",
       "                         k_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         out_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         q_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         v_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                     },\n",
       "                     GLU_0: {\n",
       "                         Dense_0: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                         },\n",
       "                         Dense_1: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                         },\n",
       "                         Dense_2: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                         },\n",
       "                         LayerNorm_0: {\n",
       "                             bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                         },\n",
       "                         LayerNorm_1: {\n",
       "                             bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                         },\n",
       "                     },\n",
       "                     LayerNorm_0: {\n",
       "                         bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                     },\n",
       "                     LayerNorm_1: {\n",
       "                         bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                         scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                     },\n",
       "                 },\n",
       "                 FlaxBartEncoderLayer_6: {\n",
       "                     FlaxBartAttention_0: {\n",
       "                         k_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         out_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         q_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         v_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                     },\n",
       "                     GLU_0: {\n",
       "                         Dense_0: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                         },\n",
       "                         Dense_1: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                         },\n",
       "                         Dense_2: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                         },\n",
       "                         LayerNorm_0: {\n",
       "                             bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                         },\n",
       "                         LayerNorm_1: {\n",
       "                             bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                         },\n",
       "                     },\n",
       "                     LayerNorm_0: {\n",
       "                         bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                     },\n",
       "                     LayerNorm_1: {\n",
       "                         bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                         scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                     },\n",
       "                 },\n",
       "                 FlaxBartEncoderLayer_7: {\n",
       "                     FlaxBartAttention_0: {\n",
       "                         k_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         out_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         q_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         v_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                     },\n",
       "                     GLU_0: {\n",
       "                         Dense_0: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                         },\n",
       "                         Dense_1: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                         },\n",
       "                         Dense_2: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                         },\n",
       "                         LayerNorm_0: {\n",
       "                             bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                         },\n",
       "                         LayerNorm_1: {\n",
       "                             bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                         },\n",
       "                     },\n",
       "                     LayerNorm_0: {\n",
       "                         bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                     },\n",
       "                     LayerNorm_1: {\n",
       "                         bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                         scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                     },\n",
       "                 },\n",
       "                 FlaxBartEncoderLayer_8: {\n",
       "                     FlaxBartAttention_0: {\n",
       "                         k_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         out_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         q_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         v_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                     },\n",
       "                     GLU_0: {\n",
       "                         Dense_0: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                         },\n",
       "                         Dense_1: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                         },\n",
       "                         Dense_2: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                         },\n",
       "                         LayerNorm_0: {\n",
       "                             bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                         },\n",
       "                         LayerNorm_1: {\n",
       "                             bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                         },\n",
       "                     },\n",
       "                     LayerNorm_0: {\n",
       "                         bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                     },\n",
       "                     LayerNorm_1: {\n",
       "                         bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                         scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                     },\n",
       "                 },\n",
       "                 FlaxBartEncoderLayer_9: {\n",
       "                     FlaxBartAttention_0: {\n",
       "                         k_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         out_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         q_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                         v_proj: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                         },\n",
       "                     },\n",
       "                     GLU_0: {\n",
       "                         Dense_0: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                         },\n",
       "                         Dense_1: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                         },\n",
       "                         Dense_2: {\n",
       "                             kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                         },\n",
       "                         LayerNorm_0: {\n",
       "                             bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                         },\n",
       "                         LayerNorm_1: {\n",
       "                             bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                         },\n",
       "                     },\n",
       "                     LayerNorm_0: {\n",
       "                         bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                     },\n",
       "                     LayerNorm_1: {\n",
       "                         bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                         scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                     },\n",
       "                 },\n",
       "             },\n",
       "         },\n",
       "     },\n",
       " })}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_params(trainable_params_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9719ab7-e159-46e6-8fe7-2517a12a39db",
   "metadata": {},
   "source": [
    "In general, optimizer is a __GradientTransformation__ object, it contains <u>a pair of functions</u>, __init__ and __update__\n",
    "\n",
    "for __distributed_shampoo__, its __init__ function (__opt.init__) has same signature, i.e. __opt.init(params)-> opt_state__, but needs to be used differently, depends on using it in pjit or pmap mode, you need to get the appropriate init function from __opt.init(params).init__ (instead of __opt.init__ directly)\n",
    "* so, you will need to first use __opt.init(params)__ to create an optimizer state object, which contains the __appropriate init__ function that you can use to create actual initial opt_state \n",
    "* the init function for pjit is __sharded_init_fn__\n",
    "* __<font color=red>how to use this pjit init function??</font>__\n",
    "  * it has same signature: __init(params) -> initial opt_state__\n",
    "  * __input__ is __params__ , however, for scanned layers, it expects the parameters without the additional dimension, so you need either remove the dimension from data or __vmap the init function__\n",
    "  * __output__ is the __initial opt state__ (__ShampooState__)\n",
    "  * for __example__, this is how we find out the shape of initial optimizer state with jax.eval_shape\n",
    "```python\n",
    "opt_state_shape = {}\n",
    "for k, p in split_params(trainable_params_shape).items():\n",
    "    if \"scanned\" not in k:\n",
    "        opt_state_shape[k] = jax.eval_shape(optimizer[k].init, p)\n",
    "    else:\n",
    "        opt_state_shape[k] = jax.eval_shape(jax.vmap(optimizer[k].init), p)\n",
    "```\n",
    "  \n",
    "\n",
    "\n",
    "all 3 optimizers has same __update__ function; but the __init__ function is created seperately for different parameter groups in dalle-mini's code\n",
    "   * i.e. for each parameter group __p__ ->  __opt.init(p).init_fn__\n",
    "   * for __parameters in scanned layers__ , it <u>remove the first dimension</u> before we apply __opt.init()__ on it - I don't think this step is needed, the parameters are unused in the function, but makes it more readable I guess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "56f4c5bd-3200-4773-8050-54a820427d90",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for k, p in split_params(trainable_params_shape).items():\n",
    "            if \"scanned\" in k:\n",
    "            # for scanned_encoder and scanned_decoder, remove the first dimension from shapes\n",
    "                p = jax.eval_shape(\n",
    "                    lambda x: jax.tree_util.tree_map(lambda y: y[0], x), p\n",
    "                )\n",
    "            # opt.init(parameters) -> \n",
    "            optimizer[k] = opt.init(p)\n",
    "            opt_fn[k] = NamedTuple(\"opt_fn\", pspec_fn=Any, shape_and_dtype_fn=Any)(\n",
    "                optimizer[k].pspec_fn, optimizer[k].shape_and_dtype_fn\n",
    "            )\n",
    "            optimizer[k] = optax.GradientTransformation(optimizer[k].init_fn, update_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd43ddc-265f-4e92-a8c6-9c497e1e72fe",
   "metadata": {},
   "source": [
    "How __optimizer{}__ and __opt_fn{}__ dict is created \n",
    "```python\n",
    "                                            opt.update\n",
    "                                                â¬‡\n",
    "p->opt.init()-> opt_state ->init_fn -> GradientTransformation -> optimizer{}\n",
    "                     â¬‡            \n",
    "              (pspec_fn, shape_and_dtype_fn)\n",
    "                     â¬‡\n",
    "                   opt_fn{}\n",
    " ```\n",
    "                                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d51c938-4f08-4585-bb94-43dd293d7c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# an example\n",
    "# take the standard/unscanned parameter group as example\n",
    "p = split_params(trainable_params_shape)['standard']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067e9c8e-34c9-4967-8294-119a506fed66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first step is to use shampoo.init to get an InitFnState object, \n",
    "# that contains the appropriate init functions that we can use to create initial opt state\n",
    "opt.init??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb09f820-245a-4a1d-8ccf-6af1dd947b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539ac6cb-5fba-4fa3-99bf-741650b64579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# InitFnState\n",
    "opt.init(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f09cf6-6d7f-474d-a63a-fff5ff85c60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the init function we need to create the initial optimizer state (ShampooState)\n",
    "opt.init(p).init_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58524a5-7c28-4b39-b16d-5cda6395bb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# didn't work - because p here is not actually parameter - it is the shapes of parameters\n",
    "# opt.init(p).init_fn(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa38083-12e2-44f1-8412-056c6adf35fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# however this will work, more on eval_shape in next section\n",
    "# jax.eval_shape(opt.init(p).init_fn, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435c2d17-770c-457b-bab7-cbdb46055db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all 3 GrandientTransformation object actually have same init and update function? same?\n",
    "id(optimizer['standard'].init),id(optimizer['scanned_encoder'].init),id(optimizer['scanned_decoder'].init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a4b533-d0c2-49b1-b781-23242fe4ae9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer is a dict of gradienttransformation\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08061efa-abbb-4948-a9c6-a8734b619ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt_fn is a dict of opt_fn\n",
    "opt_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f720f9-b7ce-496a-9692-890327ea1704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "# it really seems like the parameters are not actually used \n",
    "\n",
    "optimizer_test = {}\n",
    "opt_fn_test = {}\n",
    "\n",
    "for k, p in split_params(trainable_params_shape).items():\n",
    "            # opt.init(parameters) -> \n",
    "            optimizer_test[k] = opt.init(p)\n",
    "            opt_fn_test[k] = NamedTuple(\"opt_fn\", pspec_fn=Any, shape_and_dtype_fn=Any)(\n",
    "                optimizer_test[k].pspec_fn, optimizer_test[k].shape_and_dtype_fn\n",
    "            )\n",
    "            optimizer_test[k] = optax.GradientTransformation(optimizer_test[k].init_fn, update_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d997584-ff6e-4872-8f83-f7f5a8747231",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2a700a-6964-4fae-afaa-95527797892b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### about jax.eval_shape and ShapeDtypeStruct\n",
    "\n",
    "\n",
    "let's start to understand __jax.eval_shape__ first, it is a utility function for performing shape inference\n",
    "\n",
    "```python\n",
    "jax.eval_shape(fun, *args, **kwargs)\n",
    "```\n",
    "\n",
    "* the __purpose of jax.eval_shape__ is to __infer__ the __shape__ of <u>fun(*args, **kwargs)</u>, without actually running the function; instead of passing the actual inputs (which should be a array, scalar or nested pytree of these types), you should use __duck-typed__ scalars and arrays intead (e.g. __ShapeDtypeStruct__), which has 2 attributes: __\"shape\"__, __\"dtype\"__ \n",
    "```python\n",
    "class ShapeDtypeStruct:\n",
    "  __slots__ = [\"shape\", \"dtype\"]\n",
    "  def __init__(self, shape, dtype):\n",
    "    self.shape = shape\n",
    "    self.dtype = dtype\n",
    "```\n",
    "* the input of jax_eval_shape should be a __pytree of ShapeDtypeStruct__ and the output should also be a __pytree of ShapeDtypeStruct__; the behavior should be defined as \n",
    "```python\n",
    "def eval_shape(fun, *args, **kwargs):\n",
    "  out = fun(*args, **kwargs)\n",
    "  return jax.tree_map(shape_dtype_struct, out)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cd7862-f7ed-415b-ab21-40d331eb49de",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### about set_partition\n",
    "\n",
    "__How to use set_partition?__\n",
    "* it's used in dalle-mini to create __PartitionSpecs for trainable parameters__, which is then used to create __PartitionSpec for optimizer state__ ( we will go over in next section)\n",
    "\n",
    "\n",
    "```\n",
    "set_partitions(trainable_params_shape) -> trainable_params_spec\n",
    "```\n",
    "* both __input__ (e.g.trainable_params_shape) and __output__ (e.g.trainable_params_spec)are __pytree with same structure__ (same structure as parameters tree)\n",
    "* it doesn't matter what's in the input tree (in our example, we used the tree of shapes), it will be initialized as empty object before we try to find the partition rule for it\n",
    "* for __each parameter__, we loop through all the __rules__, which contains the __keywords__ , and a __PartitionSpec__ object - if the parameter name contains the rule keyward, we consider it a __match__. the parameter will be assigned the <u>PartitionSpec of the first matching rule</u>\n",
    "\n",
    "its basic defination, a few caveats:\n",
    "* if use_scan (which we did not use), we will add a None in each PartitionSpec for parameters in scanned layers \n",
    "* we will make sure all the parameters has a PartitionSpec \n",
    "\n",
    "```python\n",
    "def set_partitions(in_dict, use_scan):\n",
    "    rules = _get_partition_rules()\n",
    "    replace = _replacement_rules(rules)\n",
    "    initd = {k: _unmatched for k in flatten_dict(in_dict)}\n",
    "    result = {k: replace(k, v) for k, v in initd.items()}\n",
    "    return freeze(unflatten_dict(result))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7337b17b-76cc-4dad-be42-ffd0d7d78087",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# step by step\n",
    "import re\n",
    "from jax.experimental import PartitionSpec as P\n",
    "from flax.traverse_util import flatten_dict, unflatten_dict\n",
    "\n",
    "def _match(qs, ks):\n",
    "    \"\"\"Return True if regexes in qs match any window of strings in tuple ks.\"\"\"\n",
    "    # compile regexes and force complete match\n",
    "    qts = tuple(map(lambda x: re.compile(x + \"$\"), qs))\n",
    "    for i in range(len(ks) - len(qs) + 1):\n",
    "        matches = [x.match(y) for x, y in zip(qts, ks[i:])]\n",
    "        if matches and all(matches):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def _replacement_rules(rules):\n",
    "    def replace(key, val):\n",
    "        for rule, replacement in rules:\n",
    "            if _match(rule, key):\n",
    "                return replacement\n",
    "        return val\n",
    "\n",
    "    return replace\n",
    "\n",
    "def _get_partition_rules():\n",
    "    return [\n",
    "        # embeddings\n",
    "        ((\"embed_positions\", \"embedding\"), P(\"mp\", None)),\n",
    "        ((\"embed_tokens\", \"embedding\"), P(\"mp\", None)),\n",
    "        ((\"rel_bias\", \"embedding\"), P(None, \"mp\")),\n",
    "        # attention\n",
    "        ((\"(q_proj|k_proj|v_proj)\", \"kernel\"), P(None, \"mp\")),\n",
    "        ((\"out_proj\", \"kernel\"), P(\"mp\", None)),\n",
    "        # FFN\n",
    "        ((\"Dense_0\", \"kernel\"), P(None, \"mp\")),\n",
    "        ((\"GLU.*\", \"Dense_1\", \"kernel\"), P(None, \"mp\")),\n",
    "        ((\"GLU.*\", \"Dense_2\", \"kernel\"), P(\"mp\", None)),\n",
    "        ((\"FFN.*\", \"Dense_1\", \"kernel\"), P(\"mp\", None)),\n",
    "        # layer norms\n",
    "        ((\"(bias|scale)\",), None),\n",
    "        ((\"lm_head\", \"kernel\"), P(None, \"mp\")),\n",
    "        # head scale and tau\n",
    "        ((\"(head_scale|tau)\",), None),\n",
    "    ]\n",
    "\n",
    "rules = _get_partition_rules()\n",
    "replace = _replacement_rules(rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3363c511-8038-4c2d-bcb6-03f9db493524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# each rule is a tuple \n",
    "# first element is tuple of keywords, second element is the partitionspec \n",
    "rules[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be39883-65c5-4ff5-8986-030a52c5e41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace is a function that take the parameter name (here is a tuple of nested key) and the default return value\n",
    "# if any of the keys matches keywards on our rule, it will return the PartitionSpec\n",
    "# this example matches our first rule\n",
    "replace(('model', 'decoder', 'embed_positions', 'embedding'), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17db050-5046-4510-b85e-ed1a223f5bb2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### get PartitionSpec for optimizer state  -> `opt_state_spec`\n",
    "\n",
    "use __pspec_fn__ from opt.init().pspec_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "059bb8a4-b88a-4f6e-a420-4e075ca26e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # get PartitionSpec for optimizer state\n",
    "    def get_opt_state_spec_and_shape():\n",
    "        # get opt_state shape without actual init\n",
    "        opt_state_shape = {}\n",
    "        for k, p in split_params(trainable_params_shape).items():\n",
    "            if \"scanned\" not in k:\n",
    "                opt_state_shape[k] = jax.eval_shape(optimizer[k].init, p)\n",
    "            else:\n",
    "                opt_state_shape[k] = jax.eval_shape(jax.vmap(optimizer[k].init), p)\n",
    "\n",
    "        if training_args.optim == \"adafactor\":\n",
    "            # factorized state must be replicated (rank different than params)\n",
    "            opt_state_spec = {k: None for k in split_params(trainable_params_shape)}\n",
    "\n",
    "        elif training_args.optim in [\"adam\", \"distributed_shampoo\"]:\n",
    "\n",
    "            def _opt_state_spec_per_leaf(x, spec):\n",
    "                if isinstance(x, FrozenDict):\n",
    "                    # variables with same structure as params\n",
    "                    return spec\n",
    "                else:\n",
    "                    # other variables such as count\n",
    "                    return None\n",
    "\n",
    "            split_spec = split_params(set_partitions(trainable_params_shape, False))\n",
    "            opt_state_spec = {}\n",
    "            for k, p in split_params(trainable_params_shape).items():\n",
    "                if \"scanned\" in k:\n",
    "                    p = jax.eval_shape(\n",
    "                        lambda x: jax.tree_util.tree_map(lambda y: y[0], x), p\n",
    "                    )\n",
    "                if training_args.optim == \"adam\":\n",
    "                    opt_state_spec[k] = jax.tree_util.tree_map(\n",
    "                        partial(_opt_state_spec_per_leaf, spec=split_spec[k]),\n",
    "                        opt_state_shape[k],\n",
    "                        # return None spec for empty elements\n",
    "                        is_leaf=lambda x: isinstance(x, (FrozenDict, optax.EmptyState)),\n",
    "                    )\n",
    "                elif training_args.optim == \"distributed_shampoo\":\n",
    "                    opt_state_spec[k] = opt_fn[k].pspec_fn(\n",
    "                        p,\n",
    "                        split_spec[k],\n",
    "                        statistics_partition_spec,\n",
    "                    )\n",
    "                # add dimension for scanned params\n",
    "                if \"scanned\" in k:\n",
    "                    opt_state_spec[k] = jax.tree_util.tree_map(\n",
    "                        lambda x: PartitionSpec(*(None,) + x) if x is not None else None,\n",
    "                        opt_state_spec[k],\n",
    "                        is_leaf=lambda x: isinstance(x, PartitionSpec),\n",
    "                    )\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        return freeze(opt_state_spec), freeze(opt_state_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6bb9af48-c744-4751-8410-804606a9b9ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/GoogleDrive/My Drive/Github/dalle-mini/tools/train/scalable_shampoo/distributed_shampoo.py:1153: FutureWarning: jax.tree_flatten is deprecated, and will be removed in a future release. Use jax.tree_util.tree_flatten instead.\n",
      "  params_flat, treedef = jax.tree_flatten(params)\n",
      "/Volumes/GoogleDrive/My Drive/Github/dalle-mini/tools/train/scalable_shampoo/distributed_shampoo.py:1207: FutureWarning: jax.tree_unflatten is deprecated, and will be removed in a future release. Use jax.tree_util.tree_unflatten instead.\n",
      "  local_stats = jax.tree_unflatten(treedef, local_stats_flat)\n",
      "/Volumes/GoogleDrive/My Drive/Github/dalle-mini/tools/train/scalable_shampoo/distributed_shampoo.py:1267: FutureWarning: jax.tree_flatten is deprecated, and will be removed in a future release. Use jax.tree_util.tree_flatten instead.\n",
      "  param_pspec_flat, _ = jax.tree_flatten(\n",
      "/Volumes/GoogleDrive/My Drive/Github/dalle-mini/tools/train/scalable_shampoo/distributed_shampoo.py:1270: FutureWarning: jax.tree_flatten is deprecated, and will be removed in a future release. Use jax.tree_util.tree_flatten instead.\n",
      "  params_flat, treedef = jax.tree_flatten(params)\n",
      "/Volumes/GoogleDrive/My Drive/Github/dalle-mini/tools/train/scalable_shampoo/distributed_shampoo.py:1315: FutureWarning: jax.tree_unflatten is deprecated, and will be removed in a future release. Use jax.tree_util.tree_unflatten instead.\n",
      "  local_stats = jax.tree_unflatten(treedef, local_stats_flat)\n"
     ]
    }
   ],
   "source": [
    "opt_state_spec, opt_state_shape = get_opt_state_spec_and_shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26170a3f-0565-4f6b-a9ea-3c14ee52ab98",
   "metadata": {},
   "source": [
    "__opt_state_shape__\n",
    "\n",
    "it is a pytree with __same structure__ as opt_state, but contains __ShapeDtypeStruct__\n",
    "* it is a dict contains one ShampooState for each parameter group\n",
    "* we didn't have to actually create opt_state, we used __jax.eval_shape__ to inferred its shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d9f16776-8dbb-4423-871a-398d1b3ee226",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we set use_scan as False, so only one parameter group\n",
    "opt_state_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "df52171b-75e7-46d1-bda3-d2e16d49a894",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# all the leaves are shapes\n",
    "jax.tree_leaves(opt_state_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb61c7ae-d152-4c67-aeb3-4ef61d7721d6",
   "metadata": {},
   "source": [
    "__create opt_state_spec__\n",
    "\n",
    "1. first we create the __partition specs for parameters__ and split it into parameter groups -> __split_spec__\n",
    "2. loop through the parameter groups\n",
    "   * if scanned group, remove first dimension from all its parameters' shapes\n",
    "   * create __opt_state_spec__ for that parameter group use __pspec_fn()__ \n",
    "     * inputs are: __the shape__ tree, __the partition specs for params__ and __partition specs for statistics__\n",
    "\n",
    "```python\n",
    " opt_fn.pspec_fn(params_shape, params_spec, statistics_partition_spec)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "9e745e83-5b1b-434a-8767-972a58a53c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "bc895b0b-ae03-4b26-b2a3-6a06bace1260",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# first get partition based on the params_shape and partition rules\n",
    "# and then split into 3 parameter groups\n",
    "split_spec = split_params(set_partitions(trainable_params_shape, False))\n",
    "split_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e68b34-2f49-498d-9727-f724ad095ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard\n",
    "p = split_spec['standard']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2725d515-e32e-4f1e-a7bd-c4c96c8e1c32",
   "metadata": {},
   "source": [
    "about __pspec_fn__\n",
    "  * we get __pspec_fn__ from the state return by distributed_shampoo's __init__ method (see chart below)\n",
    "  * when shampoo is used in pjit mode, it is __sharded_init_partition_spec_fn__ \n",
    "```python\n",
    "                                            opt.update\n",
    "                                                â¬‡\n",
    "p -> opt.init() ->  opt_state -> init_fn -> GradientTransformation -> optimizer{}\n",
    "                        â¬‡            \n",
    "              (pspec_fn, shape_and_dtype_fn)\n",
    "                        â¬‡\n",
    "                      opt_fn{}\n",
    "```\n",
    " __pspec_fn__ takes 3 inputs: \n",
    "   * __params__:  A pytree with params shapes\n",
    "      * duck_typed is fine since we only need to use its shape info, e.g. it used trainable_params_shape \n",
    "      * its __.shape__ attribute is used, that's why we remove the first dimension of scanned parameters when we pass it to psepc_fn\n",
    "   * __params_partition_spec__: A pytree with PartitionSpec for params. \n",
    "      * the split_spec we just created\n",
    "   * __partition_spec_for_statistics__: PartitionSpec for the statistics. \n",
    "      *  statistics_partition_spec is created earlier when we create distributed_shampoo\n",
    "  * it returns a parallel state tree with PartitionSpec associated with state??\n",
    "\n",
    "\n",
    "```python\n",
    "opt_state_spec[k] = opt_fn[k].pspec_fn(\n",
    "                        p,\n",
    "                        split_spec[k],\n",
    "                        statistics_partition_spec,\n",
    "                    )\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "fa8f55a4-8466-4843-9369-878fe480bd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_fn['standard'].pspec_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "e7f60a5a-b055-455d-9b1e-eb94dfb54a6b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "split_spec['standard']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "51d1e5ea-15b2-43c8-9223-82cef0e489b2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenDict({\n",
       "    lm_head: {\n",
       "        kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 16401]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 16401]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 16401]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=0, sizes=[]),\n",
       "    },\n",
       "    model: {\n",
       "        decoder: {\n",
       "            embed_positions: {\n",
       "                embedding: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[256, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[256, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[256, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=0, sizes=[256, 1024]),\n",
       "            },\n",
       "            embed_tokens: {\n",
       "                embedding: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[16401, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[16401, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[16401, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=2, sizes=[]),\n",
       "            },\n",
       "            final_ln: {\n",
       "                bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=2, sizes=[1024]),\n",
       "            },\n",
       "            layernorm_embedding: {\n",
       "                bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=3, sizes=[1024]),\n",
       "                scale: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=4, sizes=[1024]),\n",
       "            },\n",
       "            layers: {\n",
       "                FlaxBartDecoderLayer_0: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=5, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=7, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=9, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=11, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=13, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=15, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=17, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=19, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=21, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=27, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=33, sizes=[1024, 1024, 1024, 1024, 682, 1024]),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=39, sizes=[1024]),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=40, sizes=[1024, 1024, 682]),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=43, sizes=[1024]),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=44, sizes=[1024]),\n",
       "                        scale: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=45, sizes=[1024]),\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=46, sizes=[1024]),\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=47, sizes=[1024]),\n",
       "                        scale: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=48, sizes=[1024]),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_1: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=49, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=51, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=53, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=55, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=57, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=59, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=61, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=63, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=65, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=71, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=77, sizes=[1024, 1024, 1024, 1024, 682, 1024]),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=83, sizes=[1024]),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=84, sizes=[1024, 1024, 682]),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=87, sizes=[1024]),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=88, sizes=[1024]),\n",
       "                        scale: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=89, sizes=[1024]),\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=90, sizes=[1024]),\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=91, sizes=[1024]),\n",
       "                        scale: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=92, sizes=[1024]),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_10: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=93, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=95, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=97, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=99, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=101, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=103, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=105, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=107, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=109, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=115, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=121, sizes=[1024, 1024, 1024, 1024, 682, 1024]),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=127, sizes=[1024]),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=128, sizes=[1024, 1024, 682]),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=131, sizes=[1024]),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=132, sizes=[1024]),\n",
       "                        scale: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=133, sizes=[1024]),\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=134, sizes=[1024]),\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=135, sizes=[1024]),\n",
       "                        scale: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=136, sizes=[1024]),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_11: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=137, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=139, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=141, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=143, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=145, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=147, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=149, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=151, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=153, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=159, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=165, sizes=[1024, 1024, 1024, 1024, 682, 1024]),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=171, sizes=[1024]),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=172, sizes=[1024, 1024, 682]),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=175, sizes=[1024]),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=176, sizes=[1024]),\n",
       "                        scale: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=177, sizes=[1024]),\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=178, sizes=[1024]),\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=179, sizes=[1024]),\n",
       "                        scale: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=180, sizes=[1024]),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_2: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=181, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=183, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=185, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=187, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=189, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=191, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=193, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=195, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=197, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=203, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=209, sizes=[1024, 1024, 1024, 1024, 682, 1024]),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=215, sizes=[1024]),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=216, sizes=[1024, 1024, 682]),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=219, sizes=[1024]),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=220, sizes=[1024]),\n",
       "                        scale: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=221, sizes=[1024]),\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=222, sizes=[1024]),\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=223, sizes=[1024]),\n",
       "                        scale: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=224, sizes=[1024]),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_3: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=225, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=227, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=229, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=231, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=233, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=235, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=237, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=239, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=241, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=247, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=253, sizes=[1024, 1024, 1024, 1024, 682, 1024]),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=259, sizes=[1024]),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=260, sizes=[1024, 1024, 682]),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=263, sizes=[1024]),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=264, sizes=[1024]),\n",
       "                        scale: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=265, sizes=[1024]),\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=266, sizes=[1024]),\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=267, sizes=[1024]),\n",
       "                        scale: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=268, sizes=[1024]),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_4: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=269, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=271, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=273, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=275, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=277, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=279, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=281, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=283, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=285, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=291, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=297, sizes=[1024, 1024, 1024, 1024, 682, 1024]),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=303, sizes=[1024]),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=304, sizes=[1024, 1024, 682]),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=307, sizes=[1024]),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=308, sizes=[1024]),\n",
       "                        scale: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=309, sizes=[1024]),\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=310, sizes=[1024]),\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=311, sizes=[1024]),\n",
       "                        scale: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=312, sizes=[1024]),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_5: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=313, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=315, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=317, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=319, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=321, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=323, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=325, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=327, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=329, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=335, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=341, sizes=[1024, 1024, 1024, 1024, 682, 1024]),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=347, sizes=[1024]),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=348, sizes=[1024, 1024, 682]),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=351, sizes=[1024]),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=352, sizes=[1024]),\n",
       "                        scale: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=353, sizes=[1024]),\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=354, sizes=[1024]),\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=355, sizes=[1024]),\n",
       "                        scale: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=356, sizes=[1024]),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_6: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=357, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=359, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=361, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=363, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=365, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=367, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=369, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=371, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=373, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=379, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=385, sizes=[1024, 1024, 1024, 1024, 682, 1024]),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=391, sizes=[1024]),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=392, sizes=[1024, 1024, 682]),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=395, sizes=[1024]),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=396, sizes=[1024]),\n",
       "                        scale: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=397, sizes=[1024]),\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=398, sizes=[1024]),\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=399, sizes=[1024]),\n",
       "                        scale: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=400, sizes=[1024]),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_7: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=401, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=403, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=405, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=407, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=409, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=411, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=413, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=415, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=417, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=423, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=429, sizes=[1024, 1024, 1024, 1024, 682, 1024]),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=435, sizes=[1024]),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=436, sizes=[1024, 1024, 682]),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=439, sizes=[1024]),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=440, sizes=[1024]),\n",
       "                        scale: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=441, sizes=[1024]),\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=442, sizes=[1024]),\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=443, sizes=[1024]),\n",
       "                        scale: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=444, sizes=[1024]),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_8: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=445, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=447, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=449, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=451, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=453, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=455, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=457, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=459, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=461, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=467, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=473, sizes=[1024, 1024, 1024, 1024, 682, 1024]),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=479, sizes=[1024]),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=480, sizes=[1024, 1024, 682]),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=483, sizes=[1024]),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=484, sizes=[1024]),\n",
       "                        scale: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=485, sizes=[1024]),\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=486, sizes=[1024]),\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=487, sizes=[1024]),\n",
       "                        scale: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=488, sizes=[1024]),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_9: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=489, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=491, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=493, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=495, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=497, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=499, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=501, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=503, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=505, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=511, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=517, sizes=[1024, 1024, 1024, 1024, 682, 1024]),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=523, sizes=[1024]),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=524, sizes=[1024, 1024, 682]),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=527, sizes=[1024]),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=528, sizes=[1024]),\n",
       "                        scale: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=529, sizes=[1024]),\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=530, sizes=[1024]),\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=531, sizes=[1024]),\n",
       "                        scale: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=532, sizes=[1024]),\n",
       "                    },\n",
       "                },\n",
       "            },\n",
       "        },\n",
       "        encoder: {\n",
       "            embed_positions: {\n",
       "                embedding: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[64, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[64, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[64, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=533, sizes=[64, 1024]),\n",
       "            },\n",
       "            embed_tokens: {\n",
       "                embedding: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[50300, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[50300, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[50300, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=535, sizes=[]),\n",
       "            },\n",
       "            final_ln: {\n",
       "                bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=535, sizes=[1024]),\n",
       "            },\n",
       "            layernorm_embedding: {\n",
       "                bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=536, sizes=[1024]),\n",
       "                scale: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=537, sizes=[1024]),\n",
       "            },\n",
       "            layers: {\n",
       "                FlaxBartEncoderLayer_0: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=538, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=540, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=542, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=544, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=546, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=552, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=558, sizes=[1024, 1024, 1024, 1024, 682, 1024]),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=564, sizes=[1024]),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=565, sizes=[1024, 1024, 682]),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=568, sizes=[1024]),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=569, sizes=[1024]),\n",
       "                        scale: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=570, sizes=[1024]),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_1: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=571, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=573, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=575, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=577, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=579, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=585, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=591, sizes=[1024, 1024, 1024, 1024, 682, 1024]),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=597, sizes=[1024]),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=598, sizes=[1024, 1024, 682]),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=601, sizes=[1024]),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=602, sizes=[1024]),\n",
       "                        scale: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=603, sizes=[1024]),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_10: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=604, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=606, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=608, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=610, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=612, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=618, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=624, sizes=[1024, 1024, 1024, 1024, 682, 1024]),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=630, sizes=[1024]),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=631, sizes=[1024, 1024, 682]),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=634, sizes=[1024]),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=635, sizes=[1024]),\n",
       "                        scale: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=636, sizes=[1024]),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_11: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=637, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=639, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=641, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=643, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=645, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=651, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=657, sizes=[1024, 1024, 1024, 1024, 682, 1024]),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=663, sizes=[1024]),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=664, sizes=[1024, 1024, 682]),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=667, sizes=[1024]),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=668, sizes=[1024]),\n",
       "                        scale: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=669, sizes=[1024]),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_2: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=670, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=672, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=674, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=676, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=678, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=684, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=690, sizes=[1024, 1024, 1024, 1024, 682, 1024]),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=696, sizes=[1024]),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=697, sizes=[1024, 1024, 682]),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=700, sizes=[1024]),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=701, sizes=[1024]),\n",
       "                        scale: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=702, sizes=[1024]),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_3: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=703, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=705, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=707, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=709, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=711, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=717, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=723, sizes=[1024, 1024, 1024, 1024, 682, 1024]),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=729, sizes=[1024]),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=730, sizes=[1024, 1024, 682]),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=733, sizes=[1024]),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=734, sizes=[1024]),\n",
       "                        scale: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=735, sizes=[1024]),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_4: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=736, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=738, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=740, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=742, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=744, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=750, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=756, sizes=[1024, 1024, 1024, 1024, 682, 1024]),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=762, sizes=[1024]),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=763, sizes=[1024, 1024, 682]),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=766, sizes=[1024]),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=767, sizes=[1024]),\n",
       "                        scale: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=768, sizes=[1024]),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_5: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=769, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=771, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=773, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=775, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=777, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=783, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=789, sizes=[1024, 1024, 1024, 1024, 682, 1024]),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=795, sizes=[1024]),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=796, sizes=[1024, 1024, 682]),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=799, sizes=[1024]),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=800, sizes=[1024]),\n",
       "                        scale: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=801, sizes=[1024]),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_6: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=802, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=804, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=806, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=808, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=810, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=816, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=822, sizes=[1024, 1024, 1024, 1024, 682, 1024]),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=828, sizes=[1024]),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=829, sizes=[1024, 1024, 682]),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=832, sizes=[1024]),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=833, sizes=[1024]),\n",
       "                        scale: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=834, sizes=[1024]),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_7: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=835, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=837, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=839, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=841, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=843, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=849, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=855, sizes=[1024, 1024, 1024, 1024, 682, 1024]),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=861, sizes=[1024]),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=862, sizes=[1024, 1024, 682]),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=865, sizes=[1024]),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=866, sizes=[1024]),\n",
       "                        scale: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=867, sizes=[1024]),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_8: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=868, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=870, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=872, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=874, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=876, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=882, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=888, sizes=[1024, 1024, 1024, 1024, 682, 1024]),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=894, sizes=[1024]),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=895, sizes=[1024, 1024, 682]),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=898, sizes=[1024]),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=899, sizes=[1024]),\n",
       "                        scale: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=900, sizes=[1024]),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_9: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=901, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=903, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=905, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=907, sizes=[1024, 1024]),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=909, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=915, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=921, sizes=[1024, 1024, 1024, 1024, 682, 1024]),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=927, sizes=[1024]),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=928, sizes=[1024, 1024, 682]),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=931, sizes=[1024]),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=932, sizes=[1024]),\n",
       "                        scale: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=933, sizes=[1024]),\n",
       "                    },\n",
       "                },\n",
       "            },\n",
       "        },\n",
       "    },\n",
       "})"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# opt_state_spec has same tree structre as opt_state, it is also a ShampooState \n",
    "opt_state_spec['standard'].stats.local_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "c02ebd26-7492-4008-8925-f8f804ff9e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9l/9hm851zx7qgfkmls0h72j82r0000gn/T/ipykernel_27605/2272418448.py:1: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  jax.tree_leaves(opt_state_spec['standard'].stats.global_stats)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PartitionSpec(None, 'dp', None),\n",
       " PartitionSpec(None, 'dp', None),\n",
       " PartitionSpec()]"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.tree_leaves(opt_state_spec['standard'].stats.global_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "0ff749be-2825-48fb-9cb2-ba32026b7c5c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9l/9hm851zx7qgfkmls0h72j82r0000gn/T/ipykernel_27605/2655405477.py:2: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  jax.tree_leaves(opt_state_spec['standard'].stats.local_stats)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec(),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec(),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec('mp', None),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(None, 'mp'),\n",
       " PartitionSpec(),\n",
       " ...]"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all the leaves are partitionspecs\n",
    "jax.tree_leaves(opt_state_spec['standard'].stats.local_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593232d3-6042-49a6-8177-a410f66b0667",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### create a mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1000a1be-e943-4e1e-9319-1daa40c20f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_shape = (training_args.dp_devices, training_args.mp_devices)\n",
    "devices = np.asarray(jax.devices()).reshape(*mesh_shape)\n",
    "mesh = maps.Mesh(devices, (\"dp\", \"mp\"))\n",
    "logger.info(f\"  Mesh shape: {mesh_shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "20719a41-5805-4026-a64b-0cf9a0bad96b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 1)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mesh_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a875b7bb-6f2d-45e5-a58a-44529ea641dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mesh(array([[0],\n",
       "       [1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [4],\n",
       "       [5],\n",
       "       [6],\n",
       "       [7]]), ('dp', 'mp'))"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# it's an array, with a mesh axis 'dp','mp', each element is a device, \n",
    "mesh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b571da-66bb-4d52-8550-2da2dd40ee4d",
   "metadata": {},
   "source": [
    "### define TrainState\n",
    "\n",
    "dalle-mini TrainState has custom `apply_gradient` and `create` - pay attention to how these methods are used later "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e1cb77a6-0edc-49d0-9aa3-6515c0aedb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "    class TrainState(struct.PyTreeNode):\n",
    "        step: int\n",
    "        params: core.FrozenDict[str, Any]\n",
    "        opt_state: optax.OptState\n",
    "        apply_fn: Callable = struct.field(pytree_node=False)\n",
    "        tx: optax.GradientTransformation = struct.field(pytree_node=False)\n",
    "        dropout_rng: jnp.ndarray = None\n",
    "        epoch: int = 0\n",
    "        train_time: float = 0.0  # total time the model trained\n",
    "        train_samples: int = 0  # number of samples seen\n",
    "\n",
    "        def apply_gradients(self, *, grads, **kwargs):\n",
    "            grads = split_params(trainable_params(grads, training_args.embeddings_only))\n",
    "            params = split_params(\n",
    "                trainable_params(self.params, training_args.embeddings_only)\n",
    "            )\n",
    "            opt_state = {}\n",
    "            # we loop over keys: \"standard\", \"scanned_encoder\", \"scanned_decoder\"\n",
    "            for k, param in params.items():\n",
    "                update_fn = self.tx[k].update\n",
    "                if \"scanned\" in k:\n",
    "                    update_fn = jax.vmap(update_fn, in_axes=(0, 0, 0), out_axes=(0, 0))\n",
    "                updates, new_opt_state = update_fn(grads[k], self.opt_state[k], param)\n",
    "                params[k] = optax.apply_updates(param, updates)\n",
    "                opt_state[k] = new_opt_state\n",
    "            params = unsplit_params(params)\n",
    "            # merge with non-trainable params\n",
    "            params, new_params = traverse_util.flatten_dict(\n",
    "                unfreeze(self.params)\n",
    "            ), traverse_util.flatten_dict(unfreeze(params))\n",
    "            params.update(new_params)\n",
    "            params = freeze(traverse_util.unflatten_dict(params))\n",
    "\n",
    "            return self.replace(\n",
    "                step=self.step + 1,\n",
    "                params=params,\n",
    "                opt_state=freeze(opt_state),\n",
    "                **kwargs,\n",
    "            )\n",
    "\n",
    "        @classmethod\n",
    "        def create(cls, *, apply_fn, params, tx, **kwargs):\n",
    "            opt_state = {}\n",
    "            for k, p in split_params(\n",
    "                trainable_params(params, training_args.embeddings_only)\n",
    "            ).items():\n",
    "                init_fn = tx[k].init\n",
    "                if \"scanned\" in k:\n",
    "                    init_fn = jax.vmap(init_fn)\n",
    "                opt_state[k] = init_fn(p)\n",
    "            return cls(\n",
    "                step=0,\n",
    "                apply_fn=apply_fn,\n",
    "                params=params,\n",
    "                tx=tx,\n",
    "                opt_state=freeze(opt_state),\n",
    "                **kwargs,\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c18c694-8b33-4a6e-8ade-e4075275d128",
   "metadata": {
    "tags": []
   },
   "source": [
    "### PartitionSpec for TrainState -> `state_spec'\n",
    "\n",
    "we are using __TrainState__ class to create the partition spec for TrainState (__state_spec__) since the structure match - we used __param_spec__  in place of params, and __opt_state_spec__ in place of opt_state\n",
    "\n",
    "It's a good time to review all the states associated with model that we need to partition, __TrainState__ would include both the parameters and optimizer state\n",
    "```python\n",
    "Parameters â‡¢ optimizer state â¤µ\n",
    "          â†ª â‡¢â‡¢â‡¢â‡¢â‡¢â‡¢â‡¢â‡¢       TrainState\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "dab568b9-1b27-4317-b6c2-48f63c1150f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # define state spec\n",
    "    state_spec = TrainState(\n",
    "        params=param_spec,\n",
    "        opt_state=opt_state_spec,\n",
    "        dropout_rng=None,\n",
    "        step=None,\n",
    "        epoch=None,\n",
    "        train_time=None,\n",
    "        train_samples=None,\n",
    "        apply_fn=model.__call__,\n",
    "        tx=optimizer,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0123235e-d3a8-4013-956e-22e47c8b103e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainState(step=None, params=FrozenDict({\n",
       "    lm_head: {\n",
       "        kernel: PartitionSpec(None, 'mp'),\n",
       "    },\n",
       "    model: {\n",
       "        decoder: {\n",
       "            embed_positions: {\n",
       "                embedding: PartitionSpec('mp', None),\n",
       "            },\n",
       "            embed_tokens: {\n",
       "                embedding: PartitionSpec('mp', None),\n",
       "            },\n",
       "            final_ln: {\n",
       "                bias: None,\n",
       "            },\n",
       "            layernorm_embedding: {\n",
       "                bias: None,\n",
       "                scale: None,\n",
       "            },\n",
       "            layers: {\n",
       "                FlaxBartDecoderLayer_0: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_1: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_10: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_11: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_2: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_3: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_4: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_5: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_6: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_7: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_8: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_9: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "            },\n",
       "        },\n",
       "        encoder: {\n",
       "            embed_positions: {\n",
       "                embedding: PartitionSpec('mp', None),\n",
       "            },\n",
       "            embed_tokens: {\n",
       "                embedding: PartitionSpec('mp', None),\n",
       "            },\n",
       "            final_ln: {\n",
       "                bias: None,\n",
       "            },\n",
       "            layernorm_embedding: {\n",
       "                bias: None,\n",
       "                scale: None,\n",
       "            },\n",
       "            layers: {\n",
       "                FlaxBartEncoderLayer_0: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_1: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_10: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_11: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_2: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_3: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_4: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_5: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_6: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_7: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_8: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_9: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "            },\n",
       "        },\n",
       "    },\n",
       "}), opt_state=FrozenDict({\n",
       "    standard: ShampooState(count=PartitionSpec(), stats=ShardedShampooStats(global_stats=GlobalShardedParameterStats(statistics=PartitionSpec(None, 'dp', None), preconditioners=PartitionSpec(None, 'dp', None), exponents=PartitionSpec()), local_stats=FrozenDict({\n",
       "        lm_head: {\n",
       "            kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 16401]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 16401]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 16401]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=0, sizes=[]),\n",
       "        },\n",
       "        model: {\n",
       "            decoder: {\n",
       "                embed_positions: {\n",
       "                    embedding: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[256, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[256, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[256, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=0, sizes=[256, 1024]),\n",
       "                },\n",
       "                embed_tokens: {\n",
       "                    embedding: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[16401, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[16401, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[16401, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=2, sizes=[]),\n",
       "                },\n",
       "                final_ln: {\n",
       "                    bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=2, sizes=[1024]),\n",
       "                },\n",
       "                layernorm_embedding: {\n",
       "                    bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=3, sizes=[1024]),\n",
       "                    scale: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=4, sizes=[1024]),\n",
       "                },\n",
       "                layers: {\n",
       "                    FlaxBartDecoderLayer_0: {\n",
       "                        FlaxBartAttention_0: {\n",
       "                            k_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=5, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            out_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=7, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            q_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=9, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            v_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=11, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                        },\n",
       "                        FlaxBartAttention_1: {\n",
       "                            k_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=13, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            out_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=15, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            q_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=17, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            v_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=19, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                        },\n",
       "                        GLU_0: {\n",
       "                            Dense_0: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=21, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                            },\n",
       "                            Dense_1: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=27, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                            },\n",
       "                            Dense_2: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=33, sizes=[1024, 1024, 1024, 1024, 682, 1024]),\n",
       "                            },\n",
       "                            LayerNorm_0: {\n",
       "                                bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=39, sizes=[1024]),\n",
       "                            },\n",
       "                            LayerNorm_1: {\n",
       "                                bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=40, sizes=[1024, 1024, 682]),\n",
       "                            },\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=43, sizes=[1024]),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=44, sizes=[1024]),\n",
       "                            scale: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=45, sizes=[1024]),\n",
       "                        },\n",
       "                        LayerNorm_2: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=46, sizes=[1024]),\n",
       "                        },\n",
       "                        LayerNorm_3: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=47, sizes=[1024]),\n",
       "                            scale: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=48, sizes=[1024]),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartDecoderLayer_1: {\n",
       "                        FlaxBartAttention_0: {\n",
       "                            k_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=49, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            out_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=51, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            q_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=53, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            v_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=55, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                        },\n",
       "                        FlaxBartAttention_1: {\n",
       "                            k_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=57, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            out_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=59, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            q_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=61, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            v_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=63, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                        },\n",
       "                        GLU_0: {\n",
       "                            Dense_0: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=65, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                            },\n",
       "                            Dense_1: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=71, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                            },\n",
       "                            Dense_2: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=77, sizes=[1024, 1024, 1024, 1024, 682, 1024]),\n",
       "                            },\n",
       "                            LayerNorm_0: {\n",
       "                                bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=83, sizes=[1024]),\n",
       "                            },\n",
       "                            LayerNorm_1: {\n",
       "                                bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=84, sizes=[1024, 1024, 682]),\n",
       "                            },\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=87, sizes=[1024]),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=88, sizes=[1024]),\n",
       "                            scale: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=89, sizes=[1024]),\n",
       "                        },\n",
       "                        LayerNorm_2: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=90, sizes=[1024]),\n",
       "                        },\n",
       "                        LayerNorm_3: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=91, sizes=[1024]),\n",
       "                            scale: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=92, sizes=[1024]),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartDecoderLayer_10: {\n",
       "                        FlaxBartAttention_0: {\n",
       "                            k_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=93, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            out_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=95, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            q_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=97, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            v_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=99, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                        },\n",
       "                        FlaxBartAttention_1: {\n",
       "                            k_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=101, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            out_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=103, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            q_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=105, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            v_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=107, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                        },\n",
       "                        GLU_0: {\n",
       "                            Dense_0: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=109, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                            },\n",
       "                            Dense_1: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=115, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                            },\n",
       "                            Dense_2: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=121, sizes=[1024, 1024, 1024, 1024, 682, 1024]),\n",
       "                            },\n",
       "                            LayerNorm_0: {\n",
       "                                bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=127, sizes=[1024]),\n",
       "                            },\n",
       "                            LayerNorm_1: {\n",
       "                                bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=128, sizes=[1024, 1024, 682]),\n",
       "                            },\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=131, sizes=[1024]),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=132, sizes=[1024]),\n",
       "                            scale: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=133, sizes=[1024]),\n",
       "                        },\n",
       "                        LayerNorm_2: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=134, sizes=[1024]),\n",
       "                        },\n",
       "                        LayerNorm_3: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=135, sizes=[1024]),\n",
       "                            scale: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=136, sizes=[1024]),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartDecoderLayer_11: {\n",
       "                        FlaxBartAttention_0: {\n",
       "                            k_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=137, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            out_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=139, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            q_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=141, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            v_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=143, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                        },\n",
       "                        FlaxBartAttention_1: {\n",
       "                            k_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=145, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            out_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=147, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            q_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=149, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            v_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=151, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                        },\n",
       "                        GLU_0: {\n",
       "                            Dense_0: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=153, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                            },\n",
       "                            Dense_1: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=159, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                            },\n",
       "                            Dense_2: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=165, sizes=[1024, 1024, 1024, 1024, 682, 1024]),\n",
       "                            },\n",
       "                            LayerNorm_0: {\n",
       "                                bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=171, sizes=[1024]),\n",
       "                            },\n",
       "                            LayerNorm_1: {\n",
       "                                bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=172, sizes=[1024, 1024, 682]),\n",
       "                            },\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=175, sizes=[1024]),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=176, sizes=[1024]),\n",
       "                            scale: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=177, sizes=[1024]),\n",
       "                        },\n",
       "                        LayerNorm_2: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=178, sizes=[1024]),\n",
       "                        },\n",
       "                        LayerNorm_3: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=179, sizes=[1024]),\n",
       "                            scale: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=180, sizes=[1024]),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartDecoderLayer_2: {\n",
       "                        FlaxBartAttention_0: {\n",
       "                            k_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=181, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            out_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=183, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            q_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=185, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            v_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=187, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                        },\n",
       "                        FlaxBartAttention_1: {\n",
       "                            k_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=189, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            out_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=191, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            q_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=193, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            v_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=195, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                        },\n",
       "                        GLU_0: {\n",
       "                            Dense_0: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=197, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                            },\n",
       "                            Dense_1: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=203, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                            },\n",
       "                            Dense_2: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=209, sizes=[1024, 1024, 1024, 1024, 682, 1024]),\n",
       "                            },\n",
       "                            LayerNorm_0: {\n",
       "                                bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=215, sizes=[1024]),\n",
       "                            },\n",
       "                            LayerNorm_1: {\n",
       "                                bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=216, sizes=[1024, 1024, 682]),\n",
       "                            },\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=219, sizes=[1024]),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=220, sizes=[1024]),\n",
       "                            scale: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=221, sizes=[1024]),\n",
       "                        },\n",
       "                        LayerNorm_2: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=222, sizes=[1024]),\n",
       "                        },\n",
       "                        LayerNorm_3: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=223, sizes=[1024]),\n",
       "                            scale: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=224, sizes=[1024]),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartDecoderLayer_3: {\n",
       "                        FlaxBartAttention_0: {\n",
       "                            k_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=225, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            out_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=227, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            q_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=229, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            v_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=231, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                        },\n",
       "                        FlaxBartAttention_1: {\n",
       "                            k_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=233, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            out_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=235, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            q_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=237, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            v_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=239, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                        },\n",
       "                        GLU_0: {\n",
       "                            Dense_0: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=241, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                            },\n",
       "                            Dense_1: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=247, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                            },\n",
       "                            Dense_2: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=253, sizes=[1024, 1024, 1024, 1024, 682, 1024]),\n",
       "                            },\n",
       "                            LayerNorm_0: {\n",
       "                                bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=259, sizes=[1024]),\n",
       "                            },\n",
       "                            LayerNorm_1: {\n",
       "                                bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=260, sizes=[1024, 1024, 682]),\n",
       "                            },\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=263, sizes=[1024]),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=264, sizes=[1024]),\n",
       "                            scale: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=265, sizes=[1024]),\n",
       "                        },\n",
       "                        LayerNorm_2: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=266, sizes=[1024]),\n",
       "                        },\n",
       "                        LayerNorm_3: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=267, sizes=[1024]),\n",
       "                            scale: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=268, sizes=[1024]),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartDecoderLayer_4: {\n",
       "                        FlaxBartAttention_0: {\n",
       "                            k_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=269, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            out_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=271, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            q_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=273, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            v_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=275, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                        },\n",
       "                        FlaxBartAttention_1: {\n",
       "                            k_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=277, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            out_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=279, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            q_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=281, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            v_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=283, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                        },\n",
       "                        GLU_0: {\n",
       "                            Dense_0: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=285, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                            },\n",
       "                            Dense_1: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=291, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                            },\n",
       "                            Dense_2: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=297, sizes=[1024, 1024, 1024, 1024, 682, 1024]),\n",
       "                            },\n",
       "                            LayerNorm_0: {\n",
       "                                bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=303, sizes=[1024]),\n",
       "                            },\n",
       "                            LayerNorm_1: {\n",
       "                                bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=304, sizes=[1024, 1024, 682]),\n",
       "                            },\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=307, sizes=[1024]),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=308, sizes=[1024]),\n",
       "                            scale: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=309, sizes=[1024]),\n",
       "                        },\n",
       "                        LayerNorm_2: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=310, sizes=[1024]),\n",
       "                        },\n",
       "                        LayerNorm_3: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=311, sizes=[1024]),\n",
       "                            scale: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=312, sizes=[1024]),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartDecoderLayer_5: {\n",
       "                        FlaxBartAttention_0: {\n",
       "                            k_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=313, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            out_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=315, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            q_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=317, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            v_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=319, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                        },\n",
       "                        FlaxBartAttention_1: {\n",
       "                            k_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=321, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            out_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=323, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            q_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=325, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            v_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=327, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                        },\n",
       "                        GLU_0: {\n",
       "                            Dense_0: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=329, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                            },\n",
       "                            Dense_1: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=335, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                            },\n",
       "                            Dense_2: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=341, sizes=[1024, 1024, 1024, 1024, 682, 1024]),\n",
       "                            },\n",
       "                            LayerNorm_0: {\n",
       "                                bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=347, sizes=[1024]),\n",
       "                            },\n",
       "                            LayerNorm_1: {\n",
       "                                bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=348, sizes=[1024, 1024, 682]),\n",
       "                            },\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=351, sizes=[1024]),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=352, sizes=[1024]),\n",
       "                            scale: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=353, sizes=[1024]),\n",
       "                        },\n",
       "                        LayerNorm_2: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=354, sizes=[1024]),\n",
       "                        },\n",
       "                        LayerNorm_3: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=355, sizes=[1024]),\n",
       "                            scale: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=356, sizes=[1024]),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartDecoderLayer_6: {\n",
       "                        FlaxBartAttention_0: {\n",
       "                            k_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=357, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            out_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=359, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            q_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=361, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            v_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=363, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                        },\n",
       "                        FlaxBartAttention_1: {\n",
       "                            k_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=365, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            out_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=367, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            q_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=369, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            v_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=371, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                        },\n",
       "                        GLU_0: {\n",
       "                            Dense_0: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=373, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                            },\n",
       "                            Dense_1: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=379, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                            },\n",
       "                            Dense_2: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=385, sizes=[1024, 1024, 1024, 1024, 682, 1024]),\n",
       "                            },\n",
       "                            LayerNorm_0: {\n",
       "                                bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=391, sizes=[1024]),\n",
       "                            },\n",
       "                            LayerNorm_1: {\n",
       "                                bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=392, sizes=[1024, 1024, 682]),\n",
       "                            },\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=395, sizes=[1024]),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=396, sizes=[1024]),\n",
       "                            scale: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=397, sizes=[1024]),\n",
       "                        },\n",
       "                        LayerNorm_2: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=398, sizes=[1024]),\n",
       "                        },\n",
       "                        LayerNorm_3: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=399, sizes=[1024]),\n",
       "                            scale: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=400, sizes=[1024]),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartDecoderLayer_7: {\n",
       "                        FlaxBartAttention_0: {\n",
       "                            k_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=401, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            out_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=403, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            q_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=405, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            v_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=407, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                        },\n",
       "                        FlaxBartAttention_1: {\n",
       "                            k_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=409, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            out_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=411, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            q_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=413, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            v_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=415, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                        },\n",
       "                        GLU_0: {\n",
       "                            Dense_0: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=417, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                            },\n",
       "                            Dense_1: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=423, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                            },\n",
       "                            Dense_2: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=429, sizes=[1024, 1024, 1024, 1024, 682, 1024]),\n",
       "                            },\n",
       "                            LayerNorm_0: {\n",
       "                                bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=435, sizes=[1024]),\n",
       "                            },\n",
       "                            LayerNorm_1: {\n",
       "                                bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=436, sizes=[1024, 1024, 682]),\n",
       "                            },\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=439, sizes=[1024]),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=440, sizes=[1024]),\n",
       "                            scale: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=441, sizes=[1024]),\n",
       "                        },\n",
       "                        LayerNorm_2: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=442, sizes=[1024]),\n",
       "                        },\n",
       "                        LayerNorm_3: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=443, sizes=[1024]),\n",
       "                            scale: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=444, sizes=[1024]),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartDecoderLayer_8: {\n",
       "                        FlaxBartAttention_0: {\n",
       "                            k_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=445, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            out_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=447, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            q_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=449, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            v_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=451, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                        },\n",
       "                        FlaxBartAttention_1: {\n",
       "                            k_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=453, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            out_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=455, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            q_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=457, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            v_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=459, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                        },\n",
       "                        GLU_0: {\n",
       "                            Dense_0: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=461, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                            },\n",
       "                            Dense_1: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=467, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                            },\n",
       "                            Dense_2: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=473, sizes=[1024, 1024, 1024, 1024, 682, 1024]),\n",
       "                            },\n",
       "                            LayerNorm_0: {\n",
       "                                bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=479, sizes=[1024]),\n",
       "                            },\n",
       "                            LayerNorm_1: {\n",
       "                                bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=480, sizes=[1024, 1024, 682]),\n",
       "                            },\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=483, sizes=[1024]),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=484, sizes=[1024]),\n",
       "                            scale: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=485, sizes=[1024]),\n",
       "                        },\n",
       "                        LayerNorm_2: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=486, sizes=[1024]),\n",
       "                        },\n",
       "                        LayerNorm_3: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=487, sizes=[1024]),\n",
       "                            scale: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=488, sizes=[1024]),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartDecoderLayer_9: {\n",
       "                        FlaxBartAttention_0: {\n",
       "                            k_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=489, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            out_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=491, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            q_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=493, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            v_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=495, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                        },\n",
       "                        FlaxBartAttention_1: {\n",
       "                            k_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=497, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            out_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=499, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            q_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=501, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            v_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=503, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                        },\n",
       "                        GLU_0: {\n",
       "                            Dense_0: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=505, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                            },\n",
       "                            Dense_1: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=511, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                            },\n",
       "                            Dense_2: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=517, sizes=[1024, 1024, 1024, 1024, 682, 1024]),\n",
       "                            },\n",
       "                            LayerNorm_0: {\n",
       "                                bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=523, sizes=[1024]),\n",
       "                            },\n",
       "                            LayerNorm_1: {\n",
       "                                bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=524, sizes=[1024, 1024, 682]),\n",
       "                            },\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=527, sizes=[1024]),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=528, sizes=[1024]),\n",
       "                            scale: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=529, sizes=[1024]),\n",
       "                        },\n",
       "                        LayerNorm_2: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=530, sizes=[1024]),\n",
       "                        },\n",
       "                        LayerNorm_3: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=531, sizes=[1024]),\n",
       "                            scale: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=532, sizes=[1024]),\n",
       "                        },\n",
       "                    },\n",
       "                },\n",
       "            },\n",
       "            encoder: {\n",
       "                embed_positions: {\n",
       "                    embedding: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[64, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[64, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[64, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=533, sizes=[64, 1024]),\n",
       "                },\n",
       "                embed_tokens: {\n",
       "                    embedding: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[50300, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[50300, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[50300, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=535, sizes=[]),\n",
       "                },\n",
       "                final_ln: {\n",
       "                    bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=535, sizes=[1024]),\n",
       "                },\n",
       "                layernorm_embedding: {\n",
       "                    bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=536, sizes=[1024]),\n",
       "                    scale: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=537, sizes=[1024]),\n",
       "                },\n",
       "                layers: {\n",
       "                    FlaxBartEncoderLayer_0: {\n",
       "                        FlaxBartAttention_0: {\n",
       "                            k_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=538, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            out_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=540, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            q_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=542, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            v_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=544, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                        },\n",
       "                        GLU_0: {\n",
       "                            Dense_0: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=546, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                            },\n",
       "                            Dense_1: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=552, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                            },\n",
       "                            Dense_2: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=558, sizes=[1024, 1024, 1024, 1024, 682, 1024]),\n",
       "                            },\n",
       "                            LayerNorm_0: {\n",
       "                                bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=564, sizes=[1024]),\n",
       "                            },\n",
       "                            LayerNorm_1: {\n",
       "                                bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=565, sizes=[1024, 1024, 682]),\n",
       "                            },\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=568, sizes=[1024]),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=569, sizes=[1024]),\n",
       "                            scale: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=570, sizes=[1024]),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartEncoderLayer_1: {\n",
       "                        FlaxBartAttention_0: {\n",
       "                            k_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=571, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            out_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=573, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            q_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=575, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            v_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=577, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                        },\n",
       "                        GLU_0: {\n",
       "                            Dense_0: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=579, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                            },\n",
       "                            Dense_1: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=585, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                            },\n",
       "                            Dense_2: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=591, sizes=[1024, 1024, 1024, 1024, 682, 1024]),\n",
       "                            },\n",
       "                            LayerNorm_0: {\n",
       "                                bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=597, sizes=[1024]),\n",
       "                            },\n",
       "                            LayerNorm_1: {\n",
       "                                bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=598, sizes=[1024, 1024, 682]),\n",
       "                            },\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=601, sizes=[1024]),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=602, sizes=[1024]),\n",
       "                            scale: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=603, sizes=[1024]),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartEncoderLayer_10: {\n",
       "                        FlaxBartAttention_0: {\n",
       "                            k_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=604, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            out_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=606, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            q_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=608, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            v_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=610, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                        },\n",
       "                        GLU_0: {\n",
       "                            Dense_0: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=612, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                            },\n",
       "                            Dense_1: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=618, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                            },\n",
       "                            Dense_2: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=624, sizes=[1024, 1024, 1024, 1024, 682, 1024]),\n",
       "                            },\n",
       "                            LayerNorm_0: {\n",
       "                                bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=630, sizes=[1024]),\n",
       "                            },\n",
       "                            LayerNorm_1: {\n",
       "                                bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=631, sizes=[1024, 1024, 682]),\n",
       "                            },\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=634, sizes=[1024]),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=635, sizes=[1024]),\n",
       "                            scale: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=636, sizes=[1024]),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartEncoderLayer_11: {\n",
       "                        FlaxBartAttention_0: {\n",
       "                            k_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=637, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            out_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=639, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            q_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=641, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            v_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=643, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                        },\n",
       "                        GLU_0: {\n",
       "                            Dense_0: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=645, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                            },\n",
       "                            Dense_1: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=651, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                            },\n",
       "                            Dense_2: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=657, sizes=[1024, 1024, 1024, 1024, 682, 1024]),\n",
       "                            },\n",
       "                            LayerNorm_0: {\n",
       "                                bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=663, sizes=[1024]),\n",
       "                            },\n",
       "                            LayerNorm_1: {\n",
       "                                bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=664, sizes=[1024, 1024, 682]),\n",
       "                            },\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=667, sizes=[1024]),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=668, sizes=[1024]),\n",
       "                            scale: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=669, sizes=[1024]),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartEncoderLayer_2: {\n",
       "                        FlaxBartAttention_0: {\n",
       "                            k_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=670, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            out_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=672, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            q_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=674, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            v_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=676, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                        },\n",
       "                        GLU_0: {\n",
       "                            Dense_0: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=678, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                            },\n",
       "                            Dense_1: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=684, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                            },\n",
       "                            Dense_2: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=690, sizes=[1024, 1024, 1024, 1024, 682, 1024]),\n",
       "                            },\n",
       "                            LayerNorm_0: {\n",
       "                                bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=696, sizes=[1024]),\n",
       "                            },\n",
       "                            LayerNorm_1: {\n",
       "                                bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=697, sizes=[1024, 1024, 682]),\n",
       "                            },\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=700, sizes=[1024]),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=701, sizes=[1024]),\n",
       "                            scale: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=702, sizes=[1024]),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartEncoderLayer_3: {\n",
       "                        FlaxBartAttention_0: {\n",
       "                            k_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=703, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            out_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=705, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            q_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=707, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            v_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=709, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                        },\n",
       "                        GLU_0: {\n",
       "                            Dense_0: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=711, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                            },\n",
       "                            Dense_1: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=717, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                            },\n",
       "                            Dense_2: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=723, sizes=[1024, 1024, 1024, 1024, 682, 1024]),\n",
       "                            },\n",
       "                            LayerNorm_0: {\n",
       "                                bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=729, sizes=[1024]),\n",
       "                            },\n",
       "                            LayerNorm_1: {\n",
       "                                bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=730, sizes=[1024, 1024, 682]),\n",
       "                            },\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=733, sizes=[1024]),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=734, sizes=[1024]),\n",
       "                            scale: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=735, sizes=[1024]),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartEncoderLayer_4: {\n",
       "                        FlaxBartAttention_0: {\n",
       "                            k_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=736, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            out_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=738, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            q_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=740, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            v_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=742, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                        },\n",
       "                        GLU_0: {\n",
       "                            Dense_0: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=744, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                            },\n",
       "                            Dense_1: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=750, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                            },\n",
       "                            Dense_2: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=756, sizes=[1024, 1024, 1024, 1024, 682, 1024]),\n",
       "                            },\n",
       "                            LayerNorm_0: {\n",
       "                                bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=762, sizes=[1024]),\n",
       "                            },\n",
       "                            LayerNorm_1: {\n",
       "                                bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=763, sizes=[1024, 1024, 682]),\n",
       "                            },\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=766, sizes=[1024]),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=767, sizes=[1024]),\n",
       "                            scale: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=768, sizes=[1024]),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartEncoderLayer_5: {\n",
       "                        FlaxBartAttention_0: {\n",
       "                            k_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=769, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            out_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=771, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            q_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=773, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            v_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=775, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                        },\n",
       "                        GLU_0: {\n",
       "                            Dense_0: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=777, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                            },\n",
       "                            Dense_1: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=783, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                            },\n",
       "                            Dense_2: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=789, sizes=[1024, 1024, 1024, 1024, 682, 1024]),\n",
       "                            },\n",
       "                            LayerNorm_0: {\n",
       "                                bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=795, sizes=[1024]),\n",
       "                            },\n",
       "                            LayerNorm_1: {\n",
       "                                bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=796, sizes=[1024, 1024, 682]),\n",
       "                            },\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=799, sizes=[1024]),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=800, sizes=[1024]),\n",
       "                            scale: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=801, sizes=[1024]),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartEncoderLayer_6: {\n",
       "                        FlaxBartAttention_0: {\n",
       "                            k_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=802, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            out_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=804, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            q_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=806, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            v_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=808, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                        },\n",
       "                        GLU_0: {\n",
       "                            Dense_0: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=810, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                            },\n",
       "                            Dense_1: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=816, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                            },\n",
       "                            Dense_2: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=822, sizes=[1024, 1024, 1024, 1024, 682, 1024]),\n",
       "                            },\n",
       "                            LayerNorm_0: {\n",
       "                                bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=828, sizes=[1024]),\n",
       "                            },\n",
       "                            LayerNorm_1: {\n",
       "                                bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=829, sizes=[1024, 1024, 682]),\n",
       "                            },\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=832, sizes=[1024]),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=833, sizes=[1024]),\n",
       "                            scale: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=834, sizes=[1024]),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartEncoderLayer_7: {\n",
       "                        FlaxBartAttention_0: {\n",
       "                            k_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=835, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            out_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=837, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            q_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=839, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            v_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=841, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                        },\n",
       "                        GLU_0: {\n",
       "                            Dense_0: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=843, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                            },\n",
       "                            Dense_1: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=849, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                            },\n",
       "                            Dense_2: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=855, sizes=[1024, 1024, 1024, 1024, 682, 1024]),\n",
       "                            },\n",
       "                            LayerNorm_0: {\n",
       "                                bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=861, sizes=[1024]),\n",
       "                            },\n",
       "                            LayerNorm_1: {\n",
       "                                bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=862, sizes=[1024, 1024, 682]),\n",
       "                            },\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=865, sizes=[1024]),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=866, sizes=[1024]),\n",
       "                            scale: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=867, sizes=[1024]),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartEncoderLayer_8: {\n",
       "                        FlaxBartAttention_0: {\n",
       "                            k_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=868, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            out_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=870, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            q_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=872, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            v_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=874, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                        },\n",
       "                        GLU_0: {\n",
       "                            Dense_0: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=876, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                            },\n",
       "                            Dense_1: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=882, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                            },\n",
       "                            Dense_2: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=888, sizes=[1024, 1024, 1024, 1024, 682, 1024]),\n",
       "                            },\n",
       "                            LayerNorm_0: {\n",
       "                                bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=894, sizes=[1024]),\n",
       "                            },\n",
       "                            LayerNorm_1: {\n",
       "                                bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=895, sizes=[1024, 1024, 682]),\n",
       "                            },\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=898, sizes=[1024]),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=899, sizes=[1024]),\n",
       "                            scale: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=900, sizes=[1024]),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartEncoderLayer_9: {\n",
       "                        FlaxBartAttention_0: {\n",
       "                            k_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=901, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            out_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=903, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            q_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=905, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                            v_proj: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=907, sizes=[1024, 1024]),\n",
       "                            },\n",
       "                        },\n",
       "                        GLU_0: {\n",
       "                            Dense_0: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=909, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                            },\n",
       "                            Dense_1: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), momentum=QuantizedValue(quantized=PartitionSpec(None, 'mp'), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024, 2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=915, sizes=[1024, 1024, 1024, 1024, 1024, 682]),\n",
       "                            },\n",
       "                            Dense_2: {\n",
       "                                kernel: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), diagonal_momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), momentum=QuantizedValue(quantized=PartitionSpec('mp', None), diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730, 1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=921, sizes=[1024, 1024, 1024, 1024, 682, 1024]),\n",
       "                            },\n",
       "                            LayerNorm_0: {\n",
       "                                bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=927, sizes=[1024]),\n",
       "                            },\n",
       "                            LayerNorm_1: {\n",
       "                                bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[2730]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=928, sizes=[1024, 1024, 682]),\n",
       "                            },\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=931, sizes=[1024]),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=932, sizes=[1024]),\n",
       "                            scale: LocalShardedParameterStats(diagonal_statistics=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), diagonal_momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), momentum=QuantizedValue(quantized=None, diagonal=[], bucket_size=[], quantized_dtype=<class 'jax.numpy.float32'>, extract_diagonal=False, shape=[1024]), training_metrics=TrainingMetrics(inverse_pth_root_errors=PartitionSpec()), index_start=933, sizes=[1024]),\n",
       "                        },\n",
       "                    },\n",
       "                },\n",
       "            },\n",
       "        },\n",
       "    }))),\n",
       "}), apply_fn=<bound method FlaxBartPreTrainedModel.__call__ of <dalle_mini.model.modeling.DalleBart object at 0x1094455a0>>, tx={'standard': GradientTransformation(init=<function distributed_shampoo.<locals>.sharded_init_fn at 0x145bf13f0>, update=<function distributed_shampoo.<locals>.sharded_update_fn at 0x145bf1510>)}, dropout_rng=None, epoch=None, train_time=None, train_samples=None)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the result is a TrainState tree with all the leaves as PartitionSpec\n",
    "state_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2bc2fc-014b-48a9-82a1-7432aeefdd6a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### restore metadata \n",
    "\n",
    "it does not seem to do anything here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "268823a4-d6b5-472c-b051-edc05013345c",
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_state = {}\n",
    "keys = [\"train_time\", \"train_samples\"]\n",
    "attr_state = {k: v for k, v in model_metadata.items() if k in keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "77f4a56b-b754-4069-a76a-88da946fb464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attr_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520a4938-06fb-44e0-a02d-0dd0e29be72d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "26eb42fb-3906-4f45-8d9c-61ba82ad066d",
   "metadata": {},
   "source": [
    "## finally! create TrainState (pjit)\n",
    "\n",
    "we use the pjitted init_state function to create TrainState"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adeceb7-696b-4eca-996e-7f93cf87b923",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Refresh on default TrainState before dig ino dalle-mini TrainState"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d1aa66-7ce3-47a1-8050-17eafff2cdca",
   "metadata": {},
   "source": [
    "__default TrainState__\n",
    "\n",
    "here is how the we use TrainState in training, basically use __TrainState.create()__ to create initial state, and __state.apply_gradients()__ to update the state\n",
    "\n",
    "\n",
    "```python\n",
    "state = TrainState.create(\n",
    "          apply_fn=model.apply,\n",
    "          params=variables['params'],\n",
    "          tx=tx)\n",
    "grad_fn = jax.grad(make_loss_fn(state.apply_fn))\n",
    "for batch in data:\n",
    "    grads = grad_fn(state.params, batch)\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "__default optimizer__\n",
    "* the __optimizer__ is __tx__ argument we passed to TrainState.create - we do not interact with optimizer directly\n",
    "* it is created with __factory methods__ like `optax.adam()`, `optax.sgd()`\n",
    "* it is a __GradientTransformation__ object \n",
    "  * doc here https://optax.readthedocs.io/en/latest/api.html#optax.GradientTransformation\n",
    "  * it contains a pair of pure functions: __init__ and __update__\n",
    "    * __init__ (TransformInitFn)\n",
    "      * __input__: an example instance of the parameters whose gradients will be transformed (e.g. __params__)\n",
    "      * __output__: a pytree containing the initial value for the optimizer state. (initial __opt_state__)\n",
    "      * __how it's used with TrainState__: it's called during __TrainState.create()__:  `opt_state = tx.init(params)`\n",
    "      \n",
    "    * __update__ (TransformUpdateFn)\n",
    "      * __inputs__: \n",
    "        * a pytree of candidate updates \n",
    "          * e.g. their gradient with respect to some loss (__grads__)\n",
    "          * it needs to have same tree structure as the original params pytree passed to init function (same structure as params)\n",
    "        * the previous __opt_state__(__opt_state__)\n",
    "        * optionally, the current params. (__params__)\n",
    "      * __outputs__: the computed gradient updates, and a __new opt_state__.\n",
    "      * __how it's used with TrainState__: it is called during __TrainState.apply_gradients()__\n",
    "        \n",
    "        ```python\n",
    "        updates, new_opt_state = self.tx.update(grads, self.opt_state, self.params)\n",
    "        ```\n",
    "        \n",
    "      * update -> __optax.apply_update__ -> __new parameters__ -> new state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b16c1de-a986-4646-b6b8-bd5bc9c70e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the method to create an adam optimizer -> GradientTransformation\n",
    "type(optax.adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0974d48-c0cd-437a-83eb-3a4c46e165dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default optimizer -i.e. tx in default TrainState\n",
    "optimizer_d = optax.adam(learning_rate=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d992db-0332-4074-875b-61e2807ca1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e82d008-9cfa-4e43-9e50-b57bc64b7650",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_d.init(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbaaf2cc-58eb-4bd1-b11f-6ad5d8a7cf51",
   "metadata": {
    "tags": []
   },
   "source": [
    "### init_state: the function to create initial TrainState\n",
    "\n",
    "* init_state is __pjitted__ \n",
    "```python\n",
    "with mesh:\n",
    "    state = pjit(\n",
    "        init_state, # function\n",
    "        in_axis_resources= None,\n",
    "        out_axis_resources=state_spec,\n",
    "        donate_argnums=(0,),\n",
    "    )(params)\n",
    "`````\n",
    "\n",
    "* it wrapped around __TrainState.create()__ , and it will only have 1 input variable: __params__\n",
    "* in our case, __params = None__, so init_state will first __initialize the params__ with __model.init_weights__\n",
    "```python\n",
    "model.init_weights(rng_key, (1,1))\n",
    "```\n",
    "* since we pjit this function, our result, i.e. the initial state willbe nicely sharded based on __state_spec__\n",
    "\n",
    "\n",
    "we will go over all model.init_weights, dalle-mini's TrainState.create and pjit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6bcd2caa-09fb-49f2-8659-344a4e2c2b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_state(params):\n",
    "    return TrainState.create(\n",
    "                    apply_fn=model.__call__,\n",
    "                    tx=optimizer,\n",
    "                    params=maybe_init_params(params),\n",
    "                    dropout_rng=dropout_rng,\n",
    "                    **attr_state,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "abefd1e1-4f53-41e1-b0fc-a93442d0640b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# our params is None - so initialize it first\n",
    "def maybe_init_params(params):\n",
    "    if params is not None:\n",
    "        # model params are correctly loaded\n",
    "        return params\n",
    "    else:\n",
    "        # params have not been initialized yet\n",
    "        return model.init_weights(model.key, model.input_shape)\n",
    "initialized_params = maybe_init_params(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2414be06-03a9-4a76-b6cc-300e4b1be5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mesh:\n",
    "    state = pjit(\n",
    "        init_state, # function\n",
    "        in_axis_resources= None,\n",
    "        out_axis_resources=state_spec,\n",
    "        donate_argnums=(0,),\n",
    "    )(params)\n",
    "del params, opt_state_spec, opt_state_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4d325f-00fc-4767-8144-e1d5b40fe476",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### model.init_weights() -> params\n",
    "\n",
    "we use model.init_weights() to create initial params\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b81087-b4c4-401e-bf9f-e4453e282fe7",
   "metadata": {},
   "source": [
    "__about model.init_weighs__\n",
    "* our model(__DalleBart__) is a cusom `FlaxBartForCOnditionalGenerationModule` from huggingface ;and __model.init_weights__ method comes with `FlaxBartForCOnditionalGenerationModule`\n",
    "\n",
    "* usually, to create initial variable in flax, you do something like this. \n",
    "\n",
    "```python\n",
    "variable_init = model.init(rng_key, x)\n",
    "```\n",
    "* __model.init_weights__ is __wrapped around__ the __model.init()__ that we'are familar with. It will __created model inputs__ for you before calls model.init(); we will look at how these inputs are created one by one \n",
    "  * input_ids, attention_mask,\n",
    "  * decoder_input_ids,decoder_attention_mask,\n",
    "  * position_ids,decoder_position_ids\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd9e25d-4104-4566-b087-8781909c7c38",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# code\n",
    "model.init_weights??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9253705-742d-4e2d-acdc-7ee648974a87",
   "metadata": {},
   "source": [
    "__(1)input_ids__\n",
    "\n",
    "our dummy input_ids is an array of size __1x1__ : \n",
    "* __batch_size__ is 1, i.e. the batch contain only 1 sequence; batch size doesn't matter for model.init() since the shape of parameters will be same regardless batch size \n",
    "* __sequence length__ is 1, i.e. it only contains the __eos__ token (end of sentence token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "ff69144e-2713-4f00-ab4e-ad0d5650d0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# it shape 1 x 1 defined in FlaxBartPreTrainedModel (huggingface model)\n",
    "model.input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "401d8c64-efb3-4278-bb47-7feba1df2684",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = jnp.zeros(model.input_shape, dtype=\"i4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "280564c0-0975-4ec5-97e9-f5198f3a82e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "c286b883-4c7a-46b3-93cf-aee149f1e635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# end of sentence token\n",
    "model.config.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "e424aac6-3bb8-4d41-8dba-bbef9172ab8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sequence, replace last token as eos \n",
    "input_ids = input_ids.at[(..., -1)].set(model.config.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "691a55c5-ad70-453b-951e-fce6bad47095",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "e7e7160c-4e99-409c-ad9f-82e9f5687a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8816ff-8a21-414b-bb93-15334cde4e23",
   "metadata": {},
   "source": [
    "about __array.at[].set()__\n",
    "\n",
    "The __at__ property of jax numpy provides a functionally pure equivalent of in-place array modificatons.\n",
    "\n",
    "https://jax.readthedocs.io/en/latest/_autosummary/jax.numpy.ndarray.at.html\n",
    "\n",
    "let's see an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbeab4a-be24-460f-af7f-d0f9f65d4f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = jnp.zeros((2,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b89750d-dbea-467b-b286-a97061762ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ff21fe-2195-411e-8190-dce2ae93b89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tensor.at[(...,-1)].set(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c483e9db-c707-471c-9ccb-da1eb88d5175",
   "metadata": {},
   "source": [
    "__(2) attention_mask__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "da0b4601-5f77-4209-a461-bfd83d196dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_mask = jnp.ones_like(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "6a5f8872-7194-4419-a44f-bbef85c15250",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e791a9-038f-4a36-adc1-b96934a3655a",
   "metadata": {},
   "source": [
    "__(3)decoder_input_ids__  & __decoder_attention_mask__\n",
    "\n",
    "here we just set it same as input_ids \n",
    "\n",
    "- the actual inputs are not necessarily same, for model.init we only care about shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "1782e1a6-9af2-4134-8e49-7cdc8295f0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input_ids = input_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c597d5a2-7865-4811-b444-2c767e8f3153",
   "metadata": {},
   "source": [
    "decoder_attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "04cc385a-c3cf-4e2c-a146-c6a958c5e850",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_attention_mask = jnp.ones_like(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "d2e58385-bc6e-4b6b-8388-6275928b01cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_attention_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9adcc2bf-b9e1-4413-9201-5fb7ffde3978",
   "metadata": {},
   "source": [
    "__(4)position_ids__ is same shape as input_ids, and indicate the position of token in sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "59aca8c4-9d93-4dac-833e-c4af427aff5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, sequence_length = input_ids.shape\n",
    "position_ids = jnp.broadcast_to(jnp.arange(sequence_length)[None, :], (batch_size, sequence_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "1a5db116-e798-48cd-959f-7e9e18d2fa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, sequence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "f9ff4d7c-3305-4d58-a920-6995e032f231",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d6d31e-7d7f-4fb7-bad3-de1a36ebb4c2",
   "metadata": {},
   "source": [
    "__(5)decoder_position_ids__, same thing, indicate the position of the tokens in decoder_position_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "c2d5967d-7f2c-4363-bf98-b2483c88a575",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_position_ids = jnp.broadcast_to(jnp.arange(sequence_length)[None, :], (batch_size, sequence_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "7a60a4b3-27f5-4fa7-8576-30a61c3422bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_position_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bcd688-ca9c-45f9-ad78-cf74e31f729e",
   "metadata": {},
   "source": [
    "__(6)rngs__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "3ebbcfeb-747e-457b-a86d-cd54aa78783c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = model.key\n",
    "params_rng, dropout_rng = jax.random.split(rng)\n",
    "rngs = {\"params\": params_rng, \"dropout\": dropout_rng}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "8ca78e3e-ec44-4fad-81a6-e485fcb8b3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rngs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a84be4-f59f-4ed8-a2ae-e38ae44b69df",
   "metadata": {},
   "source": [
    "after created all the inputs, it will call __model.init()__ -> this returns a variable dict, and we will only get \"params\" dict (i.e. no other intermediate variables) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "395f841f-c025-4bca-a2bd-18304c5f6978",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_params = model.module.init(\n",
    "            rngs,\n",
    "            input_ids,\n",
    "            attention_mask,\n",
    "            decoder_input_ids,\n",
    "            decoder_attention_mask,\n",
    "            position_ids,\n",
    "            decoder_position_ids,\n",
    "        )[\"params\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "a0fdb1d1-35ae-4f13-a53d-2b79c68d9cf7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# initialized model parameters\n",
    "random_params.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2574fddd-b84c-4236-b137-2b19d81351b9",
   "metadata": {},
   "source": [
    "our initial parameters! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "f87589b6-98be-4543-bc93-15588bed369c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "jax.tree_map(lambda x:x.shape, random_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9829139-59af-49e3-8ae2-71b8987b7365",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### dalle-mini TrainState.create()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d67f8c-9f10-4f8e-b0e6-505bfa7729db",
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainState.create(\n",
    "                    apply_fn=model.__call__,\n",
    "                    tx=optimizer,\n",
    "                    params=maybe_init_params(params),\n",
    "                    dropout_rng=dropout_rng,\n",
    "                    **attr_state,\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33a19ba-9059-4ae2-ba6f-8d9882dd2173",
   "metadata": {},
   "source": [
    "dalle-mini's `TrainState.create` method custom defined - let's take a look here\n",
    "\n",
    "__flax TrainState.create__\n",
    "```python\n",
    "  @classmethod\n",
    "  def create(cls, *, apply_fn, params, tx, **kwargs):\n",
    "    \"\"\"Creates a new instance with `step=0` and initialized `opt_state`.\"\"\"\n",
    "    opt_state = tx.init(params)\n",
    "    return cls(\n",
    "        step=0,\n",
    "        apply_fn=apply_fn,\n",
    "        params=params,\n",
    "        tx=tx,\n",
    "        opt_state=opt_state,\n",
    "        **kwargs,\n",
    "    )\n",
    "```\n",
    "\n",
    "__dalle-mini TrainState.create__\n",
    " ```python\n",
    "  @classmethod\n",
    "        def create(cls, *, apply_fn, params, tx, **kwargs):\n",
    "            opt_state = {}\n",
    "            for k, p in split_params(\n",
    "                trainable_params(params, training_args.embeddings_only)\n",
    "            ).items():\n",
    "                init_fn = tx[k].init\n",
    "                if \"scanned\" in k:\n",
    "                    init_fn = jax.vmap(init_fn)\n",
    "                opt_state[k] = init_fn(p)\n",
    "            return cls(\n",
    "                step=0,\n",
    "                apply_fn=apply_fn,\n",
    "                params=params,\n",
    "                tx=tx,\n",
    "                opt_state=freeze(opt_state),\n",
    "                **kwargs,\n",
    "            )\n",
    " ```\n",
    "\n",
    "looks like the main difference is <u>how it creates __opt_state__ </u>\n",
    "* __opt_state__ contains __stateful optimizer properties__ such as the current step count when using optimizer scheduels, or momemtum values)\n",
    "* with the __flax default TrainState__, you do not have to worry about opt_state at all, it create the opt_state for you when you create the TrainState, and with one step <u>opt_state = tx.init(params)</u>\n",
    "\n",
    "* how __dalle-mini__ create opt_state:\n",
    "  * __tx__ is the __optimizer {}__ we create previously, it is a dict contains one GradientTransform object for each parameter group\n",
    "    * <font color=red>I actually don't think each parameter group should have different optimizer</font>\n",
    "  * for scanned groups, it init method expect parameter without the first dimension so we vmap the init\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "bdde6337-2ba0-441b-b3da-fa957201ec47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'standard': GradientTransformation(init=<function distributed_shampoo.<locals>.sharded_init_fn at 0x135895510>, update=<function distributed_shampoo.<locals>.sharded_update_fn at 0x14577aa70>)}"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tx\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9190f485-86ef-45b4-be5e-d31ed7964610",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### take a look at the state!\n",
    "* params - checkout which device the parameters are located\n",
    "* opt_state\n",
    "* tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "48bb0cf4-f182-408d-846a-abaae074a4c1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenDict({\n",
       "    lm_head: {\n",
       "        kernel: 8,\n",
       "    },\n",
       "    model: {\n",
       "        decoder: {\n",
       "            embed_positions: {\n",
       "                embedding: 8,\n",
       "            },\n",
       "            embed_tokens: {\n",
       "                embedding: 8,\n",
       "            },\n",
       "            final_ln: {\n",
       "                bias: 8,\n",
       "            },\n",
       "            layernorm_embedding: {\n",
       "                bias: 8,\n",
       "                scale: 8,\n",
       "            },\n",
       "            layers: {\n",
       "                FlaxBartDecoderLayer_0: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: 8,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: 8,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: 8,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: 8,\n",
       "                        scale: 8,\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: 8,\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: 8,\n",
       "                        scale: 8,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_1: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: 8,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: 8,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: 8,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: 8,\n",
       "                        scale: 8,\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: 8,\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: 8,\n",
       "                        scale: 8,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_10: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: 8,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: 8,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: 8,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: 8,\n",
       "                        scale: 8,\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: 8,\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: 8,\n",
       "                        scale: 8,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_11: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: 8,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: 8,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: 8,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: 8,\n",
       "                        scale: 8,\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: 8,\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: 8,\n",
       "                        scale: 8,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_2: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: 8,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: 8,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: 8,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: 8,\n",
       "                        scale: 8,\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: 8,\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: 8,\n",
       "                        scale: 8,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_3: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: 8,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: 8,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: 8,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: 8,\n",
       "                        scale: 8,\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: 8,\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: 8,\n",
       "                        scale: 8,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_4: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: 8,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: 8,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: 8,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: 8,\n",
       "                        scale: 8,\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: 8,\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: 8,\n",
       "                        scale: 8,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_5: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: 8,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: 8,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: 8,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: 8,\n",
       "                        scale: 8,\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: 8,\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: 8,\n",
       "                        scale: 8,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_6: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: 8,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: 8,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: 8,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: 8,\n",
       "                        scale: 8,\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: 8,\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: 8,\n",
       "                        scale: 8,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_7: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: 8,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: 8,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: 8,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: 8,\n",
       "                        scale: 8,\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: 8,\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: 8,\n",
       "                        scale: 8,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_8: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: 8,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: 8,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: 8,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: 8,\n",
       "                        scale: 8,\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: 8,\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: 8,\n",
       "                        scale: 8,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_9: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: 8,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: 8,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: 8,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: 8,\n",
       "                        scale: 8,\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: 8,\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: 8,\n",
       "                        scale: 8,\n",
       "                    },\n",
       "                },\n",
       "            },\n",
       "        },\n",
       "        encoder: {\n",
       "            embed_positions: {\n",
       "                embedding: 8,\n",
       "            },\n",
       "            embed_tokens: {\n",
       "                embedding: 8,\n",
       "            },\n",
       "            final_ln: {\n",
       "                bias: 8,\n",
       "            },\n",
       "            layernorm_embedding: {\n",
       "                bias: 8,\n",
       "                scale: 8,\n",
       "            },\n",
       "            layers: {\n",
       "                FlaxBartEncoderLayer_0: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: 8,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: 8,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: 8,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: 8,\n",
       "                        scale: 8,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_1: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: 8,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: 8,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: 8,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: 8,\n",
       "                        scale: 8,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_10: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: 8,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: 8,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: 8,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: 8,\n",
       "                        scale: 8,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_11: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: 8,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: 8,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: 8,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: 8,\n",
       "                        scale: 8,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_2: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: 8,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: 8,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: 8,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: 8,\n",
       "                        scale: 8,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_3: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: 8,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: 8,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: 8,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: 8,\n",
       "                        scale: 8,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_4: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: 8,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: 8,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: 8,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: 8,\n",
       "                        scale: 8,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_5: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: 8,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: 8,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: 8,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: 8,\n",
       "                        scale: 8,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_6: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: 8,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: 8,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: 8,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: 8,\n",
       "                        scale: 8,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_7: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: 8,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: 8,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: 8,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: 8,\n",
       "                        scale: 8,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_8: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: 8,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: 8,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: 8,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: 8,\n",
       "                        scale: 8,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_9: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: 8,\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: 8,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: 8,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: 8,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: 8,\n",
       "                        scale: 8,\n",
       "                    },\n",
       "                },\n",
       "            },\n",
       "        },\n",
       "    },\n",
       "})"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.tree_map(lambda x:len(x.device_buffers), state.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "fde11aa9-1eaa-40e3-a250-f3163c3dac0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ShardedDeviceArray([[ 0.00479484, -0.01371891,  0.01736489, ...,\n",
       "                      0.00192936, -0.01647965,  0.0104647 ],\n",
       "                    [ 0.01261756, -0.00530845,  0.020302  , ...,\n",
       "                     -0.02120532, -0.01396109,  0.02460307],\n",
       "                    [ 0.01544277, -0.0097948 , -0.00852894, ...,\n",
       "                     -0.01192724, -0.02051834,  0.00836666],\n",
       "                    ...,\n",
       "                    [ 0.01032733, -0.0217177 , -0.01968484, ...,\n",
       "                      0.01031603, -0.02904796,  0.03521425],\n",
       "                    [-0.01267449, -0.00052427,  0.03444157, ...,\n",
       "                      0.00976225, -0.03176883,  0.01764944],\n",
       "                    [-0.01821935,  0.02054082,  0.00193599, ...,\n",
       "                     -0.02185882,  0.01647166, -0.02641456]],                   dtype=float32)"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take one parameter as an example \n",
    "p = state.params['lm_head']['kernel']\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "2517fecc-786a-4f93-925a-e4256f56a27c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8 devices, all duplicated arrays\n",
    "len(p.device_buffers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "7424c8a1-abcb-4402-87cb-8b8b3e2c9f56",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DeviceArray([[ 0.00479484, -0.01371891,  0.01736489, ...,  0.00192936,\n",
       "               -0.01647965,  0.0104647 ],\n",
       "              [ 0.01261756, -0.00530845,  0.020302  , ..., -0.02120532,\n",
       "               -0.01396109,  0.02460307],\n",
       "              [ 0.01544277, -0.0097948 , -0.00852894, ..., -0.01192724,\n",
       "               -0.02051834,  0.00836666],\n",
       "              ...,\n",
       "              [ 0.01032733, -0.0217177 , -0.01968484, ...,  0.01031603,\n",
       "               -0.02904796,  0.03521425],\n",
       "              [-0.01267449, -0.00052427,  0.03444157, ...,  0.00976225,\n",
       "               -0.03176883,  0.01764944],\n",
       "              [-0.01821935,  0.02054082,  0.00193599, ..., -0.02185882,\n",
       "                0.01647166, -0.02641456]], dtype=float32),\n",
       " DeviceArray([[ 0.00479484, -0.01371891,  0.01736489, ...,  0.00192936,\n",
       "               -0.01647965,  0.0104647 ],\n",
       "              [ 0.01261756, -0.00530845,  0.020302  , ..., -0.02120532,\n",
       "               -0.01396109,  0.02460307],\n",
       "              [ 0.01544277, -0.0097948 , -0.00852894, ..., -0.01192724,\n",
       "               -0.02051834,  0.00836666],\n",
       "              ...,\n",
       "              [ 0.01032733, -0.0217177 , -0.01968484, ...,  0.01031603,\n",
       "               -0.02904796,  0.03521425],\n",
       "              [-0.01267449, -0.00052427,  0.03444157, ...,  0.00976225,\n",
       "               -0.03176883,  0.01764944],\n",
       "              [-0.01821935,  0.02054082,  0.00193599, ..., -0.02185882,\n",
       "                0.01647166, -0.02641456]], dtype=float32),\n",
       " DeviceArray([[ 0.00479484, -0.01371891,  0.01736489, ...,  0.00192936,\n",
       "               -0.01647965,  0.0104647 ],\n",
       "              [ 0.01261756, -0.00530845,  0.020302  , ..., -0.02120532,\n",
       "               -0.01396109,  0.02460307],\n",
       "              [ 0.01544277, -0.0097948 , -0.00852894, ..., -0.01192724,\n",
       "               -0.02051834,  0.00836666],\n",
       "              ...,\n",
       "              [ 0.01032733, -0.0217177 , -0.01968484, ...,  0.01031603,\n",
       "               -0.02904796,  0.03521425],\n",
       "              [-0.01267449, -0.00052427,  0.03444157, ...,  0.00976225,\n",
       "               -0.03176883,  0.01764944],\n",
       "              [-0.01821935,  0.02054082,  0.00193599, ..., -0.02185882,\n",
       "                0.01647166, -0.02641456]], dtype=float32),\n",
       " DeviceArray([[ 0.00479484, -0.01371891,  0.01736489, ...,  0.00192936,\n",
       "               -0.01647965,  0.0104647 ],\n",
       "              [ 0.01261756, -0.00530845,  0.020302  , ..., -0.02120532,\n",
       "               -0.01396109,  0.02460307],\n",
       "              [ 0.01544277, -0.0097948 , -0.00852894, ..., -0.01192724,\n",
       "               -0.02051834,  0.00836666],\n",
       "              ...,\n",
       "              [ 0.01032733, -0.0217177 , -0.01968484, ...,  0.01031603,\n",
       "               -0.02904796,  0.03521425],\n",
       "              [-0.01267449, -0.00052427,  0.03444157, ...,  0.00976225,\n",
       "               -0.03176883,  0.01764944],\n",
       "              [-0.01821935,  0.02054082,  0.00193599, ..., -0.02185882,\n",
       "                0.01647166, -0.02641456]], dtype=float32),\n",
       " DeviceArray([[ 0.00479484, -0.01371891,  0.01736489, ...,  0.00192936,\n",
       "               -0.01647965,  0.0104647 ],\n",
       "              [ 0.01261756, -0.00530845,  0.020302  , ..., -0.02120532,\n",
       "               -0.01396109,  0.02460307],\n",
       "              [ 0.01544277, -0.0097948 , -0.00852894, ..., -0.01192724,\n",
       "               -0.02051834,  0.00836666],\n",
       "              ...,\n",
       "              [ 0.01032733, -0.0217177 , -0.01968484, ...,  0.01031603,\n",
       "               -0.02904796,  0.03521425],\n",
       "              [-0.01267449, -0.00052427,  0.03444157, ...,  0.00976225,\n",
       "               -0.03176883,  0.01764944],\n",
       "              [-0.01821935,  0.02054082,  0.00193599, ..., -0.02185882,\n",
       "                0.01647166, -0.02641456]], dtype=float32),\n",
       " DeviceArray([[ 0.00479484, -0.01371891,  0.01736489, ...,  0.00192936,\n",
       "               -0.01647965,  0.0104647 ],\n",
       "              [ 0.01261756, -0.00530845,  0.020302  , ..., -0.02120532,\n",
       "               -0.01396109,  0.02460307],\n",
       "              [ 0.01544277, -0.0097948 , -0.00852894, ..., -0.01192724,\n",
       "               -0.02051834,  0.00836666],\n",
       "              ...,\n",
       "              [ 0.01032733, -0.0217177 , -0.01968484, ...,  0.01031603,\n",
       "               -0.02904796,  0.03521425],\n",
       "              [-0.01267449, -0.00052427,  0.03444157, ...,  0.00976225,\n",
       "               -0.03176883,  0.01764944],\n",
       "              [-0.01821935,  0.02054082,  0.00193599, ..., -0.02185882,\n",
       "                0.01647166, -0.02641456]], dtype=float32),\n",
       " DeviceArray([[ 0.00479484, -0.01371891,  0.01736489, ...,  0.00192936,\n",
       "               -0.01647965,  0.0104647 ],\n",
       "              [ 0.01261756, -0.00530845,  0.020302  , ..., -0.02120532,\n",
       "               -0.01396109,  0.02460307],\n",
       "              [ 0.01544277, -0.0097948 , -0.00852894, ..., -0.01192724,\n",
       "               -0.02051834,  0.00836666],\n",
       "              ...,\n",
       "              [ 0.01032733, -0.0217177 , -0.01968484, ...,  0.01031603,\n",
       "               -0.02904796,  0.03521425],\n",
       "              [-0.01267449, -0.00052427,  0.03444157, ...,  0.00976225,\n",
       "               -0.03176883,  0.01764944],\n",
       "              [-0.01821935,  0.02054082,  0.00193599, ..., -0.02185882,\n",
       "                0.01647166, -0.02641456]], dtype=float32),\n",
       " DeviceArray([[ 0.00479484, -0.01371891,  0.01736489, ...,  0.00192936,\n",
       "               -0.01647965,  0.0104647 ],\n",
       "              [ 0.01261756, -0.00530845,  0.020302  , ..., -0.02120532,\n",
       "               -0.01396109,  0.02460307],\n",
       "              [ 0.01544277, -0.0097948 , -0.00852894, ..., -0.01192724,\n",
       "               -0.02051834,  0.00836666],\n",
       "              ...,\n",
       "              [ 0.01032733, -0.0217177 , -0.01968484, ...,  0.01031603,\n",
       "               -0.02904796,  0.03521425],\n",
       "              [-0.01267449, -0.00052427,  0.03444157, ...,  0.00976225,\n",
       "               -0.03176883,  0.01764944],\n",
       "              [-0.01821935,  0.02054082,  0.00193599, ..., -0.02185882,\n",
       "                0.01647166, -0.02641456]], dtype=float32)]"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the parameter is duplicated across the devices\n",
    "p.device_buffers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "0d5d2585-da99-4c8f-8959-06ebb7873861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 16401)"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "5e31f233-ddde-4c5c-b286-e14037029b0d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PartitionSpec(None, 'mp')"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_spec.params['lm_head']['kernel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "433640f7-eed7-45a3-baec-ed1f8c7c7c5e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'standard': GradientTransformation(init=<function distributed_shampoo.<locals>.sharded_init_fn at 0x14a9d3520>, update=<function distributed_shampoo.<locals>.sharded_update_fn at 0x14a9d2200>)}"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a8a9cd-4b1c-47c3-9c00-d0707dec766a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "64752c9f-e3ff-4540-bbe4-e032fb02acd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prod(val) : \n",
    "    res = 1 \n",
    "    for ele in val: \n",
    "        res *= ele \n",
    "    return res  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "63d120d4-640c-42a0-bf3b-661047655d6b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9l/9hm851zx7qgfkmls0h72j82r0000gn/T/ipykernel_27605/3405161829.py:1: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  jax.tree_leaves(jax.tree_map(lambda x: prod(x.shape), state.opt_state['standard']))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 981467136,\n",
       " 981467136,\n",
       " 936,\n",
       " 16794624,\n",
       " 16794624,\n",
       " 16794624,\n",
       " 1,\n",
       " 262144,\n",
       " 262144,\n",
       " 262144,\n",
       " 2,\n",
       " 16794624,\n",
       " 16794624,\n",
       " 16794624,\n",
       " 1,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 6,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 6,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 6,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 2730,\n",
       " 2730,\n",
       " 2730,\n",
       " 3,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 6,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 6,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 6,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 2730,\n",
       " 2730,\n",
       " 2730,\n",
       " 3,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 6,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 6,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 6,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 2730,\n",
       " 2730,\n",
       " 2730,\n",
       " 3,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 6,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 6,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 6,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 2730,\n",
       " 2730,\n",
       " 2730,\n",
       " 3,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 6,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 6,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 6,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 2730,\n",
       " 2730,\n",
       " 2730,\n",
       " 3,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 6,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 6,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 6,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 2730,\n",
       " 2730,\n",
       " 2730,\n",
       " 3,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 6,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 6,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 6,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 2730,\n",
       " 2730,\n",
       " 2730,\n",
       " 3,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 6,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 6,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 6,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 2730,\n",
       " 2730,\n",
       " 2730,\n",
       " 3,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 6,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 6,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 6,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 2730,\n",
       " 2730,\n",
       " 2730,\n",
       " 3,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 6,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 6,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 6,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 2730,\n",
       " 2730,\n",
       " 2730,\n",
       " 3,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 6,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 6,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 6,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 2730,\n",
       " 2730,\n",
       " 2730,\n",
       " 3,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 6,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 6,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 6,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 2730,\n",
       " 2730,\n",
       " 2730,\n",
       " 3,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 65536,\n",
       " 65536,\n",
       " 65536,\n",
       " 2,\n",
       " 51507200,\n",
       " 51507200,\n",
       " 51507200,\n",
       " 1,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 6,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 6,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 2795520,\n",
       " 6,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " 2730,\n",
       " 2730,\n",
       " 2730,\n",
       " 3,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1,\n",
       " ...]"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.tree_leaves(jax.tree_map(lambda x: prod(x.shape), state.opt_state['standard']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "a53b0842-c359-43fa-ab5c-00dd438a789d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GlobalShardedParameterStats(statistics=ShapeDtypeStruct(shape=(936, 1024, 1024), dtype=float32), preconditioners=ShapeDtypeStruct(shape=(936, 1024, 1024), dtype=float32), exponents=ShapeDtypeStruct(shape=(936,), dtype=int32))"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.eval_shape(lambda x:x ,state.opt_state['standard'].stats.global_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1de073-206c-445f-98ac-4d43b98af3c3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### init variables for training: local_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ec37a1bf-253a-4db6-b5c3-16c011ef18bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep local copy of state\n",
    "# basically get some state: step, epoch, train_time and train_samples, transfer them to host as numpy array\n",
    "local_state = {\n",
    "    k: jax.device_get(getattr(state, k)).item()\n",
    "    for k in [\"step\", \"epoch\", \"train_time\", \"train_samples\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "2bdcd823-4c1d-4683-b5d2-65ad6afd89bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ShardedDeviceArray(0, dtype=int32, weak_type=True)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dalle-mini trainstate has some additional fields: epoch, train_time, train_samples\n",
    "# all dupolicated across the dp \n",
    "state.step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6eb14db9-0415-435f-9254-1ba3ccd330cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0, dtype=int32)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use device_get to transfer to host\n",
    "jax.device_get(state.step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "6336c721-ad45-4a8a-a458-453ec3a3f1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'step': 0, 'epoch': 0, 'train_time': 0.0, 'train_samples': 0}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "7fac9890-6e8b-4477-8c8d-728fa69bf922",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch ... (1/3):   0%|                                                                                                                                 | 0/3 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# init variables for training\n",
    "start_time = time.perf_counter() - local_state[\"train_time\"]\n",
    "train_metrics = None\n",
    "evaluation_ran = False\n",
    "save_model_ran = False\n",
    "epochs = tqdm(\n",
    "        range(local_state[\"epoch\"], num_epochs),\n",
    "        desc=f\"Epoch ... (1/{num_epochs})\",\n",
    "        position=0,\n",
    "        disable=jax.process_index() > 0,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "0c53a3f4-d043-4097-8556-f27cece585c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch ... (1/3):   0%|                                                                                                                                 | 0/3 [00:01<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# training start\n",
    "# first epoch\n",
    "epoch = next(iter(epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "48dfed2c-51ed-434a-a42e-f6e8788f2812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "658f4170-6348-49bb-a231-a791842f1873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update epoch in both TrainState and the local_state\n",
    "state = state.replace(epoch=epoch)\n",
    "local_state[\"epoch\"] = epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "575cbfe6-a104-4a28-9e09-30850953a0ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# it is not a ShardedDeviceArray anymore??\n",
    "state.epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585d94cd-9eca-44b8-844e-e713698513c6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### create one batch \n",
    "\n",
    "it could have 3 different shapes depends on if you use_vmap_trick and gradient_accumulation_steps\n",
    "\n",
    "since our batch is a dict, we will only look at __\"input_ids\"__ as example\n",
    "* if we don't use vmap trick and set accumulate_gradient_steps =1, we will have our batch (272, 64)\n",
    "* if we use __vmap_trick__, but not accumulate gradient, we have (8, 34, 64)\n",
    "* if we use __vmap_trick__ and __accumulate gradients__ for every 3 steps, we would have one more dimension for gradient accumulation, (3, 8, 34, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "9d4c1739-448a-4c86-8483-c004b3fdf643",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_groups = max(1, \n",
    "                  training_args.mp_devices // jax.local_device_count()\n",
    "                )\n",
    "loader_bs = batch_size_per_node * node_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "76816a98-d278-4f25-889a-8f3e3900ca40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args.per_device_train_batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "2648f7fb-196e-494c-a915-924aba93fcde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args.gradient_accumulation_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "a42922a3-cddd-4f87-8184-f0c469acb9d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "816"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch_size * dp axis size * gradient accumulation \n",
    "34 * 8 * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "492e490f-65d1-401c-8c01-534414974301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "816"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size_per_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "c499a739-ac3f-40fc-b963-60dfa53cefce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = dataset.dataloader(\n",
    "                    \"train\",\n",
    "                    loader_bs,\n",
    "                    epoch,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "4567ea18-17a2-4150-8ec4-fbf1a883dbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 1 batch \n",
    "batch = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e87e2c9-164d-4ea3-bee2-89c3adc5be84",
   "metadata": {},
   "source": [
    "take a look at our batch! \n",
    "* `attention_mask` and `input_ids` is output from our tokenizer of __caption__ \n",
    "* `labels` is the encoded image from vqgan (256 discrete tokens -> index of codebook)\n",
    "* `decoder_input_ids` is `labels` shifted right, with bos token added in the 0 position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "7f085e36-dad6-4ec2-adc1-c48682a1e291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attention_mask': ShapeDtypeStruct(shape=(816, 64), dtype=int32),\n",
       " 'decoder_input_ids': ShapeDtypeStruct(shape=(816, 256), dtype=float32),\n",
       " 'input_ids': ShapeDtypeStruct(shape=(816, 64), dtype=int32),\n",
       " 'labels': ShapeDtypeStruct(shape=(816, 256), dtype=int32)}"
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.eval_shape(lambda x:x, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "372d6f65-3f31-4789-954a-96f1b7e02917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([[ 1139,  8447,  1989, ...,  1268,  9035,  7771],\n",
       "             [ 1270,  9889,  7580, ...,  1400,  5848,  2922],\n",
       "             [12167,  6598,   217, ...,  2881,  4644, 15282],\n",
       "             ...,\n",
       "             [ 5098,  4159,  1810, ...,  7491, 10627,   882],\n",
       "             [   23,  1556,  5360, ...,  5772, 12145,  9150],\n",
       "             [ 9296,  3029, 14899, ..., 10295,  7696, 11716]],            dtype=int32)"
      ]
     },
     "execution_count": 522,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "0e9aa716-2830-47b6-866e-d7aee6dc7af0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([[16384.,  1139.,  8447., ..., 13440.,  1268.,  9035.],\n",
       "             [16384.,  1270.,  9889., ...,  4817.,  1400.,  5848.],\n",
       "             [16384., 12167.,  6598., ...,  6882.,  2881.,  4644.],\n",
       "             ...,\n",
       "             [16384.,  5098.,  4159., ..., 11342.,  7491., 10627.],\n",
       "             [16384.,    23.,  1556., ...,  8447.,  5772., 12145.],\n",
       "             [16384.,  9296.,  3029., ...,  7191., 10295.,  7696.]],            dtype=float32)"
      ]
     },
     "execution_count": 523,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['decoder_input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "55453cee-00fe-4220-9947-617fed5eacc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set correct batch size for pjit\n",
    "# this is based on our base config\n",
    "# i.e use_vmap_trick and accumulate gradients for 3 steps\n",
    "bs_shape = (jax.local_device_count()  // training_args.mp_devices,  # local dp devices\n",
    "                            training_args.per_device_train_batch_size,\n",
    "                        )\n",
    "if training_args.gradient_accumulation_steps > 1:\n",
    "                        # reshape data into (gradient_accumulation_steps, batch_per_node, ...)\n",
    "                        # to avoid any data redistribution when sharding\n",
    "                        bs_shape = (\n",
    "                            training_args.gradient_accumulation_steps,\n",
    "                        ) + bs_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "a78136af-1e62-4384-a359-2edfab8669f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 8, 34)"
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grad_step, dp, batch \n",
    "bs_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "id": "cf1ec3d3-0911-4eb9-90d8-83bffc608e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape batch - prepare for pjit\n",
    "batch = jax.tree_util.tree_map(\n",
    "    lambda x: x.reshape(bs_shape + x.shape[1:]),\n",
    "    batch,)\n",
    " # freeze batch to pass safely to jax transforms\n",
    "batch = freeze(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "id": "056cc985-e3a6-4079-8477-7c8569a945ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenDict({\n",
       "    attention_mask: ShapeDtypeStruct(shape=(3, 8, 34, 64), dtype=int32),\n",
       "    decoder_input_ids: ShapeDtypeStruct(shape=(3, 8, 34, 256), dtype=float32),\n",
       "    input_ids: ShapeDtypeStruct(shape=(3, 8, 34, 64), dtype=int32),\n",
       "    labels: ShapeDtypeStruct(shape=(3, 8, 34, 256), dtype=int32),\n",
       "})"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.eval_shape(lambda x:x, batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba6ac2a-c00a-4978-a251-0cf92d3c1bf4",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### create batch_simple\n",
    "\n",
    "* __batch_simple__ is a batch created <u>__without__ vmap_trick and gradient accumulation</u>, it has shape `(8*34, ...)`, where `dp=8`, `per_device_train_batch_size=34`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "979b7585-de93-4f36-9094-b0c22459af25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "272"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size_per_node_per_grad_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "91fa990e-6e3f-442d-a631-e74649b4d9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_simple = dataset.dataloader(\n",
    "                    \"train\",\n",
    "                    batch_size_per_node_per_grad_step,\n",
    "                    epoch,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "8d15a92b-50a6-4011-9715-be4b8d5d98d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_simple = next(iter(train_loader_simple))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "dabd324b-1ca4-424f-a313-ed6955a4a8f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attention_mask': ShapeDtypeStruct(shape=(272, 64), dtype=int32),\n",
       " 'decoder_input_ids': ShapeDtypeStruct(shape=(272, 256), dtype=float32),\n",
       " 'input_ids': ShapeDtypeStruct(shape=(272, 64), dtype=int32),\n",
       " 'labels': ShapeDtypeStruct(shape=(272, 256), dtype=int32)}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.eval_shape(lambda x:x, batch_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "eb3747ed-6992-413d-b6cb-56a96eafd8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_shape_simple = (batch_size_per_node_per_grad_step,)\n",
    "batch_simple = jax.tree_util.tree_map(\n",
    "    lambda x: x.reshape(bs_shape_simple + x.shape[1:]),\n",
    "    batch_simple,)\n",
    " # freeze batch to pass safely to jax transforms\n",
    "batch_simple = freeze(batch_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e4a77288-7828-43d3-88ec-6b5d9d5ff123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenDict({\n",
       "    attention_mask: ShapeDtypeStruct(shape=(272, 64), dtype=int32),\n",
       "    decoder_input_ids: ShapeDtypeStruct(shape=(272, 256), dtype=float32),\n",
       "    input_ids: ShapeDtypeStruct(shape=(272, 64), dtype=int32),\n",
       "    labels: ShapeDtypeStruct(shape=(272, 256), dtype=int32),\n",
       "})"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.eval_shape(lambda x:x, batch_simple)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906e8fde-af51-4ef9-aee8-c1494e492d4d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### create more specs: batch_spec, grad_batch_spec, grad_param_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd963153-43eb-4508-891f-e5cefb675afa",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "__batch_spec__ and __grad_batch_spec__ is used to partition the __minibatch__ \n",
    "```python\n",
    "   p_train_step = pjit(\n",
    "        train_step,\n",
    "        in_axis_resources=(\n",
    "            state_spec,\n",
    "            grad_batch_spec\n",
    "            if training_args.gradient_accumulation_steps > 1\n",
    "            else batch_spec,\n",
    "            None,\n",
    "        ),\n",
    "        out_axis_resources=(state_spec, None),\n",
    "        donate_argnums=(0,),\n",
    "    )\n",
    "  state, train_metrics = p_train_step(state, batch, train_time)\n",
    "```\n",
    "\n",
    "\n",
    "* __batch_spec__ is what we use to partition __minibatch__\n",
    "  * e.g. our minibatch is (272, 64), with a mesh (dp=8, mp=1)\n",
    "  * the __batch_spec ('dp',)__ will shard the batch dimension (272) over the 8 devices, each will have a slice __(34, 64)__\n",
    "  * <u>if we use __vmap_trick__</u>, our minibatch will have shape (8, 34, 64), the bath_spec (dp,) will result each device has __(1,34,64)__\n",
    "* __grad_batch_spec__ is also used to partition __minibatch__, when __gradient_accumulation_steps > 1__\n",
    "  * when the gradient_accumulation_steps > 1,e.g. gradient_accumulation_steps =3, our minibatch will have an additional grad_idx dimension (3, 272, 64)\n",
    "  * with a mesh (dp=8, mp=1), the grad_batch_spec __(None, 'dp')__ will shard the batch dimension (272) over the 8 devices, each will have a slice __(3, 34, 64)__\n",
    "  * if we use __vmap_trick__ and __gradient accumulation__, our batch will have shape (3,8,34,64), each device will have __(3,1,34,64)__\n",
    "  \n",
    "__param_spec__ and __grad_param_spec__ is used to partition __gradients__\n",
    "* __grad_param_spec__ is used to partition gradients (when we use vmap_trick)\n",
    "\n",
    "```python\n",
    "loss, grads = jax.vmap(\n",
    "                    grad_fn, in_axes=(None, 0, None), out_axes=(0, 0)\n",
    "                )(state.params, minibatch, dropout_rng)\n",
    "                # ensure they are sharded correctly\n",
    "                loss = with_sharding_constraint(loss, batch_spec)\n",
    "                grads = with_sharding_constraint(grads, grad_param_spec)\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "7754b46e-4128-4f8e-9cc0-562a038fd148",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_spec = PartitionSpec(\"dp\")\n",
    "grad_batch_spec = PartitionSpec(None, \"dp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "0971b993-e897-43e8-9b8a-0b8959f062e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PartitionSpec('dp',)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch_spec is what we use to partition minibatch - say it is (\n",
    "batch_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "f1c597f3-de5d-4ae8-88ad-1a0bf5b56e64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PartitionSpec(None, 'dp')"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_batch_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc2e290-0c1f-4cf1-ba7a-314c15db6497",
   "metadata": {},
   "source": [
    "we are using the \"vmap_trick\", not sure what it is yet, but it is to avoid a crash when mp_devices > 1\n",
    "https://wandb.ai/dalle-mini/dalle-mini/reports/JAX-pmap-vs-pjit--VmlldzoxNDg1ODA2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "4965f5d0-eae8-4ed6-8dc8-e38e5fb45218",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_vmap_trick = training_args.use_vmap_trick\n",
    "\n",
    "# make grad_param_spec for vmap\n",
    "if use_vmap_trick:\n",
    "    grad_param_spec = jax.tree_util.tree_map(\n",
    "        lambda x: PartitionSpec(*(\"dp\",) + (x if x is not None else (None,))),\n",
    "            param_spec,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "89c09a93-4190-49ec-aaa1-97d8b2c2ddd0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenDict({\n",
       "    lm_head: {\n",
       "        kernel: PartitionSpec('dp', None, 'mp'),\n",
       "    },\n",
       "    model: {\n",
       "        decoder: {\n",
       "            embed_positions: {\n",
       "                embedding: PartitionSpec('dp', 'mp', None),\n",
       "            },\n",
       "            embed_tokens: {\n",
       "                embedding: PartitionSpec('dp', 'mp', None),\n",
       "            },\n",
       "            final_ln: {\n",
       "                bias: None,\n",
       "            },\n",
       "            layernorm_embedding: {\n",
       "                bias: None,\n",
       "                scale: None,\n",
       "            },\n",
       "            layers: {\n",
       "                FlaxBartDecoderLayer_0: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('dp', 'mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('dp', 'mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('dp', 'mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_1: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('dp', 'mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('dp', 'mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('dp', 'mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_10: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('dp', 'mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('dp', 'mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('dp', 'mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_11: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('dp', 'mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('dp', 'mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('dp', 'mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_2: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('dp', 'mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('dp', 'mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('dp', 'mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_3: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('dp', 'mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('dp', 'mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('dp', 'mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_4: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('dp', 'mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('dp', 'mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('dp', 'mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_5: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('dp', 'mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('dp', 'mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('dp', 'mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_6: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('dp', 'mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('dp', 'mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('dp', 'mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_7: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('dp', 'mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('dp', 'mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('dp', 'mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_8: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('dp', 'mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('dp', 'mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('dp', 'mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_9: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('dp', 'mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('dp', 'mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('dp', 'mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "            },\n",
       "        },\n",
       "        encoder: {\n",
       "            embed_positions: {\n",
       "                embedding: PartitionSpec('dp', 'mp', None),\n",
       "            },\n",
       "            embed_tokens: {\n",
       "                embedding: PartitionSpec('dp', 'mp', None),\n",
       "            },\n",
       "            final_ln: {\n",
       "                bias: None,\n",
       "            },\n",
       "            layernorm_embedding: {\n",
       "                bias: None,\n",
       "                scale: None,\n",
       "            },\n",
       "            layers: {\n",
       "                FlaxBartEncoderLayer_0: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('dp', 'mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('dp', 'mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_1: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('dp', 'mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('dp', 'mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_10: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('dp', 'mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('dp', 'mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_11: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('dp', 'mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('dp', 'mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_2: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('dp', 'mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('dp', 'mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_3: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('dp', 'mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('dp', 'mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_4: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('dp', 'mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('dp', 'mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_5: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('dp', 'mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('dp', 'mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_6: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('dp', 'mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('dp', 'mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_7: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('dp', 'mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('dp', 'mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_8: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('dp', 'mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('dp', 'mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_9: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('dp', 'mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec('dp', None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('dp', 'mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "            },\n",
       "        },\n",
       "    },\n",
       "})"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# basically for each PartitionSpec in param_spec, add a leading dimension and shard over dp\n",
    "# don't know why we are dong this yet \n",
    "grad_param_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d56870-d5a8-4eca-b03a-6bb2aaad8abd",
   "metadata": {},
   "source": [
    "## !!train step\n",
    "\n",
    "how it is pjitted\n",
    "\n",
    "```python\n",
    "   p_train_step = pjit(\n",
    "        train_step,\n",
    "        in_axis_resources=(\n",
    "            state_spec,\n",
    "            grad_batch_spec\n",
    "            if training_args.gradient_accumulation_steps > 1\n",
    "            else batch_spec,\n",
    "            None,\n",
    "        ),\n",
    "        out_axis_resources=(state_spec, None),\n",
    "        donate_argnums=(0,),\n",
    "    )\n",
    " ```\n",
    "\n",
    "how it is used, after pjit, we call \n",
    "```python\n",
    "state, train_metrics = p_train_step(state, batch, train_time)\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "Let's see take step by step to understand how it is defined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb37174-29e9-4c44-8383-992092144b97",
   "metadata": {},
   "source": [
    "#### create dropout_rng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "10a02b0c-78f1-4de9-92a4-2031fc6a0a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_rng, _ = jax.random.split(state.dropout_rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "7a8a4de3-f667-4de7-9012-9afe6fe191ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([2465931498, 3679230171], dtype=uint32)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropout_rng"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00cd670-e3c5-488b-b973-315d4aba018e",
   "metadata": {},
   "source": [
    "#### shard the batch \n",
    "(based on batch_spec)\n",
    "\n",
    "use <u>with_sharding_constraint</u> to ensure data is sharded properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "5ede86fe-2a92-4be4-ae2b-10f2550a6785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# when training_args.gradient_accumulation_steps = 1 and use_vamp_trick is False\n",
    "minibatch = batch_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "49954494-4961-4050-a73e-2cbb2544573f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenDict({\n",
       "    attention_mask: ShapeDtypeStruct(shape=(272, 64), dtype=int32),\n",
       "    decoder_input_ids: ShapeDtypeStruct(shape=(272, 256), dtype=float32),\n",
       "    input_ids: ShapeDtypeStruct(shape=(272, 64), dtype=int32),\n",
       "    labels: ShapeDtypeStruct(shape=(272, 256), dtype=int32),\n",
       "})"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.eval_shape(lambda x:x, minibatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "15101bbd-77af-4381-9fee-de0ad62997b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pjit_fn_with = pjit(\n",
    "  lambda batch: with_sharding_constraint(minibatch, batch_spec),\n",
    "  in_axis_resources=batch_spec,\n",
    "  out_axis_resources=batch_spec)\n",
    "with mesh:\n",
    "    minibatch = pjit_fn_with(minibatch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "d2c21b5b-f29e-4c11-b4b7-4ebcd73d5e15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PartitionSpec('dp',)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "ccc55460-938b-41fb-9665-4abc7a22f1ed",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenDict({\n",
       "    attention_mask: ShapeDtypeStruct(shape=(272, 64), dtype=int32),\n",
       "    decoder_input_ids: ShapeDtypeStruct(shape=(272, 256), dtype=float32),\n",
       "    input_ids: ShapeDtypeStruct(shape=(272, 64), dtype=int32),\n",
       "    labels: ShapeDtypeStruct(shape=(272, 256), dtype=int32),\n",
       "})"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we shard the first dimension of batch_simple across the 8 devices on dp\n",
    "# each get 34\n",
    "jax.eval_shape(lambda x:x, minibatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "4041dece-fff1-40bb-9ba5-27dd9770fda8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenDict({\n",
       "    attention_mask: (34, 64),\n",
       "    decoder_input_ids: (34, 256),\n",
       "    input_ids: (34, 64),\n",
       "    labels: (34, 256),\n",
       "})"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.tree_map(lambda x:x.device_buffers[0].shape, minibatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "e64a853a-9c24-4fe5-9228-1b38b32afd4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(272, 256)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minibatch['labels'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "a7d0438d-2612-4916-b4a4-c6e4f22a62f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34, 256)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minibatch['labels'].device_buffers[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "03f79cf1-55e7-4388-8024-ce24bbb1916f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256,)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply jnp.mean() will bring the result back to the host \n",
    "jnp.mean(minibatch['labels'], axis=0).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df9aaf1-fbeb-42ac-a898-b2ebee15c79c",
   "metadata": {},
   "source": [
    "#### model.apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "e2ff6e56-0744-4766-a0c9-3c309dfacb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args, labels = minibatch.pop(\"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "015669fb-391d-4ce4-ba89-439f7a513fe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(272, 256)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "44937490-9b02-4256-b8d4-de6a6f337cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_labels = jax.tree_map(lambda x: x.device_buffers[0], labels)\n",
    "model_labels = jax.device_get(model_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "2d732ebb-44da-416c-bff7-6fd6904403bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = jax.tree_map(lambda x: x.device_buffers[0], model_args)\n",
    "model_args = jax.device_get(model_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "48c1fae1-1934-4a9f-8f92-4b805f55e9d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenDict({\n",
       "    attention_mask: (34, 64),\n",
       "    decoder_input_ids: (34, 256),\n",
       "    input_ids: (34, 64),\n",
       "})"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.tree_map(lambda x:x.shape, model_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "fbb21607-fa7e-4357-86b9-cb5c9ae77a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = jax.tree_map(lambda x: x.device_buffers[0], state.params)\n",
    "model_params = jax.device_get(model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "487d5f09-15bd-4484-af7d-aa5924b9ee30",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenDict({\n",
       "    lm_head: {\n",
       "        kernel: ShapeDtypeStruct(shape=(1024, 16401), dtype=float32),\n",
       "    },\n",
       "    model: {\n",
       "        decoder: {\n",
       "            embed_positions: {\n",
       "                embedding: ShapeDtypeStruct(shape=(256, 1024), dtype=float32),\n",
       "            },\n",
       "            embed_tokens: {\n",
       "                embedding: ShapeDtypeStruct(shape=(16401, 1024), dtype=float32),\n",
       "            },\n",
       "            final_ln: {\n",
       "                bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "            },\n",
       "            layernorm_embedding: {\n",
       "                bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "            },\n",
       "            layers: {\n",
       "                FlaxBartDecoderLayer_0: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_1: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_10: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_11: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_2: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_3: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_4: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_5: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_6: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_7: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_8: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_9: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                },\n",
       "            },\n",
       "        },\n",
       "        encoder: {\n",
       "            embed_positions: {\n",
       "                embedding: ShapeDtypeStruct(shape=(64, 1024), dtype=float32),\n",
       "            },\n",
       "            embed_tokens: {\n",
       "                embedding: ShapeDtypeStruct(shape=(50300, 1024), dtype=float32),\n",
       "            },\n",
       "            final_ln: {\n",
       "                bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "            },\n",
       "            layernorm_embedding: {\n",
       "                bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "            },\n",
       "            layers: {\n",
       "                FlaxBartEncoderLayer_0: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_1: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_10: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_11: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_2: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_3: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_4: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_5: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_6: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_7: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_8: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_9: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                },\n",
       "            },\n",
       "        },\n",
       "    },\n",
       "})"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.eval_shape(lambda x:x, model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "442ae4bd-a05b-46bc-8a9c-53ac94e3ed55",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = state.apply_fn(**model_args, \n",
    "                        params=model_params, \n",
    "                        dropout_rng=dropout_rng, \n",
    "                        train=True\n",
    "            )[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "27aa0070-ef12-4ec0-9247-c1c950e6f2ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method FlaxBartPreTrainedModel.__call__ of <dalle_mini.model.modeling.DalleBart object at 0x1094455a0>>"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.apply_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "66e6d7e8-19d9-4ace-a654-ed0ff3c80bcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34, 256, 16401)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "492b6aea-4577-4e30-a5d5-b6dab991c91b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34, 256, 16401)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot(model_labels, logits.shape[-1]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2857ff26-9890-4158-83f8-14fc208c2fd0",
   "metadata": {},
   "source": [
    "# model step by step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf7fb85-6196-4fde-947d-d67979ed12c8",
   "metadata": {},
   "source": [
    "## Review what's been done so far"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344652a9-116a-40fb-8aa5-1e56d9edbde7",
   "metadata": {},
   "source": [
    "__How model was created__\n",
    "```python\n",
    "model = DalleBart(\n",
    "            config,\n",
    "            seed=training_args.seed_model,\n",
    "            dtype=getattr(jnp, model_args.dtype),\n",
    "            _do_init=False,\n",
    "        )\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "c2482347-3f8a-4a37-93ad-46f031699fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`params` cannot be accessed from model when the model is created with `_do_init=False`. You must call `init_weights` manually and store the params outside of the model and pass it explicitly where needed.\n"
     ]
    }
   ],
   "source": [
    "# it was created with _do_init=False\n",
    "try: \n",
    "    model.params\n",
    "except ValueError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "e94174fd-369a-42b0-908d-3afc4d463747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FlaxBartForConditionalGenerationModule()"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "6569c295-4fd0-4680-a0cb-adb0750543e7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DalleBartConfig {\n",
       "  \"activation_dropout\": 0.0,\n",
       "  \"activation_function\": \"gelu\",\n",
       "  \"attention_dropout\": 0.0,\n",
       "  \"bos_token_id\": 16385,\n",
       "  \"d_model\": 1024,\n",
       "  \"decoder_attention_heads\": 16,\n",
       "  \"decoder_ffn_dim\": 2730,\n",
       "  \"decoder_layers\": 12,\n",
       "  \"decoder_start_token_id\": 16384,\n",
       "  \"do_sample\": true,\n",
       "  \"dropout\": 0.0,\n",
       "  \"encoder_attention_heads\": 16,\n",
       "  \"encoder_ffn_dim\": 2730,\n",
       "  \"encoder_layers\": 12,\n",
       "  \"encoder_vocab_size\": 50300,\n",
       "  \"eos_token_id\": 16385,\n",
       "  \"force_ln_scale\": false,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"image_length\": 256,\n",
       "  \"image_vocab_size\": 16400,\n",
       "  \"init_std\": 0.02,\n",
       "  \"is_encoder_decoder\": true,\n",
       "  \"ln_positions\": \"normformer\",\n",
       "  \"ln_type\": \"layernorm\",\n",
       "  \"max_length\": 257,\n",
       "  \"max_text_length\": 64,\n",
       "  \"min_length\": 257,\n",
       "  \"model_type\": \"dallebart\",\n",
       "  \"normalize_text\": true,\n",
       "  \"pad_token_id\": 16385,\n",
       "  \"scale_embedding\": false,\n",
       "  \"sinkhorn_iters\": 1,\n",
       "  \"tau_init\": 0.05,\n",
       "  \"tie_word_embeddings\": false,\n",
       "  \"transformers_version\": \"4.24.0.dev0\",\n",
       "  \"use_absolute_position_embeddings\": true,\n",
       "  \"use_alibi\": false,\n",
       "  \"use_bias\": false,\n",
       "  \"use_cache\": true,\n",
       "  \"use_cosine_attention\": false,\n",
       "  \"use_deepnet_scaling\": false,\n",
       "  \"use_final_ln_decoder\": true,\n",
       "  \"use_final_ln_encoder\": true,\n",
       "  \"use_glu\": true,\n",
       "  \"use_head_scale\": false,\n",
       "  \"use_scan\": false,\n",
       "  \"use_subln_init\": false,\n",
       "  \"use_swin_position_embeddings\": false\n",
       "}"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7050e6eb-bc35-4e50-986f-f999b86f7306",
   "metadata": {},
   "source": [
    "__How was model parameters initialized?__\n",
    "\n",
    "it was initialized __init_state__ function\n",
    "```python\n",
    "with mesh:\n",
    "    state = pjit(\n",
    "        init_state, # function\n",
    "        in_axis_resources= None,\n",
    "        out_axis_resources=state_spec,\n",
    "        donate_argnums=(0,),\n",
    "    )(params)\n",
    "`````\n",
    "\n",
    "* it wrapped around __TrainState.create()__ , the resulting function will only have 1 input variable: __params__\n",
    "* we passed __params = None__, so init_state will first __initialize the params__ with __model.init_weights__\n",
    "```python\n",
    "model.init_weights(rng_key, (1,1))\n",
    "```\n",
    "* since we pjit this function, our result, i.e. the __initial state__ willbe nicely sharded based on __state_spec__; particularlly, our __parameters__ are partitioned based on __param_spec__\n",
    "\n",
    "for this test purpose, I convert the parameter back to host -> model_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "f38eed05-882d-41ca-bfa6-a3a3da5c4b1c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenDict({\n",
       "    lm_head: {\n",
       "        kernel: ShapeDtypeStruct(shape=(1024, 16401), dtype=float32),\n",
       "    },\n",
       "    model: {\n",
       "        decoder: {\n",
       "            embed_positions: {\n",
       "                embedding: ShapeDtypeStruct(shape=(256, 1024), dtype=float32),\n",
       "            },\n",
       "            embed_tokens: {\n",
       "                embedding: ShapeDtypeStruct(shape=(16401, 1024), dtype=float32),\n",
       "            },\n",
       "            final_ln: {\n",
       "                bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "            },\n",
       "            layernorm_embedding: {\n",
       "                bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "            },\n",
       "            layers: {\n",
       "                FlaxBartDecoderLayer_0: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_1: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_10: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_11: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_2: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_3: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_4: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_5: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_6: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_7: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_8: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_9: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                },\n",
       "            },\n",
       "        },\n",
       "        encoder: {\n",
       "            embed_positions: {\n",
       "                embedding: ShapeDtypeStruct(shape=(64, 1024), dtype=float32),\n",
       "            },\n",
       "            embed_tokens: {\n",
       "                embedding: ShapeDtypeStruct(shape=(50300, 1024), dtype=float32),\n",
       "            },\n",
       "            final_ln: {\n",
       "                bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "            },\n",
       "            layernorm_embedding: {\n",
       "                bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "            },\n",
       "            layers: {\n",
       "                FlaxBartEncoderLayer_0: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_1: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_10: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_11: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_2: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_3: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_4: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_5: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_6: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_7: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_8: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_9: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 1024), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(1024, 2730), dtype=float32),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: ShapeDtypeStruct(shape=(2730, 1024), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: ShapeDtypeStruct(shape=(2730,), dtype=float32),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                        scale: ShapeDtypeStruct(shape=(1024,), dtype=float32),\n",
       "                    },\n",
       "                },\n",
       "            },\n",
       "        },\n",
       "    },\n",
       "})"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.eval_shape(lambda x:x , model_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0eed9c-ec81-4ca3-844b-ef239e865bf9",
   "metadata": {},
   "source": [
    "__model arguments dict__:\n",
    "\n",
    "I took one buffer in one device "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "32689c76-cd5c-4e7c-b68f-e23adda552af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenDict({\n",
       "    attention_mask: ShapeDtypeStruct(shape=(34, 64), dtype=int32),\n",
       "    decoder_input_ids: ShapeDtypeStruct(shape=(34, 256), dtype=float32),\n",
       "    input_ids: ShapeDtypeStruct(shape=(34, 64), dtype=int32),\n",
       "})"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.eval_shape(lambda x:x, model_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "228e413c-c421-409e-bf0c-0c229ab2d393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method FlaxBartPreTrainedModel.__call__ of <dalle_mini.model.modeling.DalleBart object at 0x1094455a0>>"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.apply_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d8ad77-3f68-44c3-9914-5322a61e0c52",
   "metadata": {},
   "source": [
    "## model structure\n",
    "```python\n",
    "\n",
    "(custom)              (transformers/bart)            (transformers/bart)        (transformers/modeling_flax_utils)\n",
    "DalleBart    ->  FlaxBartForConditionalGeneration  -> FlaxBartPreTrainedModel -> FlaxPreTrainedModel\n",
    "                                                       __call__\n",
    "  â¬‡ module_class                         â¬‡ module_class\n",
    "                                   \n",
    "FlaxBartForConditionalGenerationModule -> FlaxBartForConditionalGenerationModule\n",
    "(custom)                                     (transformers/bart)\n",
    "  __call__ \n",
    "    \n",
    "  â¬‡ lm_head      â¬‡ model     \n",
    "                                   \n",
    "  Dense         FlaxBartModule  ->  FlaxBartModule\n",
    "                (custom)            (transformers/bart)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d31da7-66f3-4dd2-b69d-b8e5944e1189",
   "metadata": {},
   "source": [
    "## prepare inputs\n",
    "\n",
    "`FlaxBartPreTrainedModel.__call__`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf1b8a5-757a-4359-925c-da0cf6bbd765",
   "metadata": {},
   "source": [
    "__model arguments__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "dce2a1a9-c44f-4940-98ee-84576db6d398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozen_dict_keys(['attention_mask', 'decoder_input_ids', 'input_ids'])"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_args.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "1e0eadcb-e8bc-474f-b170-f4cf8068f7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = model_args['input_ids']\n",
    "attention_mask = model_args['attention_mask']\n",
    "decoder_input_ids = model_args['decoder_input_ids']\n",
    "params=model_params \n",
    "dropout_rng=dropout_rng\n",
    "train=True\n",
    "\n",
    "# defaults\n",
    "decoder_attention_mask = None\n",
    "position_ids = None\n",
    "decoder_position_ids = None\n",
    "output_attentions = None\n",
    "output_hidden_states = None\n",
    "return_dict = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "04706cf0-2841-4a5e-bbe9-4408343ec3ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.output_attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "ecdb06af-00ed-458e-bb97-64e1b0fe2e7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.output_hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "e538fb36-21a6-4d94-a813-abaaa2c0c939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.return_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "fb8c9586-ffef-455c-aa14-306faba79fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_attentions = output_attentions if output_attentions is not None else model.config.output_attentions\n",
    "output_hidden_states = (\n",
    "    output_hidden_states if output_hidden_states is not None else model.config.output_hidden_states\n",
    "        )\n",
    "return_dict = return_dict if return_dict is not None else model.config.return_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4d8964-1b1c-483c-b559-9e5d06922f0b",
   "metadata": {},
   "source": [
    "__Inputs for BART encoder__\n",
    "\n",
    "captions are encoded through a BART encoder.\n",
    "\n",
    "* __input_ids__: tokenized caption\n",
    "* __attention_mask__: output of tokenizer as well, 0 indicating padding\n",
    "* __position_ids__: same shape as input_ids, indicate the position of token in each sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "bfb76107-5d0a-42ee-a9f3-fdf91cf6769c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the only thing we need to create is position_ids\n",
    "batch_size, sequence_length = input_ids.shape\n",
    "position_ids = jnp.broadcast_to(jnp.arange(sequence_length)[None, :], (batch_size, sequence_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "a135f06d-de86-4595-9286-3f27e9c07b2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,    75,  1455,    31,    11,  7315, 16612, 25641,  5072,\n",
       "        7406,    11,   176, 49895,   107,   820,   125, 10795,     2,\n",
       "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1], dtype=int32)"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenized caption (text input) \n",
    "# first sequence\n",
    "input_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "0746c814-1d90-4b2c-82cd-f608edee044f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# attention_mask, 0 for padding positions\n",
    "attention_mask[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "72a8a58b-777b-4b1c-bb5f-84f6c1c0cd74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34, 64)"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# position_ids indicate each token's position in the sequence 0 - 64\n",
    "input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "28a08fb5-c30d-434c-80a5-e08c47921ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14,\n",
       "             15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29,\n",
       "             30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44,\n",
       "             45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59,\n",
       "             60, 61, 62, 63], dtype=int32)"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_ids[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7992d27f-b52c-4991-a1b4-3d4eaab03da2",
   "metadata": {},
   "source": [
    "__Inputs for BART decoder__\n",
    "\n",
    "The __output of the BART encoder__ and __encoded images__ are fed through the __BART decoder__\n",
    "\n",
    "* __decoder_input_ids__:(same as \"labels\" (encoded image from vqgan encoder), but shift right 1 position, adding bos token)\n",
    "    * e.g. image -> tok1, tok2, tok3 -> bos, tok1, tok2\n",
    "* __decoder_attention_mask__: same shape as decoder_input_ids, but all 1\n",
    "* __decoder_position_ids__: same shape as decoder_input_ids, indicate position of the token in the sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "63c12784-98db-4e77-9f98-cad756c2cf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder_attention_mask\n",
    "if decoder_attention_mask is None:\n",
    "    decoder_attention_mask = jnp.ones_like(decoder_input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "d430abde-bff7-4da0-a161-4118d73d7014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder_position_ids\n",
    "if decoder_position_ids is None:\n",
    "            batch_size, sequence_length = decoder_input_ids.shape\n",
    "            decoder_position_ids = jnp.broadcast_to(\n",
    "                jnp.arange(sequence_length)[None, :], (batch_size, sequence_length)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "143ca0b6-32e0-4ee9-8933-a9da240d69ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34, 256)"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "4adde4bb-d443-45cf-94a3-2baa51462f0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16384.,  1304., 15525., 14164.,  7191.,  8173.,  1495., 16147.,\n",
       "        8173.,  2428.], dtype=float32)"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input_ids[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "f13e8a19-3327-4cb3-a8a1-fc0283b6918b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34, 256)"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_attention_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "4fcd59c6-1daa-4f26-9c2a-6391190bf012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int32)"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_position_ids[0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65da1981-c315-4095-9fba-9243763eecdf",
   "metadata": {},
   "source": [
    "from here, it calls\n",
    "\n",
    "```python\n",
    "self.module.apply(\n",
    "            {\"params\": params or self.params},\n",
    "            input_ids=jnp.array(input_ids, dtype=\"i4\"),\n",
    "            attention_mask=jnp.array(attention_mask, dtype=\"i4\"),\n",
    "            position_ids=jnp.array(position_ids, dtype=\"i4\"),\n",
    "            decoder_input_ids=jnp.array(decoder_input_ids, dtype=\"i4\"),\n",
    "            decoder_attention_mask=jnp.array(decoder_attention_mask, dtype=\"i4\"),\n",
    "            decoder_position_ids=jnp.array(decoder_position_ids, dtype=\"i4\"),\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "            deterministic=not train,\n",
    "            rngs=rngs,\n",
    "        )\n",
    "```\n",
    "\n",
    "where `self.module` is a dalle-mini custom  `FlaxBartForCOnditionalGenerationModule`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "d7af9eeb-f287-446a-986d-48d73dfef924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dropout': (DeviceArray([2465931498, 3679230171], dtype=uint32),)}"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rngs = {\"dropout\": dropout_rng} if dropout_rng is not None else {}\n",
    "rngs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "cd0a45fe-9aea-4bb1-aa5a-13e37d48bc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"params\": model_params}\n",
    "input_ids=jnp.array(input_ids, dtype=\"i4\")\n",
    "attention_mask=jnp.array(attention_mask, dtype=\"i4\")\n",
    "position_ids=jnp.array(position_ids, dtype=\"i4\")\n",
    "decoder_input_ids=jnp.array(decoder_input_ids, dtype=\"i4\")\n",
    "decoder_attention_mask=jnp.array(decoder_attention_mask, dtype=\"i4\")\n",
    "decoder_position_ids=jnp.array(decoder_position_ids, dtype=\"i4\")\n",
    "deterministic=not train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "c14d9e25-38e4-4ae2-8df9-61bf15f81544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deterministic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7397da80-465f-4e4f-a3f7-cc1642daa2e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "75a4558b-4005-4b0d-8306-c34e546e27fa",
   "metadata": {},
   "source": [
    "## self.module\n",
    "__custom FlaxBartForConditionalGenerationModule__\n",
    "\n",
    "\n",
    "* this module is the main interface for DalleBart, it defines the layers here\n",
    "  * lm_head (Dense)\n",
    "  * model (FlaxBartModule)\n",
    "* define `__call__` method\n",
    "```python\n",
    "outputs = self.model(...)\n",
    "hidden_states = outputs[0]\n",
    "lm_logits = self.lm_head(hidden_states)\n",
    "return FlaxSeq2SeqLMOutput(logits=lm_logits, ...)\n",
    "```\n",
    "\n",
    "inputs -> FlatBartModule -> outputs[0] -> lm_head -> logits? (this is what we take to compare against encoded images to calculate loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29c51b3-d3bb-4180-bf3b-878290978a13",
   "metadata": {},
   "source": [
    "### \"model\": FlaxBartModule\n",
    "* it is a __FlaxBartModule__ (dalle-mini custom)\n",
    "* defined custom __encoder__ and __decoder__ methods\n",
    "  * (\"model\",\"encoder\") -> __FlaxBartEncoder__\n",
    "  * (\"model\",\"decoder\") -> __FlaxBartDecoder__\n",
    "* create embeddings for encoder and decoder\n",
    "  * encoder_embed_tokens\n",
    "  * decoder_embded_tokens\n",
    "* inherit the `__call__` method from the FlaxBartModule (transformer/bart)\n",
    "```python\n",
    "encoder_outputs = self.encoder()\n",
    "decoder_outputs = self.decoder(\n",
    "            input_ids=decoder_input_ids,\n",
    "            attention_mask=decoder_attention_mask,\n",
    "            position_ids=decoder_position_ids,\n",
    "            encoder_hidden_states=encoder_outputs[0],\n",
    "            encoder_attention_mask=attention_mask,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "            deterministic=deterministic,\n",
    "        )\n",
    "return FlaxSeq2SeqModelOutput(\n",
    "            last_hidden_state=decoder_outputs.last_hidden_state,\n",
    "            decoder_hidden_states=decoder_outputs.hidden_states,\n",
    "            decoder_attentions=decoder_outputs.attentions,\n",
    "            cross_attentions=decoder_outputs.cross_attentions,\n",
    "            encoder_last_hidden_state=encoder_outputs.last_hidden_state,\n",
    "            encoder_hidden_states=encoder_outputs.hidden_states,\n",
    "            encoder_attentions=encoder_outputs.attentions,\n",
    "        )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9918a4b5-bfa5-4e9e-939a-22dbbb196c30",
   "metadata": {},
   "source": [
    "create encoder embedding: __(\"model\",\"encoder\",\"embed_tokens\")__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "ae9edd9a-d90e-4ae0-b725-79a35d07e756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50300"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vocab size for tokenizer (text)\n",
    "config.encoder_vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "b63f3079-a385-4d36-a337-9489a8543487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.d_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "e52e3ba8-4658-4abe-89ad-47425bde32f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_embed_tokens = nn.Embed(\n",
    "            config.encoder_vocab_size,\n",
    "            config.d_model,\n",
    "            embedding_init=jax.nn.initializers.normal(config.init_std),\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bf2961-6853-4529-bee8-b45ae7235b04",
   "metadata": {},
   "source": [
    "create decoder embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "c9a15708-439f-4ab2-bd66-eda4b96d3de4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embed(\n",
       "    # attributes\n",
       "    num_embeddings = 50300\n",
       "    features = 1024\n",
       "    dtype = None\n",
       "    param_dtype = float32\n",
       "    embedding_init = init\n",
       "    embedding = None\n",
       ")"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_embed_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "dc385ad6-0069-456a-8497-dda12e9dbb3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16400"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vocab size for image tokens (vqgan codebook size)\n",
    "config.image_vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "b79299b9-0532-499f-ae8e-ce890b615346",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_embed_tokens = nn.Embed(\n",
    "    config.image_vocab_size + 1,  # image vocab size + 1 for BOS\n",
    "    config.d_model,\n",
    "    embedding_init=jax.nn.initializers.normal(config.init_std),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "edc83792-9d17-40c6-afac-13912c203cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embed(\n",
       "    # attributes\n",
       "    num_embeddings = 16401\n",
       "    features = 1024\n",
       "    dtype = None\n",
       "    param_dtype = float32\n",
       "    embedding_init = init\n",
       "    embedding = None\n",
       ")"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_embed_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65c723b-57ff-4f0f-9313-71bfe5431bda",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### define FlaxBartEncoder and FlaxBartDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "8a9bf13c-8f3f-427a-924b-751b18af2594",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlaxBartEncoder(nn.Module):\n",
    "    config: DalleBartConfig\n",
    "    embed_tokens: nn.Embed\n",
    "    dtype: jnp.dtype = jnp.float32  # the dtype of the computation\n",
    "    \"\"\"\n",
    "    Edits:\n",
    "    - offset set to 0 (no padding token)\n",
    "    - use max_text_length instead of max_position_embeddings\n",
    "    - use custom FlaxBartEncoderLayerCollection\n",
    "    - embed_tokens cannot be None (issue at compile time)\n",
    "    \"\"\"\n",
    "\n",
    "    def setup(self):\n",
    "        self.dropout_layer = nn.Dropout(rate=self.config.dropout)\n",
    "\n",
    "        embed_dim = self.config.d_model\n",
    "        self.padding_idx = self.config.pad_token_id\n",
    "        self.embed_scale = math.sqrt(embed_dim) if self.config.scale_embedding else 1.0\n",
    "\n",
    "        # Bart is set up so that if padding_idx is specified then offset the embedding ids by 2\n",
    "        # and adjust num_embeddings appropriately. Other models don't have this hack\n",
    "        self.offset = 0\n",
    "        if self.config.use_absolute_position_embeddings:\n",
    "            self.embed_positions = nn.Embed(\n",
    "                self.config.max_text_length + self.offset,  # image length for BOS\n",
    "                embed_dim,\n",
    "                embedding_init=jax.nn.initializers.normal(self.config.init_std),\n",
    "            )\n",
    "        self.layers = FlaxBartEncoderLayerCollection(self.config, self.dtype)\n",
    "        self.layernorm_embedding = norm(\n",
    "            self.config.ln_type, dtype=self.dtype, epsilon=1e-05\n",
    "        )\n",
    "\n",
    "        # postln is already applied in every layer\n",
    "        if self.config.use_final_ln_encoder and self.config.ln_positions != \"postln\":\n",
    "            self.final_ln = norm(\n",
    "                self.config.ln_type,\n",
    "                dtype=self.dtype,\n",
    "                epsilon=1e-05,\n",
    "                use_scale=self.config.force_ln_scale,\n",
    "            )\n",
    "        else:\n",
    "            self.final_ln = None\n",
    "\n",
    "    def __call__(\n",
    "        self,\n",
    "        input_ids,\n",
    "        attention_mask,\n",
    "        position_ids,\n",
    "        output_attentions: bool = False,\n",
    "        output_hidden_states: bool = False,\n",
    "        return_dict: bool = True,\n",
    "        deterministic: bool = True,\n",
    "    ):\n",
    "        input_shape = input_ids.shape\n",
    "        input_ids = input_ids.reshape(-1, input_shape[-1])\n",
    "\n",
    "        hidden_states = self.embed_tokens(input_ids) * self.embed_scale\n",
    "\n",
    "        if self.config.use_absolute_position_embeddings:\n",
    "            embed_pos = self.embed_positions(position_ids + self.offset)\n",
    "            hidden_states = hidden_states + embed_pos\n",
    "\n",
    "        hidden_states = self.layernorm_embedding(hidden_states)\n",
    "        hidden_states = self.dropout_layer(hidden_states, deterministic=deterministic)\n",
    "\n",
    "        outputs = self.layers(\n",
    "            hidden_states,\n",
    "            attention_mask,\n",
    "            deterministic=deterministic,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        if self.final_ln is None:\n",
    "            final_output = outputs[0]\n",
    "        else:\n",
    "            final_output = self.final_ln(outputs[0])\n",
    "\n",
    "        if not return_dict:\n",
    "            return (final_output,) + outputs[1:]\n",
    "\n",
    "        return FlaxBaseModelOutput(\n",
    "            last_hidden_state=final_output,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )\n",
    "\n",
    "class FlaxBartDecoder(nn.Module):\n",
    "    config: DalleBartConfig\n",
    "    embed_tokens: nn.Embed\n",
    "    dtype: jnp.dtype = jnp.float32  # the dtype of the computation\n",
    "    \"\"\"\n",
    "    Edits:\n",
    "    - offset set to 0 (no padding token)\n",
    "    - use image_length instead of max_position_embeddings\n",
    "    - use custom FlaxBartDecoderLayerCollection\n",
    "    - embed_tokens cannot be None (issue at compile time)\n",
    "    \"\"\"\n",
    "\n",
    "    def setup(self):\n",
    "        self.dropout_layer = nn.Dropout(rate=self.config.dropout)\n",
    "\n",
    "        embed_dim = self.config.d_model\n",
    "        self.padding_idx = self.config.pad_token_id\n",
    "        self.embed_scale = (\n",
    "            math.sqrt(self.config.d_model) if self.config.scale_embedding else 1.0\n",
    "        )\n",
    "\n",
    "        # Bart is set up so that if padding_idx is specified then offset the embedding ids by 2\n",
    "        # and adjust num_embeddings appropriately. Other models don't have this hack\n",
    "        self.offset = 0\n",
    "        if self.config.use_absolute_position_embeddings:\n",
    "            self.embed_positions = nn.Embed(\n",
    "                self.config.image_length + self.offset,  # image length for BOS\n",
    "                embed_dim,\n",
    "                embedding_init=jax.nn.initializers.normal(self.config.init_std),\n",
    "            )\n",
    "\n",
    "        self.layers = FlaxBartDecoderLayerCollection(self.config, self.dtype)\n",
    "        self.layernorm_embedding = norm(\n",
    "            self.config.ln_type, dtype=self.dtype, epsilon=1e-05\n",
    "        )\n",
    "\n",
    "        # postln is already applied in every layer\n",
    "        if self.config.use_final_ln_decoder and self.config.ln_positions != \"postln\":\n",
    "            self.final_ln = norm(\n",
    "                self.config.ln_type,\n",
    "                dtype=self.dtype,\n",
    "                epsilon=1e-05,\n",
    "                use_scale=self.config.force_ln_scale,\n",
    "            )\n",
    "\n",
    "    def __call__(\n",
    "        self,\n",
    "        input_ids,\n",
    "        attention_mask,\n",
    "        position_ids,\n",
    "        encoder_hidden_states: Optional[jnp.ndarray] = None,\n",
    "        encoder_attention_mask: Optional[jnp.ndarray] = None,\n",
    "        init_cache: bool = False,\n",
    "        output_attentions: bool = False,\n",
    "        output_hidden_states: bool = False,\n",
    "        return_dict: bool = True,\n",
    "        deterministic: bool = True,\n",
    "    ):\n",
    "        input_shape = input_ids.shape\n",
    "        input_ids = input_ids.reshape(-1, input_shape[-1])\n",
    "\n",
    "        hidden_states = self.embed_tokens(input_ids) * self.embed_scale\n",
    "\n",
    "        if self.config.use_absolute_position_embeddings:\n",
    "            embed_pos = self.embed_positions(position_ids + self.offset)\n",
    "            hidden_states = hidden_states + embed_pos\n",
    "\n",
    "        hidden_states = self.layernorm_embedding(hidden_states)\n",
    "        hidden_states = self.dropout_layer(hidden_states, deterministic=deterministic)\n",
    "\n",
    "        outputs = self.layers(\n",
    "            hidden_states,\n",
    "            attention_mask,\n",
    "            encoder_hidden_states,\n",
    "            encoder_attention_mask,\n",
    "            deterministic=deterministic,\n",
    "            init_cache=init_cache,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        if self.final_ln is None:\n",
    "            final_output = outputs[0]\n",
    "        else:\n",
    "            final_output = self.final_ln(outputs[0])\n",
    "\n",
    "        if not return_dict:\n",
    "            return (final_output,) + outputs[1:]\n",
    "\n",
    "        return FlaxBaseModelOutputWithPastAndCrossAttentions(\n",
    "            last_hidden_state=final_output,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "            cross_attentions=outputs.cross_attentions,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884a40e0-bd44-49fb-acb5-83b4ba61343f",
   "metadata": {},
   "source": [
    "#### (\"model\",\"encoder\")\n",
    "\n",
    "FlaxBartEncoder (dalle-mini custom)\n",
    "\n",
    "__captions__ are encoded through a BART encoder.\n",
    "\n",
    "\n",
    "It is <u>defined in FlaxBartModule </u>\n",
    "\n",
    "create an __encoder__ now "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "b75638a7-0a33-463c-8d3f-d4cf4cc89485",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = FlaxBartEncoder(\n",
    "    config, dtype=model.dtype, embed_tokens=encoder_embed_tokens\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69da8146-b494-411b-856b-61388f1d85c5",
   "metadata": {},
   "source": [
    "walk through its` __call__` method step by step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c18cd61-c5e0-4e56-8bb7-74a3e745f849",
   "metadata": {},
   "source": [
    "__input_ids__ contains the tokenized captions, \n",
    "\n",
    "first we make sure it has the correct shape __(batch_size, sequence_length)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "f47b9bcd-cc15-4499-9703-b8955e22d490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34, 64)"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "b352297e-e574-4a4a-a6c6-0fc4a4cebe54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape input_ids, so it will have 2 dimensions: batch_size, sequence length\n",
    "input_shape = input_ids.shape\n",
    "input_ids = input_ids.reshape(-1, input_shape[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171cf69b-7713-4304-8d84-6e9e4197ed48",
   "metadata": {},
   "source": [
    "input_ids.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24200ff-e284-4ccd-a79d-373f38436d77",
   "metadata": {},
   "source": [
    "apply __encoder embedding__ and __position embedding layers__ \n",
    "\n",
    "```python\n",
    "\n",
    "     input_ids -> encoder.embed_tokens -> hidden_states (34,64,1024) \n",
    "                                                 â¬‡ï¸\n",
    "                                              N-grammer layer\n",
    "                                                 â¬‡ï¸\n",
    "                                        n-gram augmented embedding\n",
    "                                                 âž•                   \n",
    "nput_positions -> encoder.embed_positions -> embed_pos (34,64,1024)\n",
    "                                                 â¬‡ï¸\n",
    "                                          hidden_states (34,64,1024)\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "f3ef8eeb-eea1-4c1f-998b-5e5e28e82286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the parameters\n",
    "params_encoder_embed_tokens = model_params['model']['encoder']['embed_tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "5f0c4a68-e166-425d-9c7a-f65556e3acea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50300, 1024)"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_encoder_embed_tokens['embedding'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "10f8a2ed-29f7-447e-9a7f-5d93a68883d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_states = encoder.embed_tokens.apply(\n",
    "    {'params': params_encoder_embed_tokens},\n",
    "    input_ids,\n",
    "     rngs= None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6390ced-fee3-4501-a783-304294f2abbb",
   "metadata": {},
   "source": [
    "n-grammer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "19d4ead9-60ad-4904-b960-04a10a5a8a0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1024//16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc56213-323f-4622-a698-31f236e8f504",
   "metadata": {},
   "source": [
    "* hidden_states here is our input to n-grammer\n",
    "* for each token, its embedding has shape (1024,), and they are from an embedding size (50300,1024)\n",
    "* learn a cookbook (k, h, 1024//h), where h is number of head, e.g h=16, and the codekbook size (k, 16, 64), each head has its own codebook (k, 64)\n",
    "* we can device each token embedding (1024) into 16 heads also, and we will have has 16 sequences of 64 dimensions, and map each to a code-word (64) in the codebook of its corresponding head\n",
    "* we can then represent it with the codeboo kid {0,1,2,...,k}\n",
    "\n",
    "the experiments use k = 4096, 8192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "5f954bd4-efe4-40ae-ac0f-3fce4ec9a3b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34, 64, 1024)"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "e4cf485d-3713-4ec2-8fdc-d3ffc32ab574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(75, dtype=int32)"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "68b62d91-7669-4aee-8f69-dd20b85999b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([0.05645201, 0.00823602, 0.00430387, ..., 0.00144471,\n",
       "             0.03303868, 0.03409737], dtype=float32)"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_states[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3f53ee-a943-44e4-845e-8d964af10244",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "ce1feb70-9074-4556-bbdd-1d218906d5c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.scale_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05cc3e5d-aa72-4bf5-9b92-02bf9fe9f682",
   "metadata": {},
   "source": [
    "apply a scaler to embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "062422bd-ca8e-4914-808a-312d15275fee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we do not scale the embedding\n",
    "config.scale_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d86a662-23fd-4ea4-8293-3c8a05dab2bd",
   "metadata": {},
   "source": [
    "add position embedding (64,1024)\n",
    "* we have 64 positions in input_ids \n",
    "* same dimension as encoding embedding, 1024\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "5ee4cc15-c3f4-4897-8b4b-9ee002739232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.use_absolute_position_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "b7537bb0-2744-4d50-87e4-174c6abcc301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.max_text_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "177317ac-9c71-4ba6-84b7-c350e2bbb875",
   "metadata": {},
   "outputs": [],
   "source": [
    "offset =0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "64590455-346a-4e80-b939-cb8ce4bc9dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_embed_positions = nn.Embed(\n",
    "                config.max_text_length + offset,  # image length for BOS\n",
    "                config.d_model,\n",
    "                embedding_init=jax.nn.initializers.normal(config.init_std),\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "bd2f9dc9-60cc-4f25-aa23-f88a05d3174d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embed(\n",
       "    # attributes\n",
       "    num_embeddings = 64\n",
       "    features = 1024\n",
       "    dtype = None\n",
       "    param_dtype = float32\n",
       "    embedding_init = init\n",
       "    embedding = None\n",
       ")"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_embed_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "4ecfbfd1-0a20-4c80-87fe-050dcc2aa89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_encoder_embed_positions = model_params['model']['encoder']['embed_positions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "e51bf727-db72-47d3-bee7-22ce5cf1c6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_pos = encoder_embed_positions.apply(\n",
    "    {'params': params_encoder_embed_positions},\n",
    "    position_ids + offset,\n",
    "    rngs=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "02939c12-57df-45c3-bf92-ea8b7ce63363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34, 64, 1024)"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_pos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "eb858195-e1ea-471c-babf-1bcd8240b7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_states = hidden_states + embed_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "6169979e-1a2b-405e-9712-d0cac28ab5cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34, 64, 1024)"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1172d4-f60f-4d6b-bfef-6399e0b59e23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc96d1a9-3266-455b-b0bb-0b5e49565f4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cf8c7f-5942-4d39-8880-a4f5e3bf2d25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "58f3d57d-b57f-4c1e-99ef-924292e6ec43",
   "metadata": {},
   "source": [
    "# pjit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "id": "080d816b-c9da-4bf4-ade4-0f1f53bf62bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pjit_fn_without = pjit(\n",
    "  lambda batch: batch,\n",
    "  in_axis_resources=batch_spec,\n",
    "  out_axis_resources=batch_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "id": "ae61a5ed-39d6-43b5-a01e-33cf3c59096f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mesh:\n",
    "    minibatch_without = pjit_fn_without(minibatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "id": "7a629160-367c-4095-83c8-17cc6941a812",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DeviceArray([[[ 1139,  8447,  1989, ...,  1268,  9035,  7771],\n",
       "               [ 1270,  9889,  7580, ...,  1400,  5848,  2922],\n",
       "               [12167,  6598,   217, ...,  2881,  4644, 15282],\n",
       "               ...,\n",
       "               [ 9035,  7266, 13586, ...,  2524,  5053, 11993],\n",
       "               [ 3272,  7106, 11228, ..., 11012,   882,  9479],\n",
       "               [ 5171,  5171,  5171, ..., 11096,  1400,  7738]]],            dtype=int32),\n",
       " DeviceArray([[[10042, 10042,  5171, ...,  5171, 10042,  9834],\n",
       "               [14283,  8867,  5171, ..., 12566, 10042, 10042],\n",
       "               [10042, 10042,  5171, ...,  9000,  2334,  1571],\n",
       "               ...,\n",
       "               [ 2987, 14420,  1183, ...,  1597, 11348, 12823],\n",
       "               [ 9570, 10042, 14420, ...,  5416,  2601,  2813],\n",
       "               [ 4950,  1847, 15565, ..., 15947,  4648,  7806]]],            dtype=int32),\n",
       " DeviceArray([[[ 5171,  5171,  1270, ...,  1941,  8283,  8283],\n",
       "               [ 6060, 16279,  8283, ...,  9837, 11456, 11591],\n",
       "               [10042, 10042,  5171, ...,  5171, 10042,  9834],\n",
       "               ...,\n",
       "               [15076, 12145,  4075, ...,  9479,  6790, 12159],\n",
       "               [ 1627, 16279,  4652, ..., 10278, 10710,  9345],\n",
       "               [10274,  2701,  1948, ...,    23, 10909,  8867]]],            dtype=int32),\n",
       " DeviceArray([[[11492,   271,  9889, ...,  6113, 12143,  5839],\n",
       "               [ 2683,  6808, 11718, ...,  9630,  5113, 11587],\n",
       "               [ 4238,  5984,  1941, ..., 11718,  9756,  8222],\n",
       "               ...,\n",
       "               [ 4635,  1567,  8412, ...,  4816,  9150,  9837],\n",
       "               [13670, 11327,  5984, ...,  7491,  6808,  8413],\n",
       "               [15525, 14240,  9206, ...,  1972, 14494, 10627]]],            dtype=int32),\n",
       " DeviceArray([[[ 1024, 10629, 15387, ...,  1872,  8269, 14494],\n",
       "               [16017, 15575,  9206, ...,  8207,  1400,  6523],\n",
       "               [ 8888, 13010, 11674, ..., 10627, 11492,  1702],\n",
       "               ...,\n",
       "               [10042,  5171,   910, ...,  9570,  5171, 10042],\n",
       "               [ 5213,  8737, 12618, ..., 11427,   129,  7467],\n",
       "               [10042,  5171,  5171, ...,  5171,  5171,  9834]]],            dtype=int32),\n",
       " DeviceArray([[[ 1811,  7467,  4945, ...,   633,  7749,  4869],\n",
       "               [12143,  6123, 12951, ...,  6930, 14129, 10845],\n",
       "               [  167,  4238, 12566, ...,  6690,  6123,   601],\n",
       "               ...,\n",
       "               [10227,  8493,   134, ...,  2029, 11334, 13670],\n",
       "               [11235,  5908, 15276, ..., 15917,  7576, 14283],\n",
       "               [ 8867,  5314, 13427, ..., 11427, 11605, 14793]]],            dtype=int32),\n",
       " DeviceArray([[[ 4635, 11941,  2987, ...,   194, 12025, 10845],\n",
       "               [10042, 10042,  5171, ..., 13769, 14283,  9834],\n",
       "               [ 8493,  5693, 11708, ...,  2469,  4817, 10529],\n",
       "               ...,\n",
       "               [ 9206,  4301,  1024, ...,  8583, 11147,  3135],\n",
       "               [ 9753,  9598, 13512, ..., 10042,  6965, 12566],\n",
       "               [ 6965,  6172,  1052, ..., 14164, 14447,  5772]]],            dtype=int32),\n",
       " DeviceArray([[[10042,  5171,  4238, ...,  9570, 10042,  9834],\n",
       "               [ 2474,   432,  4075, ...,  2987,  5625,  2778],\n",
       "               [10042,  5171, 11334, ...,  9570, 10042,  9834],\n",
       "               ...,\n",
       "               [ 9834,  4238, 14473, ...,  5113,    81,  7106],\n",
       "               [10278,  9470,  1270, ..., 12823,  6933,  1872],\n",
       "               [10042,  5171,  5171, ...,  9834,  5171,  9834]]],            dtype=int32)]"
      ]
     },
     "execution_count": 580,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is the pjit without the with_sharding_constraint - looks identical \n",
    "minibatch_without['labels'].device_buffers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "4df6b1ea-52d0-40c9-9850-1bb7770b6e25",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DeviceArray([[[ 1139,  8447,  1989, ...,  1268,  9035,  7771],\n",
       "               [ 1270,  9889,  7580, ...,  1400,  5848,  2922],\n",
       "               [12167,  6598,   217, ...,  2881,  4644, 15282],\n",
       "               ...,\n",
       "               [ 9035,  7266, 13586, ...,  2524,  5053, 11993],\n",
       "               [ 3272,  7106, 11228, ..., 11012,   882,  9479],\n",
       "               [ 5171,  5171,  5171, ..., 11096,  1400,  7738]]],            dtype=int32),\n",
       " DeviceArray([[[10042, 10042,  5171, ...,  5171, 10042,  9834],\n",
       "               [14283,  8867,  5171, ..., 12566, 10042, 10042],\n",
       "               [10042, 10042,  5171, ...,  9000,  2334,  1571],\n",
       "               ...,\n",
       "               [ 2987, 14420,  1183, ...,  1597, 11348, 12823],\n",
       "               [ 9570, 10042, 14420, ...,  5416,  2601,  2813],\n",
       "               [ 4950,  1847, 15565, ..., 15947,  4648,  7806]]],            dtype=int32),\n",
       " DeviceArray([[[ 5171,  5171,  1270, ...,  1941,  8283,  8283],\n",
       "               [ 6060, 16279,  8283, ...,  9837, 11456, 11591],\n",
       "               [10042, 10042,  5171, ...,  5171, 10042,  9834],\n",
       "               ...,\n",
       "               [15076, 12145,  4075, ...,  9479,  6790, 12159],\n",
       "               [ 1627, 16279,  4652, ..., 10278, 10710,  9345],\n",
       "               [10274,  2701,  1948, ...,    23, 10909,  8867]]],            dtype=int32),\n",
       " DeviceArray([[[11492,   271,  9889, ...,  6113, 12143,  5839],\n",
       "               [ 2683,  6808, 11718, ...,  9630,  5113, 11587],\n",
       "               [ 4238,  5984,  1941, ..., 11718,  9756,  8222],\n",
       "               ...,\n",
       "               [ 4635,  1567,  8412, ...,  4816,  9150,  9837],\n",
       "               [13670, 11327,  5984, ...,  7491,  6808,  8413],\n",
       "               [15525, 14240,  9206, ...,  1972, 14494, 10627]]],            dtype=int32),\n",
       " DeviceArray([[[ 1024, 10629, 15387, ...,  1872,  8269, 14494],\n",
       "               [16017, 15575,  9206, ...,  8207,  1400,  6523],\n",
       "               [ 8888, 13010, 11674, ..., 10627, 11492,  1702],\n",
       "               ...,\n",
       "               [10042,  5171,   910, ...,  9570,  5171, 10042],\n",
       "               [ 5213,  8737, 12618, ..., 11427,   129,  7467],\n",
       "               [10042,  5171,  5171, ...,  5171,  5171,  9834]]],            dtype=int32),\n",
       " DeviceArray([[[ 1811,  7467,  4945, ...,   633,  7749,  4869],\n",
       "               [12143,  6123, 12951, ...,  6930, 14129, 10845],\n",
       "               [  167,  4238, 12566, ...,  6690,  6123,   601],\n",
       "               ...,\n",
       "               [10227,  8493,   134, ...,  2029, 11334, 13670],\n",
       "               [11235,  5908, 15276, ..., 15917,  7576, 14283],\n",
       "               [ 8867,  5314, 13427, ..., 11427, 11605, 14793]]],            dtype=int32),\n",
       " DeviceArray([[[ 4635, 11941,  2987, ...,   194, 12025, 10845],\n",
       "               [10042, 10042,  5171, ..., 13769, 14283,  9834],\n",
       "               [ 8493,  5693, 11708, ...,  2469,  4817, 10529],\n",
       "               ...,\n",
       "               [ 9206,  4301,  1024, ...,  8583, 11147,  3135],\n",
       "               [ 9753,  9598, 13512, ..., 10042,  6965, 12566],\n",
       "               [ 6965,  6172,  1052, ..., 14164, 14447,  5772]]],            dtype=int32),\n",
       " DeviceArray([[[10042,  5171,  4238, ...,  9570, 10042,  9834],\n",
       "               [ 2474,   432,  4075, ...,  2987,  5625,  2778],\n",
       "               [10042,  5171, 11334, ...,  9570, 10042,  9834],\n",
       "               ...,\n",
       "               [ 9834,  4238, 14473, ...,  5113,    81,  7106],\n",
       "               [10278,  9470,  1270, ..., 12823,  6933,  1872],\n",
       "               [10042,  5171,  5171, ...,  9834,  5171,  9834]]],            dtype=int32)]"
      ]
     },
     "execution_count": 579,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minibatch['labels'].device_buffers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d77e8b-1fe3-40ce-b995-7d64ba901059",
   "metadata": {},
   "source": [
    "### compute_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "id": "7e3e697d-ad4f-4a9b-a230-f6ca1babdecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss\n",
    "def loss_fn(logits, labels):\n",
    "    loss = optax.softmax_cross_entropy(logits, onehot(labels, logits.shape[-1]))\n",
    "    loss = loss.mean()\n",
    "    return loss\n",
    "\n",
    "def compute_loss(params, minibatch, dropout_rng):\n",
    "    # minibatch has dim (batch_size, ...)\n",
    "    minibatch, labels = minibatch.pop(\"labels\")\n",
    "    logits = state.apply_fn(\n",
    "        **minibatch, params=params, dropout_rng=dropout_rng, train=True)[0]\n",
    "    return loss_fn(logits, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b518167-7fd1-477b-9dd4-196a53e91cb8",
   "metadata": {},
   "source": [
    "note that __state.apply_fn__ is defined as \n",
    "```python\n",
    "TrainState.create( apply_fn=model.__call__, ...)\n",
    "```\n",
    "\n",
    "the `__call__` method is defined in __FlaxBartPreTrainedModel__, which we will look into later; \n",
    "it returns an __FlaxSeq2SeqLMOutput__ object, where its first item is __logits__, we used it to compare against __labels__ and calculate the __loss__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591b7ccb-fcd0-436b-a14d-0f780cde8628",
   "metadata": {},
   "source": [
    "#### p_compute_loss\n",
    "\n",
    "Let's pjit the compute_loss to see how it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d3cc35-b434-40e5-8a7f-bbe792e0828b",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_compute_loss = pjit(\n",
    "    compute_loss,\n",
    "    in_axis_resources = (state_spec.params, batch_spec, None,),\n",
    "    out_axis_resources = None)\n",
    "\n",
    "with mesh:\n",
    "    loss = p_compute_loss(state.params, minibatch, dropout_rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d8a74c5-b490-409b-be7e-0f476e6fcbb7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'minibatch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mminibatch\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'minibatch' is not defined"
     ]
    }
   ],
   "source": [
    "minibatch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef10993-dd05-4716-ab9e-51993b17071e",
   "metadata": {},
   "source": [
    "here we go over __each of the input__ to compute_loss and its __PartitionSpec__\n",
    "\n",
    "__input(1): state.params__\n",
    "* a tree of __ShardedDeviceArray__ \n",
    "* already sharded according to __state_spec.params__\n",
    "* since we set mp_device = 1, we are not sharding model parameters, all the parameters are duplicated across all devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "id": "0bccd93b-fefd-4d50-b0b9-4a3c41dc4003",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenDict({\n",
       "    lm_head: {\n",
       "        kernel: (1024, 16401),\n",
       "    },\n",
       "    model: {\n",
       "        decoder: {\n",
       "            embed_positions: {\n",
       "                embedding: (256, 1024),\n",
       "            },\n",
       "            embed_tokens: {\n",
       "                embedding: (16401, 1024),\n",
       "            },\n",
       "            final_ln: {\n",
       "                bias: (1024,),\n",
       "            },\n",
       "            layernorm_embedding: {\n",
       "                bias: (1024,),\n",
       "                scale: (1024,),\n",
       "            },\n",
       "            layers: {\n",
       "                FlaxBartDecoderLayer_0: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: (2730, 1024),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: (1024,),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: (2730,),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: (1024,),\n",
       "                        scale: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: (1024,),\n",
       "                        scale: (1024,),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_1: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: (2730, 1024),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: (1024,),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: (2730,),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: (1024,),\n",
       "                        scale: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: (1024,),\n",
       "                        scale: (1024,),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_10: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: (2730, 1024),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: (1024,),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: (2730,),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: (1024,),\n",
       "                        scale: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: (1024,),\n",
       "                        scale: (1024,),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_11: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: (2730, 1024),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: (1024,),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: (2730,),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: (1024,),\n",
       "                        scale: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: (1024,),\n",
       "                        scale: (1024,),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_2: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: (2730, 1024),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: (1024,),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: (2730,),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: (1024,),\n",
       "                        scale: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: (1024,),\n",
       "                        scale: (1024,),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_3: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: (2730, 1024),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: (1024,),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: (2730,),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: (1024,),\n",
       "                        scale: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: (1024,),\n",
       "                        scale: (1024,),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_4: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: (2730, 1024),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: (1024,),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: (2730,),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: (1024,),\n",
       "                        scale: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: (1024,),\n",
       "                        scale: (1024,),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_5: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: (2730, 1024),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: (1024,),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: (2730,),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: (1024,),\n",
       "                        scale: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: (1024,),\n",
       "                        scale: (1024,),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_6: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: (2730, 1024),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: (1024,),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: (2730,),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: (1024,),\n",
       "                        scale: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: (1024,),\n",
       "                        scale: (1024,),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_7: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: (2730, 1024),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: (1024,),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: (2730,),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: (1024,),\n",
       "                        scale: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: (1024,),\n",
       "                        scale: (1024,),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_8: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: (2730, 1024),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: (1024,),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: (2730,),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: (1024,),\n",
       "                        scale: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: (1024,),\n",
       "                        scale: (1024,),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_9: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: (2730, 1024),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: (1024,),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: (2730,),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: (1024,),\n",
       "                        scale: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: (1024,),\n",
       "                        scale: (1024,),\n",
       "                    },\n",
       "                },\n",
       "            },\n",
       "        },\n",
       "        encoder: {\n",
       "            embed_positions: {\n",
       "                embedding: (64, 1024),\n",
       "            },\n",
       "            embed_tokens: {\n",
       "                embedding: (50300, 1024),\n",
       "            },\n",
       "            final_ln: {\n",
       "                bias: (1024,),\n",
       "            },\n",
       "            layernorm_embedding: {\n",
       "                bias: (1024,),\n",
       "                scale: (1024,),\n",
       "            },\n",
       "            layers: {\n",
       "                FlaxBartEncoderLayer_0: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: (2730, 1024),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: (1024,),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: (2730,),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: (1024,),\n",
       "                        scale: (1024,),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_1: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: (2730, 1024),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: (1024,),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: (2730,),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: (1024,),\n",
       "                        scale: (1024,),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_10: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: (2730, 1024),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: (1024,),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: (2730,),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: (1024,),\n",
       "                        scale: (1024,),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_11: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: (2730, 1024),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: (1024,),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: (2730,),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: (1024,),\n",
       "                        scale: (1024,),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_2: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: (2730, 1024),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: (1024,),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: (2730,),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: (1024,),\n",
       "                        scale: (1024,),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_3: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: (2730, 1024),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: (1024,),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: (2730,),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: (1024,),\n",
       "                        scale: (1024,),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_4: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: (2730, 1024),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: (1024,),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: (2730,),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: (1024,),\n",
       "                        scale: (1024,),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_5: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: (2730, 1024),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: (1024,),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: (2730,),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: (1024,),\n",
       "                        scale: (1024,),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_6: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: (2730, 1024),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: (1024,),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: (2730,),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: (1024,),\n",
       "                        scale: (1024,),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_7: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: (2730, 1024),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: (1024,),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: (2730,),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: (1024,),\n",
       "                        scale: (1024,),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_8: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: (2730, 1024),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: (1024,),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: (2730,),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: (1024,),\n",
       "                        scale: (1024,),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_9: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: (2730, 1024),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: (1024,),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: (2730,),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: (1024,),\n",
       "                        scale: (1024,),\n",
       "                    },\n",
       "                },\n",
       "            },\n",
       "        },\n",
       "    },\n",
       "})"
      ]
     },
     "execution_count": 639,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shapes of input: state.params\n",
    "jax.tree_map(lambda x:x.shape, state.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "id": "d739e87f-fc4f-4a0f-80a2-6ad9b5bdbab8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenDict({\n",
       "    lm_head: {\n",
       "        kernel: (1024, 16401),\n",
       "    },\n",
       "    model: {\n",
       "        decoder: {\n",
       "            embed_positions: {\n",
       "                embedding: (256, 1024),\n",
       "            },\n",
       "            embed_tokens: {\n",
       "                embedding: (16401, 1024),\n",
       "            },\n",
       "            final_ln: {\n",
       "                bias: (1024,),\n",
       "            },\n",
       "            layernorm_embedding: {\n",
       "                bias: (1024,),\n",
       "                scale: (1024,),\n",
       "            },\n",
       "            layers: {\n",
       "                FlaxBartDecoderLayer_0: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: (2730, 1024),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: (1024,),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: (2730,),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: (1024,),\n",
       "                        scale: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: (1024,),\n",
       "                        scale: (1024,),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_1: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: (2730, 1024),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: (1024,),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: (2730,),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: (1024,),\n",
       "                        scale: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: (1024,),\n",
       "                        scale: (1024,),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_10: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: (2730, 1024),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: (1024,),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: (2730,),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: (1024,),\n",
       "                        scale: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: (1024,),\n",
       "                        scale: (1024,),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_11: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: (2730, 1024),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: (1024,),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: (2730,),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: (1024,),\n",
       "                        scale: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: (1024,),\n",
       "                        scale: (1024,),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_2: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: (2730, 1024),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: (1024,),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: (2730,),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: (1024,),\n",
       "                        scale: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: (1024,),\n",
       "                        scale: (1024,),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_3: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: (2730, 1024),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: (1024,),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: (2730,),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: (1024,),\n",
       "                        scale: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: (1024,),\n",
       "                        scale: (1024,),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_4: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: (2730, 1024),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: (1024,),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: (2730,),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: (1024,),\n",
       "                        scale: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: (1024,),\n",
       "                        scale: (1024,),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_5: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: (2730, 1024),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: (1024,),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: (2730,),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: (1024,),\n",
       "                        scale: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: (1024,),\n",
       "                        scale: (1024,),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_6: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: (2730, 1024),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: (1024,),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: (2730,),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: (1024,),\n",
       "                        scale: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: (1024,),\n",
       "                        scale: (1024,),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_7: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: (2730, 1024),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: (1024,),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: (2730,),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: (1024,),\n",
       "                        scale: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: (1024,),\n",
       "                        scale: (1024,),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_8: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: (2730, 1024),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: (1024,),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: (2730,),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: (1024,),\n",
       "                        scale: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: (1024,),\n",
       "                        scale: (1024,),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_9: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: (2730, 1024),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: (1024,),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: (2730,),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: (1024,),\n",
       "                        scale: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: (1024,),\n",
       "                        scale: (1024,),\n",
       "                    },\n",
       "                },\n",
       "            },\n",
       "        },\n",
       "        encoder: {\n",
       "            embed_positions: {\n",
       "                embedding: (64, 1024),\n",
       "            },\n",
       "            embed_tokens: {\n",
       "                embedding: (50300, 1024),\n",
       "            },\n",
       "            final_ln: {\n",
       "                bias: (1024,),\n",
       "            },\n",
       "            layernorm_embedding: {\n",
       "                bias: (1024,),\n",
       "                scale: (1024,),\n",
       "            },\n",
       "            layers: {\n",
       "                FlaxBartEncoderLayer_0: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: (2730, 1024),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: (1024,),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: (2730,),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: (1024,),\n",
       "                        scale: (1024,),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_1: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: (2730, 1024),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: (1024,),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: (2730,),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: (1024,),\n",
       "                        scale: (1024,),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_10: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: (2730, 1024),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: (1024,),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: (2730,),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: (1024,),\n",
       "                        scale: (1024,),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_11: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: (2730, 1024),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: (1024,),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: (2730,),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: (1024,),\n",
       "                        scale: (1024,),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_2: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: (2730, 1024),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: (1024,),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: (2730,),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: (1024,),\n",
       "                        scale: (1024,),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_3: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: (2730, 1024),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: (1024,),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: (2730,),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: (1024,),\n",
       "                        scale: (1024,),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_4: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: (2730, 1024),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: (1024,),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: (2730,),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: (1024,),\n",
       "                        scale: (1024,),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_5: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: (2730, 1024),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: (1024,),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: (2730,),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: (1024,),\n",
       "                        scale: (1024,),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_6: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: (2730, 1024),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: (1024,),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: (2730,),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: (1024,),\n",
       "                        scale: (1024,),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_7: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: (2730, 1024),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: (1024,),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: (2730,),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: (1024,),\n",
       "                        scale: (1024,),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_8: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: (2730, 1024),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: (1024,),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: (2730,),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: (1024,),\n",
       "                        scale: (1024,),\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_9: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: (1024, 1024),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: (1024, 2730),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: (2730, 1024),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: (1024,),\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: (2730,),\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: (1024,),\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: (1024,),\n",
       "                        scale: (1024,),\n",
       "                    },\n",
       "                },\n",
       "            },\n",
       "        },\n",
       "    },\n",
       "})"
      ]
     },
     "execution_count": 638,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in our case, our parameters are replicated in each device\n",
    "# here take a look of the data in the first device - it's the entire parameter tree\n",
    "jax.tree_map(lambda x: x.device_buffers[0].shape, state.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "id": "e8a49768-7d2d-4920-962c-bfe8d0789ab9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenDict({\n",
       "    lm_head: {\n",
       "        kernel: PartitionSpec(None, 'mp'),\n",
       "    },\n",
       "    model: {\n",
       "        decoder: {\n",
       "            embed_positions: {\n",
       "                embedding: PartitionSpec('mp', None),\n",
       "            },\n",
       "            embed_tokens: {\n",
       "                embedding: PartitionSpec('mp', None),\n",
       "            },\n",
       "            final_ln: {\n",
       "                bias: None,\n",
       "            },\n",
       "            layernorm_embedding: {\n",
       "                bias: None,\n",
       "                scale: None,\n",
       "            },\n",
       "            layers: {\n",
       "                FlaxBartDecoderLayer_0: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_1: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_10: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_11: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_2: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_3: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_4: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_5: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_6: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_7: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_8: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartDecoderLayer_9: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    FlaxBartAttention_1: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                    LayerNorm_2: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_3: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "            },\n",
       "        },\n",
       "        encoder: {\n",
       "            embed_positions: {\n",
       "                embedding: PartitionSpec('mp', None),\n",
       "            },\n",
       "            embed_tokens: {\n",
       "                embedding: PartitionSpec('mp', None),\n",
       "            },\n",
       "            final_ln: {\n",
       "                bias: None,\n",
       "            },\n",
       "            layernorm_embedding: {\n",
       "                bias: None,\n",
       "                scale: None,\n",
       "            },\n",
       "            layers: {\n",
       "                FlaxBartEncoderLayer_0: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_1: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_10: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_11: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_2: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_3: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_4: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_5: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_6: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_7: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_8: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "                FlaxBartEncoderLayer_9: {\n",
       "                    FlaxBartAttention_0: {\n",
       "                        k_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        out_proj: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        q_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        v_proj: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                    },\n",
       "                    GLU_0: {\n",
       "                        Dense_0: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_1: {\n",
       "                            kernel: PartitionSpec(None, 'mp'),\n",
       "                        },\n",
       "                        Dense_2: {\n",
       "                            kernel: PartitionSpec('mp', None),\n",
       "                        },\n",
       "                        LayerNorm_0: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                        LayerNorm_1: {\n",
       "                            bias: None,\n",
       "                        },\n",
       "                    },\n",
       "                    LayerNorm_0: {\n",
       "                        bias: None,\n",
       "                    },\n",
       "                    LayerNorm_1: {\n",
       "                        bias: None,\n",
       "                        scale: None,\n",
       "                    },\n",
       "                },\n",
       "            },\n",
       "        },\n",
       "    },\n",
       "})"
      ]
     },
     "execution_count": 646,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the PartitionSpec for parameters - only shard over mp, which is 1, so no sharding at all\n",
    "state_spec.params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236a161e-0d94-41ce-bc9f-a0d6a5578805",
   "metadata": {},
   "source": [
    "__input(2): minibatch__\n",
    "* a tree of ShardedDeviceArray\n",
    "* PartitionSpec is (dp,)\n",
    "* so for each of its SharedDeviceArray, its __first dimension__ of its arrays is size __272__, it needs to be __sharded__ over the __8 devices__ in __dp__, so each will have __34__\n",
    "* already sharded correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "id": "5ac6cc94-be7e-478c-873d-f0ad4e88d7fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenDict({\n",
       "    attention_mask: (272, 64),\n",
       "    decoder_input_ids: (272, 256),\n",
       "    input_ids: (272, 64),\n",
       "    labels: (272, 256),\n",
       "})"
      ]
     },
     "execution_count": 648,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.tree_map(lambda x:x.shape, minibatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "id": "81056d0c-a5af-4ba9-873b-68a50af2c3e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PartitionSpec('dp',)"
      ]
     },
     "execution_count": 649,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shard the first dimension (272) over dp (8 devices)\n",
    "batch_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "id": "32864e2a-f48e-41d0-9526-6f8074150e86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenDict({\n",
       "    attention_mask: (34, 64),\n",
       "    decoder_input_ids: (34, 256),\n",
       "    input_ids: (34, 64),\n",
       "    labels: (34, 256),\n",
       "})"
      ]
     },
     "execution_count": 650,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the slice of minibatch in first device\n",
    "jax.tree_map(lambda x: x.device_buffers[0].shape, minibatch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40d6ac2-3cfb-4025-9b7c-95995a41e9f6",
   "metadata": {},
   "source": [
    "__input(3)__: __dropout_rng__ is replicated across all devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "id": "537297b9-a769-4a23-bb2b-90cbae6bdc54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([2465931498, 3679230171], dtype=uint32)"
      ]
     },
     "execution_count": 651,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropout_rng"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f35c51-b839-4cca-a66f-f2d5987946f8",
   "metadata": {},
   "source": [
    "__output__: __loss__, replicated across all devices because out_axis_resources = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "id": "6b5b6189-6c45-4c77-8e5f-994fc8a0146e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ShardedDeviceArray(9.912242, dtype=float32)"
      ]
     },
     "execution_count": 661,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "id": "4fa3ca74-5b08-42ac-a842-5f0e2f199f32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(9.912242, dtype=float32)"
      ]
     },
     "execution_count": 662,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.device_get(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "id": "da980264-e1c3-48e9-b044-8ce5ebea7be5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DeviceArray(9.912242, dtype=float32),\n",
       " DeviceArray(9.912242, dtype=float32),\n",
       " DeviceArray(9.912242, dtype=float32),\n",
       " DeviceArray(9.912242, dtype=float32),\n",
       " DeviceArray(9.912242, dtype=float32),\n",
       " DeviceArray(9.912242, dtype=float32),\n",
       " DeviceArray(9.912242, dtype=float32),\n",
       " DeviceArray(9.912242, dtype=float32)]"
      ]
     },
     "execution_count": 663,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.device_buffers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b5d697-4613-4325-b1a2-6162d34d98c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c968f415-1639-4297-b12a-7afb9761ad0d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### grad_fn() -> loss, grad \n",
    "\n",
    "if we don't apply vmap_trick, our __loss__ and __gradient__ can be calculated directly with __grad_fn__\n",
    "\n",
    "__grad_fn__ are defined below, it is pretty standard:\n",
    "* define a __compute_loss__ function that takes all the __inputs__(e.g. variables, batch, rng)  and returns a __loss__ \n",
    "```python\n",
    "compute_loss(params, minibatch, dropout_rng) -> loss\n",
    "``` \n",
    "* apply __jax.value_and_grad__ on it to get the __grad_fn__, which takes the same inputs but returns __loss and gradients__\n",
    "```python\n",
    "grad_fn(state.params, minibatch, dropout_rng) -> loss, grads\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "id": "2c87a126-69ef-4c87-a050-5cd6e15881f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PartitionSpec('dp',)"
      ]
     },
     "execution_count": 690,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "id": "6c7bdc85-3e8c-4ddc-abd1-0787a0574be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_fn = jax.value_and_grad(compute_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "id": "2c5440fd-1b8a-4402-91f9-765da457a7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    " def loss_and_grad(dropout_rng):\n",
    "        # only 1 single rng per grad step, let us handle larger batch size (not sure why)\n",
    "        dropout_rng, _ = jax.random.split(dropout_rng)\n",
    "                # \"vmap trick\" does not work in multi-hosts and requires too much hbm\n",
    "        loss, grads = grad_fn(state.params, minibatch, dropout_rng)\n",
    "        # ensure grads are sharded\n",
    "        grads = with_sharding_constraint(grads, param_spec)\n",
    "            # return loss and grads\n",
    "        return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5017bfa2-6eff-4b75-add3-256eabcd550a",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_loss_and_grad = pjit(\n",
    "    loss_and_grad,\n",
    "    in_axis_resources = None,\n",
    "    out_axis_resources = param_spec)\n",
    "\n",
    "with mesh:\n",
    "    grads = p_loss_and_grad(dropout_rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ceacd9-4918-482f-909f-c61748c9c2d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0d1a12-ae52-4a67-8ca5-fbe85f4e6288",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952d68bd-70e8-4172-9e47-b95fb8bb9fee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86739bba-c6fa-4ee9-a1c7-f8399cac3509",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3520c2c7-b71d-436b-bec2-c884d9ffc707",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0904e5d4-9b96-492b-9ca1-ac47e2270245",
   "metadata": {},
   "source": [
    "#### grad_fn (use_vmap_trick)\n",
    "\n",
    "when use vmap trick, we vamp <u>same __grad_fn__ function</u> over same __minibatch__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4462c2-f262-47d4-9756-88445677a820",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, grads = jax.vmap(\n",
    "                    grad_fn, in_axes=(None, 0, None), out_axes=(0, 0)\n",
    "                )(state.params, minibatch, dropout_rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "id": "29378e41-079d-4093-b072-165dd5bf331c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenDict({\n",
       "    attention_mask: ShardedDeviceArray([[[1, 1, 1, ..., 0, 0, 0],\n",
       "                         [1, 1, 1, ..., 0, 0, 0],\n",
       "                         [1, 1, 1, ..., 0, 0, 0],\n",
       "                         ...,\n",
       "                         [1, 1, 1, ..., 0, 0, 0],\n",
       "                         [1, 1, 1, ..., 0, 0, 0],\n",
       "                         [1, 1, 0, ..., 0, 0, 0]],\n",
       "    \n",
       "                        [[1, 1, 1, ..., 0, 0, 0],\n",
       "                         [1, 1, 1, ..., 0, 0, 0],\n",
       "                         [1, 1, 1, ..., 0, 0, 0],\n",
       "                         ...,\n",
       "                         [1, 1, 1, ..., 0, 0, 0],\n",
       "                         [1, 1, 1, ..., 0, 0, 0],\n",
       "                         [1, 1, 0, ..., 0, 0, 0]],\n",
       "    \n",
       "                        [[1, 1, 1, ..., 0, 0, 0],\n",
       "                         [1, 1, 0, ..., 0, 0, 0],\n",
       "                         [1, 1, 0, ..., 0, 0, 0],\n",
       "                         ...,\n",
       "                         [1, 1, 0, ..., 0, 0, 0],\n",
       "                         [1, 1, 1, ..., 0, 0, 0],\n",
       "                         [1, 1, 1, ..., 0, 0, 0]],\n",
       "    \n",
       "                        ...,\n",
       "    \n",
       "                        [[1, 1, 0, ..., 0, 0, 0],\n",
       "                         [1, 1, 1, ..., 0, 0, 0],\n",
       "                         [1, 1, 1, ..., 0, 0, 0],\n",
       "                         ...,\n",
       "                         [1, 1, 1, ..., 0, 0, 0],\n",
       "                         [1, 1, 0, ..., 0, 0, 0],\n",
       "                         [1, 1, 1, ..., 0, 0, 0]],\n",
       "    \n",
       "                        [[1, 1, 1, ..., 0, 0, 0],\n",
       "                         [1, 1, 1, ..., 0, 0, 0],\n",
       "                         [1, 1, 1, ..., 0, 0, 0],\n",
       "                         ...,\n",
       "                         [1, 1, 1, ..., 0, 0, 0],\n",
       "                         [1, 1, 1, ..., 0, 0, 0],\n",
       "                         [1, 1, 0, ..., 0, 0, 0]],\n",
       "    \n",
       "                        [[1, 1, 1, ..., 0, 0, 0],\n",
       "                         [1, 1, 1, ..., 0, 0, 0],\n",
       "                         [1, 1, 1, ..., 0, 0, 0],\n",
       "                         ...,\n",
       "                         [1, 1, 1, ..., 0, 0, 0],\n",
       "                         [1, 1, 1, ..., 0, 0, 0],\n",
       "                         [1, 1, 1, ..., 0, 0, 0]]], dtype=int32),\n",
       "    decoder_input_ids: ShardedDeviceArray([[[16384.,  1139.,  8447., ..., 13440.,  1268.,\n",
       "                           9035.],\n",
       "                         [16384.,  1270.,  9889., ...,  4817.,  1400.,\n",
       "                           5848.],\n",
       "                         [16384., 12167.,  6598., ...,  6882.,  2881.,\n",
       "                           4644.],\n",
       "                         ...,\n",
       "                         [16384.,  9035.,  7266., ..., 11993.,  2524.,\n",
       "                           5053.],\n",
       "                         [16384.,  3272.,  7106., ...,  6948., 11012.,\n",
       "                            882.],\n",
       "                         [16384.,  5171.,  5171., ...,  7896., 11096.,\n",
       "                           1400.]],\n",
       "    \n",
       "                        [[16384., 10042., 10042., ...,  5171.,  5171.,\n",
       "                          10042.],\n",
       "                         [16384., 14283.,  8867., ..., 10042., 12566.,\n",
       "                          10042.],\n",
       "                         [16384., 10042., 10042., ..., 11342.,  9000.,\n",
       "                           2334.],\n",
       "                         ...,\n",
       "                         [16384.,  2987., 14420., ...,  1495.,  1597.,\n",
       "                          11348.],\n",
       "                         [16384.,  9570., 10042., ...,  7896.,  5416.,\n",
       "                           2601.],\n",
       "                         [16384.,  4950.,  1847., ...,  9957., 15947.,\n",
       "                           4648.]],\n",
       "    \n",
       "                        [[16384.,  5171.,  5171., ..., 10769.,  1941.,\n",
       "                           8283.],\n",
       "                         [16384.,  6060., 16279., ...,  2029.,  9837.,\n",
       "                          11456.],\n",
       "                         [16384., 10042., 10042., ...,  5171.,  5171.,\n",
       "                          10042.],\n",
       "                         ...,\n",
       "                         [16384., 15076., 12145., ...,  8946.,  9479.,\n",
       "                           6790.],\n",
       "                         [16384.,  1627., 16279., ...,  8566., 10278.,\n",
       "                          10710.],\n",
       "                         [16384., 10274.,  2701., ..., 11196.,    23.,\n",
       "                          10909.]],\n",
       "    \n",
       "                        ...,\n",
       "    \n",
       "                        [[16384.,  1811.,  7467., ...,  1363.,   633.,\n",
       "                           7749.],\n",
       "                         [16384., 12143.,  6123., ..., 13519.,  6930.,\n",
       "                          14129.],\n",
       "                         [16384.,   167.,  4238., ...,  2428.,  6690.,\n",
       "                           6123.],\n",
       "                         ...,\n",
       "                         [16384., 10227.,  8493., ...,  3212.,  2029.,\n",
       "                          11334.],\n",
       "                         [16384., 11235.,  5908., ..., 10319., 15917.,\n",
       "                           7576.],\n",
       "                         [16384.,  8867.,  5314., ...,  8431., 11427.,\n",
       "                          11605.]],\n",
       "    \n",
       "                        [[16384.,  4635., 11941., ...,  8663.,   194.,\n",
       "                          12025.],\n",
       "                         [16384., 10042., 10042., ..., 11594., 13769.,\n",
       "                          14283.],\n",
       "                         [16384.,  8493.,  5693., ...,  6271.,  2469.,\n",
       "                           4817.],\n",
       "                         ...,\n",
       "                         [16384.,  9206.,  4301., ...,  6386.,  8583.,\n",
       "                          11147.],\n",
       "                         [16384.,  9753.,  9598., ...,  7191., 10042.,\n",
       "                           6965.],\n",
       "                         [16384.,  6965.,  6172., ..., 14447., 14164.,\n",
       "                          14447.]],\n",
       "    \n",
       "                        [[16384., 10042.,  5171., ..., 14673.,  9570.,\n",
       "                          10042.],\n",
       "                         [16384.,  2474.,   432., ...,  5171.,  2987.,\n",
       "                           5625.],\n",
       "                         [16384., 10042.,  5171., ...,  9834.,  9570.,\n",
       "                          10042.],\n",
       "                         ...,\n",
       "                         [16384.,  9834.,  4238., ...,  6060.,  5113.,\n",
       "                             81.],\n",
       "                         [16384., 10278.,  9470., ...,  1704., 12823.,\n",
       "                           6933.],\n",
       "                         [16384., 10042.,  5171., ...,   129.,  9834.,\n",
       "                           5171.]]], dtype=float32),\n",
       "    input_ids: ShardedDeviceArray([[[    0,    99,   241, ...,     1,     1,     1],\n",
       "                         [    0, 12007,  3464, ...,     1,     1,     1],\n",
       "                         [    0,  2857,  8287, ...,     1,     1,     1],\n",
       "                         ...,\n",
       "                         [    0,  1824,    99, ...,     1,     1,     1],\n",
       "                         [    0, 11304,   439, ...,     1,     1,     1],\n",
       "                         [    0,     2,     1, ...,     1,     1,     1]],\n",
       "    \n",
       "                        [[    0,  6444,  4475, ...,     1,     1,     1],\n",
       "                         [    0,  4280,  1915, ...,     1,     1,     1],\n",
       "                         [    0,  2154, 44698, ...,     1,     1,     1],\n",
       "                         ...,\n",
       "                         [    0,  2947,    99, ...,     1,     1,     1],\n",
       "                         [    0,  2331,  2054, ...,     1,     1,     1],\n",
       "                         [    0,     2,     1, ...,     1,     1,     1]],\n",
       "    \n",
       "                        [[    0,  5235, 20302, ...,     1,     1,     1],\n",
       "                         [    0,     2,     1, ...,     1,     1,     1],\n",
       "                         [    0,     2,     1, ...,     1,     1,     1],\n",
       "                         ...,\n",
       "                         [    0,     2,     1, ...,     1,     1,     1],\n",
       "                         [    0,   205,  1250, ...,     1,     1,     1],\n",
       "                         [    0, 16858, 30843, ...,     1,     1,     1]],\n",
       "    \n",
       "                        ...,\n",
       "    \n",
       "                        [[    0,     2,     1, ...,     1,     1,     1],\n",
       "                         [    0,  4083,  3014, ...,     1,     1,     1],\n",
       "                         [    0,  1953, 27632, ...,     1,     1,     1],\n",
       "                         ...,\n",
       "                         [    0,  2618,  3976, ...,     1,     1,     1],\n",
       "                         [    0,     2,     1, ...,     1,     1,     1],\n",
       "                         [    0,   252,    38, ...,     1,     1,     1]],\n",
       "    \n",
       "                        [[    0,  1371,    28, ...,     1,     1,     1],\n",
       "                         [    0,   486,   645, ...,     1,     1,     1],\n",
       "                         [    0,  7504,  1971, ...,     1,     1,     1],\n",
       "                         ...,\n",
       "                         [    0,  1201, 12048, ...,     1,     1,     1],\n",
       "                         [    0, 17813,   129, ...,     1,     1,     1],\n",
       "                         [    0,     2,     1, ...,     1,     1,     1]],\n",
       "    \n",
       "                        [[    0,  1791,    31, ...,     1,     1,     1],\n",
       "                         [    0,   173,  1155, ...,     1,     1,     1],\n",
       "                         [    0,  3998, 26443, ...,     1,     1,     1],\n",
       "                         ...,\n",
       "                         [    0,  1572,  3948, ...,     1,     1,     1],\n",
       "                         [    0,   339,  2482, ...,     1,     1,     1],\n",
       "                         [    0,   781,   408, ...,     1,     1,     1]]],                   dtype=int32),\n",
       "    labels: ShardedDeviceArray([[[ 1139,  8447,  1989, ...,  1268,  9035,  7771],\n",
       "                         [ 1270,  9889,  7580, ...,  1400,  5848,  2922],\n",
       "                         [12167,  6598,   217, ...,  2881,  4644, 15282],\n",
       "                         ...,\n",
       "                         [ 9035,  7266, 13586, ...,  2524,  5053, 11993],\n",
       "                         [ 3272,  7106, 11228, ..., 11012,   882,  9479],\n",
       "                         [ 5171,  5171,  5171, ..., 11096,  1400,  7738]],\n",
       "    \n",
       "                        [[10042, 10042,  5171, ...,  5171, 10042,  9834],\n",
       "                         [14283,  8867,  5171, ..., 12566, 10042, 10042],\n",
       "                         [10042, 10042,  5171, ...,  9000,  2334,  1571],\n",
       "                         ...,\n",
       "                         [ 2987, 14420,  1183, ...,  1597, 11348, 12823],\n",
       "                         [ 9570, 10042, 14420, ...,  5416,  2601,  2813],\n",
       "                         [ 4950,  1847, 15565, ..., 15947,  4648,  7806]],\n",
       "    \n",
       "                        [[ 5171,  5171,  1270, ...,  1941,  8283,  8283],\n",
       "                         [ 6060, 16279,  8283, ...,  9837, 11456, 11591],\n",
       "                         [10042, 10042,  5171, ...,  5171, 10042,  9834],\n",
       "                         ...,\n",
       "                         [15076, 12145,  4075, ...,  9479,  6790, 12159],\n",
       "                         [ 1627, 16279,  4652, ..., 10278, 10710,  9345],\n",
       "                         [10274,  2701,  1948, ...,    23, 10909,  8867]],\n",
       "    \n",
       "                        ...,\n",
       "    \n",
       "                        [[ 1811,  7467,  4945, ...,   633,  7749,  4869],\n",
       "                         [12143,  6123, 12951, ...,  6930, 14129, 10845],\n",
       "                         [  167,  4238, 12566, ...,  6690,  6123,   601],\n",
       "                         ...,\n",
       "                         [10227,  8493,   134, ...,  2029, 11334, 13670],\n",
       "                         [11235,  5908, 15276, ..., 15917,  7576, 14283],\n",
       "                         [ 8867,  5314, 13427, ..., 11427, 11605, 14793]],\n",
       "    \n",
       "                        [[ 4635, 11941,  2987, ...,   194, 12025, 10845],\n",
       "                         [10042, 10042,  5171, ..., 13769, 14283,  9834],\n",
       "                         [ 8493,  5693, 11708, ...,  2469,  4817, 10529],\n",
       "                         ...,\n",
       "                         [ 9206,  4301,  1024, ...,  8583, 11147,  3135],\n",
       "                         [ 9753,  9598, 13512, ..., 10042,  6965, 12566],\n",
       "                         [ 6965,  6172,  1052, ..., 14164, 14447,  5772]],\n",
       "    \n",
       "                        [[10042,  5171,  4238, ...,  9570, 10042,  9834],\n",
       "                         [ 2474,   432,  4075, ...,  2987,  5625,  2778],\n",
       "                         [10042,  5171, 11334, ...,  9570, 10042,  9834],\n",
       "                         ...,\n",
       "                         [ 9834,  4238, 14473, ...,  5113,    81,  7106],\n",
       "                         [10278,  9470,  1270, ..., 12823,  6933,  1872],\n",
       "                         [10042,  5171,  5171, ...,  9834,  5171,  9834]]],                   dtype=int32),\n",
       "})"
      ]
     },
     "execution_count": 588,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jaxminibatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d580c27-e2d0-4702-84d2-67d45cd81596",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9a106d-dde8-4039-8bfc-b6b32b98e71e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3ba157-e315-4ad5-82b9-43c64d8a1b95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8350bf87-8d61-4a57-acf9-d1a79d970c15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa8c543c-8509-403a-a879-04ec31f12113",
   "metadata": {},
   "source": [
    "#### accumulate gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f8d012-1e81-478a-b9f3-4c9ec54ff7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accumulate gradients\n",
    "def cumul_minibatch_step(grad_idx, cumul_loss_grad_dropout):\n",
    "                cumul_loss, cumul_grads, dropout_rng = cumul_loss_grad_dropout\n",
    "                loss, grads, dropout_rng = loss_and_grad(grad_idx, dropout_rng)\n",
    "                cumul_loss, cumul_grads = jax.tree_util.tree_map(\n",
    "                    jnp.add, (cumul_loss, cumul_grads), (loss, grads)\n",
    "                )\n",
    "                cumul_grads = with_sharding_constraint(cumul_grads, param_spec)\n",
    "                return cumul_loss, cumul_grads, dropout_rng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fd2330-1564-4396-bea3-1632e62089f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93336207-1f74-4858-ad59-1b4844dfee75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351df696-013e-4aff-9ed4-dbf6d6c45b2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4833ea8-5a57-48a6-8f7e-fb273e9e97c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bce60a-e732-48e3-b322-299888f6c4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create initial state for cumul_minibatch_step loop\n",
    "init_minibatch_step = (\n",
    "                0.0,\n",
    "                with_sharding_constraint(\n",
    "                    jax.tree_util.tree_map(jnp.zeros_like, state.params), param_spec\n",
    "                ),\n",
    "                state.dropout_rng,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fefa2b2-920a-441c-af4a-d5dfbbb0647f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab45247-88f2-4f40-937e-d6ae80108af8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94124b21-2c8c-4cd8-90ec-6a0c2b637420",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fb64a6-d201-4d5e-ac88-d9e13cbfd7b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fa949f-48b0-44f8-a959-97bdc7612d53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9099dfb-9d10-4689-8874-040f4491945f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af42d195-c9ef-42aa-92d0-1e60ccabb628",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eed813f-d71f-4596-aafa-db573bc777f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48caa32c-34e9-4043-b0b0-116cb06f647c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13282122-d6b3-4e91-b17b-f65a16ddc57f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7836011d-1c3d-4bc2-b2d1-2fefc9add2f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cb46e8-d657-4d23-bbba-4933d6b6473f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1743162d-b69a-4443-8513-206e9647ffd2",
   "metadata": {},
   "source": [
    "#### model \n",
    "\n",
    "```python\n",
    "model = DalleBart(\n",
    "            config,\n",
    "            seed=training_args.seed_model,\n",
    "            dtype=getattr(jnp, model_args.dtype),\n",
    "            _do_init=False,\n",
    "        )\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "96a8135c-761a-45de-9497-c6a55ec1c6ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DalleBartConfig {\n",
       "  \"activation_dropout\": 0.0,\n",
       "  \"activation_function\": \"gelu\",\n",
       "  \"attention_dropout\": 0.0,\n",
       "  \"bos_token_id\": 16385,\n",
       "  \"d_model\": 1024,\n",
       "  \"decoder_attention_heads\": 16,\n",
       "  \"decoder_ffn_dim\": 2730,\n",
       "  \"decoder_layers\": 12,\n",
       "  \"decoder_start_token_id\": 16384,\n",
       "  \"do_sample\": true,\n",
       "  \"dropout\": 0.0,\n",
       "  \"encoder_attention_heads\": 16,\n",
       "  \"encoder_ffn_dim\": 2730,\n",
       "  \"encoder_layers\": 12,\n",
       "  \"encoder_vocab_size\": 50300,\n",
       "  \"eos_token_id\": 16385,\n",
       "  \"force_ln_scale\": false,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"image_length\": 256,\n",
       "  \"image_vocab_size\": 16400,\n",
       "  \"init_std\": 0.02,\n",
       "  \"is_encoder_decoder\": true,\n",
       "  \"ln_positions\": \"normformer\",\n",
       "  \"ln_type\": \"layernorm\",\n",
       "  \"max_length\": 257,\n",
       "  \"max_text_length\": 64,\n",
       "  \"min_length\": 257,\n",
       "  \"model_type\": \"dallebart\",\n",
       "  \"normalize_text\": true,\n",
       "  \"pad_token_id\": 16385,\n",
       "  \"scale_embedding\": false,\n",
       "  \"sinkhorn_iters\": 1,\n",
       "  \"tau_init\": 0.05,\n",
       "  \"tie_word_embeddings\": false,\n",
       "  \"transformers_version\": \"4.24.0.dev0\",\n",
       "  \"use_absolute_position_embeddings\": true,\n",
       "  \"use_alibi\": false,\n",
       "  \"use_bias\": false,\n",
       "  \"use_cache\": true,\n",
       "  \"use_cosine_attention\": false,\n",
       "  \"use_deepnet_scaling\": false,\n",
       "  \"use_final_ln_decoder\": true,\n",
       "  \"use_final_ln_encoder\": true,\n",
       "  \"use_glu\": true,\n",
       "  \"use_head_scale\": false,\n",
       "  \"use_scan\": false,\n",
       "  \"use_subln_init\": false,\n",
       "  \"use_swin_position_embeddings\": false\n",
       "}"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "980e951f-095e-4adb-886f-ad613ee56803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['_config', '_module', 'key', 'dtype', 'input_shape', '_is_initialized', '_params_shape_tree', '_required_params'])"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "18082d9f-1f5e-4902-80c7-a450e9637a06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FlaxBartForConditionalGenerationModule()"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "83e944bf-310b-4ab1-b502-e2492abc8e72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "jax.numpy.bfloat16"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "af1022ce-ea57-4156-93f6-f0b8d80bbd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.bart.modeling_flax_bart import (\n",
    "    FlaxBartAttention,\n",
    "    FlaxBartForConditionalGeneration,\n",
    "    FlaxBartForConditionalGenerationModule,\n",
    "    FlaxBartModule,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "af7c3b21-577c-4177-9769-6bac8f1f6594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FlaxBartModule(\n",
       "    # attributes\n",
       "    config = DalleBartConfig {\n",
       "      \"activation_dropout\": 0.0,\n",
       "      \"activation_function\": \"gelu\",\n",
       "      \"attention_dropout\": 0.0,\n",
       "      \"bos_token_id\": 16385,\n",
       "      \"d_model\": 1024,\n",
       "      \"decoder_attention_heads\": 16,\n",
       "      \"decoder_ffn_dim\": 2730,\n",
       "      \"decoder_layers\": 12,\n",
       "      \"decoder_start_token_id\": 16384,\n",
       "      \"do_sample\": true,\n",
       "      \"dropout\": 0.0,\n",
       "      \"encoder_attention_heads\": 16,\n",
       "      \"encoder_ffn_dim\": 2730,\n",
       "      \"encoder_layers\": 12,\n",
       "      \"encoder_vocab_size\": 50300,\n",
       "      \"eos_token_id\": 16385,\n",
       "      \"force_ln_scale\": false,\n",
       "      \"gradient_checkpointing\": false,\n",
       "      \"image_length\": 256,\n",
       "      \"image_vocab_size\": 16400,\n",
       "      \"init_std\": 0.02,\n",
       "      \"is_encoder_decoder\": true,\n",
       "      \"ln_positions\": \"normformer\",\n",
       "      \"ln_type\": \"layernorm\",\n",
       "      \"max_length\": 257,\n",
       "      \"max_text_length\": 64,\n",
       "      \"min_length\": 257,\n",
       "      \"model_type\": \"dallebart\",\n",
       "      \"normalize_text\": true,\n",
       "      \"pad_token_id\": 16385,\n",
       "      \"scale_embedding\": false,\n",
       "      \"sinkhorn_iters\": 1,\n",
       "      \"tau_init\": 0.05,\n",
       "      \"tie_word_embeddings\": false,\n",
       "      \"transformers_version\": \"4.24.0.dev0\",\n",
       "      \"use_absolute_position_embeddings\": true,\n",
       "      \"use_alibi\": false,\n",
       "      \"use_bias\": false,\n",
       "      \"use_cache\": true,\n",
       "      \"use_cosine_attention\": false,\n",
       "      \"use_deepnet_scaling\": false,\n",
       "      \"use_final_ln_decoder\": true,\n",
       "      \"use_final_ln_encoder\": true,\n",
       "      \"use_glu\": true,\n",
       "      \"use_head_scale\": false,\n",
       "      \"use_scan\": false,\n",
       "      \"use_subln_init\": false,\n",
       "      \"use_swin_position_embeddings\": false\n",
       "    }\n",
       "    \n",
       "    dtype = bfloat16\n",
       ")"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FlaxBartModule(config=config, dtype=model.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "8570d040-3967-4234-bee6-1cbfdc37db39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DalleBartConfig {\n",
       "  \"activation_dropout\": 0.0,\n",
       "  \"activation_function\": \"gelu\",\n",
       "  \"attention_dropout\": 0.0,\n",
       "  \"bos_token_id\": 16385,\n",
       "  \"d_model\": 1024,\n",
       "  \"decoder_attention_heads\": 16,\n",
       "  \"decoder_ffn_dim\": 2730,\n",
       "  \"decoder_layers\": 12,\n",
       "  \"decoder_start_token_id\": 16384,\n",
       "  \"do_sample\": true,\n",
       "  \"dropout\": 0.0,\n",
       "  \"encoder_attention_heads\": 16,\n",
       "  \"encoder_ffn_dim\": 2730,\n",
       "  \"encoder_layers\": 12,\n",
       "  \"encoder_vocab_size\": 50300,\n",
       "  \"eos_token_id\": 16385,\n",
       "  \"force_ln_scale\": false,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"image_length\": 256,\n",
       "  \"image_vocab_size\": 16400,\n",
       "  \"init_std\": 0.02,\n",
       "  \"is_encoder_decoder\": true,\n",
       "  \"ln_positions\": \"normformer\",\n",
       "  \"ln_type\": \"layernorm\",\n",
       "  \"max_length\": 257,\n",
       "  \"max_text_length\": 64,\n",
       "  \"min_length\": 257,\n",
       "  \"model_type\": \"dallebart\",\n",
       "  \"normalize_text\": true,\n",
       "  \"pad_token_id\": 16385,\n",
       "  \"scale_embedding\": false,\n",
       "  \"sinkhorn_iters\": 1,\n",
       "  \"tau_init\": 0.05,\n",
       "  \"tie_word_embeddings\": false,\n",
       "  \"transformers_version\": \"4.24.0.dev0\",\n",
       "  \"use_absolute_position_embeddings\": true,\n",
       "  \"use_alibi\": false,\n",
       "  \"use_bias\": false,\n",
       "  \"use_cache\": true,\n",
       "  \"use_cosine_attention\": false,\n",
       "  \"use_deepnet_scaling\": false,\n",
       "  \"use_final_ln_decoder\": true,\n",
       "  \"use_final_ln_encoder\": true,\n",
       "  \"use_glu\": true,\n",
       "  \"use_head_scale\": false,\n",
       "  \"use_scan\": false,\n",
       "  \"use_subln_init\": false,\n",
       "  \"use_swin_position_embeddings\": false\n",
       "}"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.module.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "df3fdea9-888d-49f7-970a-35f85a417b9d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mrngs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmethod\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmutable\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCollection\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mForwardRef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DenyList'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDenyList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeny\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'intermediates'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcapture_intermediates\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mForwardRef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Module'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mflax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrozen_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFrozenDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "  \u001b[0;34m@\u001b[0m\u001b[0mtraceback_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_boundary\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m           \u001b[0mrngs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mPRNGKey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRNGSequences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m           \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m           \u001b[0mmethod\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m           \u001b[0mmutable\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCollectionFilter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDenyList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'intermediates'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m           \u001b[0mcapture_intermediates\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Module'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m           \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mFrozenVariableDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Initializes a module method with variables and returns modified variables.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Jitting `init` initializes a model lazily using only the shapes of the\u001b[0m\n",
       "\u001b[0;34m    provided arguments, and avoids computing the forward pass with actual\u001b[0m\n",
       "\u001b[0;34m    values. Example::\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m      jit_init = jax.jit(SomeModule(...).init)\u001b[0m\n",
       "\u001b[0;34m      jit_init(rng, jnp.ones(input_shape, jnp.float32))\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Args:\u001b[0m\n",
       "\u001b[0;34m      rngs: The rngs for the variable collections.\u001b[0m\n",
       "\u001b[0;34m      *args: Named arguments passed to the init function.\u001b[0m\n",
       "\u001b[0;34m      method: An optional method. If provided, applies this method. If not\u001b[0m\n",
       "\u001b[0;34m        provided, applies the ``__call__`` method.\u001b[0m\n",
       "\u001b[0;34m      mutable: Can be bool, str, or list. Specifies which collections should be\u001b[0m\n",
       "\u001b[0;34m        treated as mutable: ``bool``: all/no collections are mutable.\u001b[0m\n",
       "\u001b[0;34m        ``str``: The name of a single mutable collection. ``list``: A\u001b[0m\n",
       "\u001b[0;34m        list of names of mutable collections. By default all collections\u001b[0m\n",
       "\u001b[0;34m        except \"intermediates\" are mutable.\u001b[0m\n",
       "\u001b[0;34m      capture_intermediates: If `True`, captures intermediate return values\u001b[0m\n",
       "\u001b[0;34m        of all Modules inside the \"intermediates\" collection. By default only\u001b[0m\n",
       "\u001b[0;34m        the return values of all ``__call__`` methods are stored. A function can\u001b[0m\n",
       "\u001b[0;34m        be passed to change the filter behavior. The filter function takes\u001b[0m\n",
       "\u001b[0;34m        the Module instance and method name and returns a bool indicating\u001b[0m\n",
       "\u001b[0;34m        whether the output of that method invocation should be stored.\u001b[0m\n",
       "\u001b[0;34m      **kwargs: Keyword arguments passed to the init function.\u001b[0m\n",
       "\u001b[0;34m    Returns:\u001b[0m\n",
       "\u001b[0;34m      The initialized variable dict.\u001b[0m\n",
       "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_with_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mrngs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mmutable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmutable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mcapture_intermediates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcapture_intermediates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mv_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      ~/mambaforge/lib/python3.10/site-packages/flax/linen/module.py\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.module.init??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "86ec352f-549d-40e5-8913-16a048ee6464",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DalleBart' object has no attribute 'shared'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [377], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshared\u001b[49m\u001b[38;5;241m.\u001b[39mnum_embeddings\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DalleBart' object has no attribute 'shared'"
     ]
    }
   ],
   "source": [
    "model.shared.num_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f17119-c6bd-4273-a32d-9d877d4d9e03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d19574a-8b64-4bec-93a7-976d3ad47f6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c8e3b2-a513-46d3-bb18-1467d8de8b4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b297d7-cfd4-437b-9493-9fe1101cf3b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a181d2b6-7ae0-41da-b789-5de432806192",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf00369c-60dd-4f0b-8fbe-2057d63b1fd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764d9d56-bab8-4a58-8142-82c1447c716a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29bf185-a0f5-47f7-83e0-c6045ae4c400",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe801d86-4bbf-4ca4-9f18-0d73874a9cc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edfcf61-7e8e-48e9-9a42-60eaf9e21cf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e3e1b0-cedf-4a43-b36d-dbb31161ae6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ec6461-87b3-4ba3-867c-2c6cd9347f3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1649b20d-ab43-498a-9146-78e90b7456a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad65b81-730d-4825-bff7-7eb8d24e7858",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44caed2a-72cb-4d79-b7dc-5d311b33dcb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01742169-2022-48ef-b3ff-510a25a39bbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835a107d-d70e-473d-b78d-f53b16eb29c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08425dfc-3d85-4735-bb95-ee70337a037c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb0b5ec-cab0-479b-99e1-fd744f449310",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146cb552-4db6-4da7-88cf-46455a9d644a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
